[
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1257',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1257/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1257/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1257/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1257',
  'id': 2511343808,
  'node_id': 'I_kwDOJgX1Gs6VsBDA',
  'number': 1257,
  'title': 'Additional required fields for metrics',
  'user': {'login': 'Nanayeb34',
   'id': 69251896,
   'node_id': 'MDQ6VXNlcjY5MjUxODk2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/69251896?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Nanayeb34',
   'html_url': 'https: //github.com/Nanayeb34',
   'followers_url': 'https: //api.github.com/users/Nanayeb34/followers',
   'following_url': 'https: //api.github.com/users/Nanayeb34/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Nanayeb34/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Nanayeb34/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Nanayeb34/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Nanayeb34/orgs',
   'repos_url': 'https: //api.github.com/users/Nanayeb34/repos',
   'events_url': 'https: //api.github.com/users/Nanayeb34/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Nanayeb34/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-09-07T00: 30: 04Z',
  'updated_at': '2024-09-07T00: 37: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[ yes
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nI keep getting missing required fields when trying to use `faithfulness`, `answer_relevancy` and `answer_correctness` metrics. From the documentation, there is no response field specified but I am getting an error that it is needed\r\n\r\nRagas version:\r\nPython version:3.10\r\n\r\n**Code to Reproduce**\r\n```\r\ndef query_engine(query):\r\n    query_engine_result= vector_db.max_marginal_relevance_search(query, k=1)\r\n    model_response=final_chain.run(context=query_engine_result, question=query)\r\n    return model_response,query_engine_result\r\n\r\ndef generate_response(query_engine,test_questions,test_answers):\r\n    responses=[query_engine(question) for question in test_questions]\r\n    answers=[]\r\n    contexts=[]\r\n    for index,r in enumerate(responses):\r\n\r\n        answers.append(r[0])\r\n        contexts.append([r[1][0].page_content])\r\n        dataset_dict={\r\n            "user_input":test_questions,\r\n            "answer":answers,\r\n            "retrieved_contexts":contexts,\r\n        }\r\n    if test_answers is not None:\r\n        dataset_dict["reference"]=[test_answer[0] if isinstance(test_answer, list) else test_answer for test_answer in test_answers]\r\n    ds=Dataset.from_dict(dataset_dict)\r\n    return ds\r\n\r\nresults_ds=generate_response(query_engine,test_questions,test_answers)\r\n\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import (\r\n    answer_relevancy,\r\n    faithfulness,\r\n    context_recall,\r\n    context_precision,\r\n    answer_correctness\r\n)\r\nmetrics=[\r\n    context_precision,\r\n    faithfulness,\r\n    answer_relevancy,\r\n    answer_correctness,\r\n    context_recall,\r\n]\r\nresult = evaluate(\r\n    results_ds,\r\n    metrics=metrics\r\n)\r\n```\r\n\r\n**Error trace**\r\n```\r\n{\r\n\t"name": "ValueError",\r\n\t"message": "The metric [faithfulness] that that is used requires the following additional columns [\'response\'] to be present in the dataset.",\r\n\t"stack": "---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[101], line 16\r\n      2 from ragas.metrics import (\r\n      3     answer_relevancy,\r\n      4     faithfulness,\r\n   (...)\r\n      7     answer_correctness\r\n      8 )\r\n      9 metrics=[\r\n     10     context_precision,\r\n     11     faithfulness,\r\n   (...)\r\n     14     context_recall,\r\n     15 ]\r\n---> 16 result = evaluate(\r\n     17     results_ds,\r\n     18     metrics=metrics\r\n     19 )\r\n     21 result\r\n\r\nFile ~/G_RAG/ragas/src/ragas/_analytics.py:129, in track_was_completed.<locals>.wrapper(*args, **kwargs)\r\n    126 @wraps(func)\r\n    127 def wrapper(*args: P.args, **kwargs: P.kwargs) -> t.Any:\r\n    128     track(IsCompleteEvent(event_type=func.__name__, is_completed=False))\r\n--> 129     result = func(*args, **kwargs)\r\n    130     track(IsCompleteEvent(event_type=func.__name__, is_completed=True))\r\n    132     return result\r\n\r\nFile ~/G_RAG/ragas/src/ragas/evaluation.py:162, in evaluate(dataset, metrics, llm, embeddings, callbacks, in_ci, run_config, token_usage_parser, raise_exceptions, column_map)\r\n    159     dataset = EvaluationDataset.from_list(dataset.to_list())\r\n    161 if isinstance(dataset, EvaluationDataset):\r\n--> 162     validate_required_columns(dataset, metrics)\r\n    164 # set the llm and embeddings\r\n    165 if isinstance(llm, LangchainLLM):\r\n\r\nFile ~/G_RAG/ragas/src/ragas/validation.py:47, in validate_required_columns(ds, metrics)\r\n     45 available_columns = ds.features()\r\n     46 if not required_columns.issubset(available_columns):\r\n---> 47     raise ValueError(\r\n     48         f\\"The metric [{m.name}] that that is used requires the following \\"\r\n     49         f\\"additional columns {list(required_columns - available_columns)} \\"\r\n     50         f\\"to be present in the dataset.\\"\r\n     51     )\r\n\r\nValueError: The metric [faithfulness] that that is used requires the following additional columns [\'response\'] to be present in the dataset."\r\n}\r\n```\r\n\r\n**Expected behavior**\r\nExpecting to see the results of the metrics defined\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1257/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1257/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1255',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1255/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1255/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1255/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1255',
  'id': 2509875964,
  'node_id': 'I_kwDOJgX1Gs6Vmar8',
  'number': 1255,
  'title': 'Error running local LLM',
  'user': {'login': 'minglong-huang',
   'id': 75299100,
   'node_id': 'MDQ6VXNlcjc1Mjk5MTAw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/75299100?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/minglong-huang',
   'html_url': 'https: //github.com/minglong-huang',
   'followers_url': 'https: //api.github.com/users/minglong-huang/followers',
   'following_url': 'https: //api.github.com/users/minglong-huang/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/minglong-huang/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/minglong-huang/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/minglong-huang/subscriptions',
   'organizations_url': 'https: //api.github.com/users/minglong-huang/orgs',
   'repos_url': 'https: //api.github.com/users/minglong-huang/repos',
   'events_url': 'https: //api.github.com/users/minglong-huang/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/minglong-huang/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-09-06T08: 48: 01Z',
  'updated_at': '2024-09-06T09: 08: 55Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '\r\nMy code：\r\n```\r\nimport typing as t\r\nimport asyncio\r\nfrom typing import List\r\nfrom datasets import load_dataset, load_from_disk\r\nfrom ragas.metrics import faithfulness, context_recall, context_precision\r\nfrom ragas.metrics import AnswerRelevancy\r\nfrom ragas import evaluate\r\nfrom ragas.llms import BaseRagasLLM\r\nfrom langchain.schema import LLMResult\r\nfrom langchain.schema import Generation\r\nfrom langchain.callbacks.base import Callbacks\r\nfrom langchain.schema.embeddings import Embeddings\r\nfrom transformers import AutoModel, AutoTokenizer\r\nfrom ragas.llms.prompt import PromptValue\r\nfrom llama_index.llms.ollama import Ollama\r\nfrom llama_index.core import Settings\r\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\r\nfrom FlagEmbedding import FlagModel\r\nfrom FlagEmbedding import BGEM3FlagModel\r\nfrom ragas.metrics import answer_relevancy\r\nfrom langchain_core.language_models import BaseLanguageModel\r\nfrom langchain_core.embeddings import Embeddings\r\nfrom ragas.llms import BaseRagasLLM, LangchainLLMWrapper\r\nfrom ragas.embeddings import BaseRagasEmbeddings\r\nimport asyncio\r\nimport traceback\r\nfrom datasets import Dataset\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\nimport torch\r\nfrom ragas.run_config import RunConfig, add_async_retry, add_retry\r\nfrom abc import ABC\r\n\r\nclass MyLLM(BaseRagasLLM):\r\n\r\n    def __init__(self,llm_path):\r\n        self.tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = AutoModel.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = self.base_llm\r\n        self.base_llm = self.base_llm.to(\'cuda\').eval()\r\n\r\n    @property\r\n    def llm(self):\r\n        return self.base_llm\r\n\r\n    def get_llm_result(self, prompt):\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n\r\n        text, history = self.base_llm.chat(self.tokenizer, content, history=[])\r\n        generations.append([Generation(text=text)
            ])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'
            ] = token_total\r\n        return LLMResult(generations=generations, llm_output=llm_output)\r\n\r\n    def generate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = [],\r\n    ):\r\n        print(f\'runing generate_text function...\')\r\n        result = self.get_llm_result(prompt)\r\n        return result\r\n\r\n    async def agenerate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = [],\r\n    ) -> LLMResult:\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n        print(f\'running async def agenerate_text\')\r\n        # text, history = self.base_llm.chat(self.tokenizer, content, history=[])\r\n        # print(f\'*\'*15)\r\n        # print(("Generated text: %s", text))\r\n        try:\r\n            text, history = await asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,\r\n                                                                       content,
            [])\r\n\r\n            # text, history = await asyncio.wait_for(\r\n            #     asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,content,
            []),\r\n            #     timeout=42  # 例如，设置超时时间为60秒\r\n            # )\r\n\r\n        except asyncio.TimeoutError:\r\n            print("操作超时，请检查代码或增加超时时间")\r\n        except asyncio.CancelledError:\r\n            print("任务被取消，请检查代码")\r\n            info = traceback.format_exc()\r\n            print(f"info ={info}")\r\n        except Exception as e:\r\n            print(f"发生未知错误：{e}")\r\n\r\n        generations.append([Generation(text=text)
            ])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'
            ] = token_total\r\n        result = LLMResult(generations=generations, llm_output=llm_output)\r\n        return result\r\n\r\n    async def generate(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: t.Optional[float
            ] = None,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = None,\r\n            is_async: bool = True,\r\n    ) -> LLMResult:\r\n        if temperature is None:\r\n            temperature = 1e-8\r\n        if is_async:\r\n            return await self.agenerate_text(prompt, n, temperature, stop, callbacks)\r\n        else:\r\n            return self.generate_text(prompt, n, temperature, stop, callbacks)\r\n\r\n\r\n# class MyEmbedding(Embeddings):\r\n#\r\n#     def __init__(self, path,max_length=8192, batch_size=256):\r\n#         self.model = FlagModel(path, query_instruction_for_retrieval="为这个句子生成表示以用于检索相关文章：")\r\n#         #self.model = BGEM3FlagModel(path, map_location=\'cuda\')\r\n#         self.max_length = max_length\r\n#         self.batch_size = batch_size\r\n#\r\n#     def embed_documents(self, texts: List[str
            ]) -> List[List[float
                  ]
            ]:\r\n#         return self.model.encode_corpus(texts, self.batch_size, self.max_length).tolist()\r\n#\r\n#     def embed_query(self, text: str) -> List[float
            ]:\r\n#         return self.model.encode_queries(text, self.batch_size, self.max_length).tolist()\r\n\r\nclass TEstEmbedding(Embeddings, ABC):\r\n    run_config: RunConfig\r\n    def __init__(self,model_path):\r\n        self.embed_texts = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\r\n\r\n    def embed_text(self, text: str) -> List[float
            ]:\r\n        embs = self.embed_texts([text
            ])\r\n        return embs[
                  0
            ]\r\n\r\n    def embed_texts(self, texts: List[str
            ]) -> t.List[t.List[float
                  ]
            ]:\r\n\r\n        # loop = asyncio.get_event_loop()\r\n        embed_documents_with_retry = add_retry(\r\n            self.embed_documents, self.run_config\r\n        )\r\n        return embed_documents_with_retry(texts)\r\n\r\n\r\n    async def aembed_text(self, text: str, is_async=True) -> List[float
            ]:\r\n        embs = await self.embed_texts([text
            ], is_async=is_async)\r\n        return embs[
                  0
            ]\r\n\r\n    async def aembed_texts(\r\n        self, texts: List[str
            ], is_async: bool = True\r\n    ) -> t.List[t.List[float
                  ]
            ]:\r\n        if is_async:\r\n            aembed_documents_with_retry = add_async_retry(\r\n                self.aembed_documents, self.run_config\r\n            )\r\n            return await aembed_documents_with_retry(texts)\r\n        else:\r\n            loop = asyncio.get_event_loop()\r\n            embed_documents_with_retry = add_retry(\r\n                self.embed_documents, self.run_config\r\n            )\r\n            return await loop.run_in_executor(None, embed_documents_with_retry, texts)\r\n\r\n    def set_run_config(self, run_config: RunConfig):\r\n        self.run_config = run_config\r\n\r\n    def embed_documents(self, texts: List[str
            ]) -> List[List[float
                  ]
            ]:\r\n        return self.embed_texts.encode_corpus(texts, self.batch_size, self.max_length).tolist()\r\n\r\n    def embed_query(self, text: str) -> List[float
            ]:\r\n        return self.embed_texts.encode_queries(text, self.batch_size, self.max_length).tolist()\r\n#数据\r\ndata_path = "/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa"\r\namnesty_qa = load_dataset("/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa")\r\n\r\n\r\n# MODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\n# MODEL_PATH = \'/home/kelvin/nlp/model/LLM/Qwen/Qwen1.5-32B\'\r\nMODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\n\r\n\r\n\r\nembed_model_path = \'/home/kelvin/nlp/model/Embedding/BAAI/bge-m3\'\r\n# embedding_model = MyEmbedding(embed_model_path)\r\nembedding_model = TEstEmbedding(embed_model_path)\r\nmy_llm = MyLLM(MODEL_PATH)\r\n\r\n\r\nans_relevancy = AnswerRelevancy()\r\n\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'
                  ],\r\n    \'answer\': [\'The first superbowl was held on Jan 15,
                        1967\', \'The most super bowls have been won by The New England Patriots\'
                  ],\r\n    \'contexts\' : [
                        [\'The First AFL–NFL World Championship Game was an American football game played on January 15,
                              1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'
                        ],\r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\'
                        ]
                  ],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15,
                        1967\', \'The New England Patriots have won the Super Bowl a record six times\'
                  ]\r\n
            }\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n# amnesty_qa[
                  "eval"
            ],\r\nresult = evaluate(\r\n    dataset,\r\n    metrics=[context_recall, context_precision, ans_relevancy, faithfulness
            ],\r\n    llm=my_llm,\r\n    embeddings=embedding_model,\r\n    is_async = True,\r\n    raise_exceptions=True,\r\n)\r\n\r\ndf = result.to_pandas()\r\nprint(df.head())\r\ndf.to_csv("result.csv", index=False)\r\n\r\n# print(result)\r\n```\r\n\r\nand error：\r\n```\r\n../aten/src/ATen/native/cuda/Indexing.cu: 1231: indexSelectSmallIndex: block: [
                  18,
                  0,
                  0
            ], thread: [
                  123,
                  0,
                  0
            ] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu: 1231: indexSelectSmallIndex: block: [
                  18,
                  0,
                  0
            ], thread: [
                  124,
                  0,
                  0
            ] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu: 1231: indexSelectSmallIndex: block: [
                  18,
                  0,
                  0
            ], thread: [
                  125,
                  0,
                  0
            ] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu: 1231: indexSelectSmallIndex: block: [
                  18,
                  0,
                  0
            ], thread: [
                  126,
                  0,
                  0
            ] Assertion `srcIndex < srcSelectDimSize` failed.\r\n../aten/src/ATen/native/cuda/Indexing.cu: 1231: indexSelectSmallIndex: block: [
                  18,
                  0,
                  0
            ], thread: [
                  127,
                  0,
                  0
            ] Assertion `srcIndex < srcSelectDimSize` failed.\r\nEvaluating: 0%|          | 0/8 [
                  00: 04<?, ?it/s
            ]\r\nException in thread Thread-3:\r\nTraceback (most recent call last):\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/threading.py", line 1009, in _bootstrap_inner\r\n    self.run()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 75, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/asyncio/base_events.py", line 641, in run_until_complete\r\n    return future.result()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 63, in _aresults\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 58, in _aresults\r\n    r = await future\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/asyncio/tasks.py", line 575, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 91, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/base.py", line 91, in ascore\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/base.py", line 87, in ascore\r\n    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/_faithfulness.py", line 180, in _ascore\r\n    answer_result = await self.llm.generate(\r\n  File "/home/kelvin/nlp/graphrag/eval.py", line 121, in generate\r\n    return await self.agenerate_text(prompt, n, temperature, stop, callbacks)\r\n  File "/home/kelvin/nlp/graphrag/eval.py", line 103, in agenerate_text\r\n    generations.append([Generation(text=text)
            ])\r\nUnboundLocalError: local variable \'text\' referenced before assignment\r\nTraceback (most recent call last):\r\n  File "/home/kelvin/nlp/graphrag/eval.py", line 215, in <module>\r\n    result = evaluate(\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/evaluation.py", line 231, in evaluate\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/evaluation.py", line 213, in evaluate\r\n    raise ExceptionInRunner()\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exception=False` incase you want to show only a warning message instead.\r\n\r\nProcess finished with exit code 1\r\n\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1255/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1255/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1254',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1254/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1254/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1254/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1254',
  'id': 2509806363,
  'node_id': 'I_kwDOJgX1Gs6VmJsb',
  'number': 1254,
  'title': 'How to turn off asynchronous when run local LLM and Embeddings v2',
  'user': {'login': 'minglong-huang',
   'id': 75299100,
   'node_id': 'MDQ6VXNlcjc1Mjk5MTAw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/75299100?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/minglong-huang',
   'html_url': 'https: //github.com/minglong-huang',
   'followers_url': 'https: //api.github.com/users/minglong-huang/followers',
   'following_url': 'https: //api.github.com/users/minglong-huang/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/minglong-huang/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/minglong-huang/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/minglong-huang/subscriptions',
   'organizations_url': 'https: //api.github.com/users/minglong-huang/orgs',
   'repos_url': 'https: //api.github.com/users/minglong-huang/repos',
   'events_url': 'https: //api.github.com/users/minglong-huang/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/minglong-huang/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-09-06T08: 12: 56Z',
  'updated_at': '2024-09-06T08: 15: 12Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Here is my code:\r\n\r\n```\r\nimport typing as t\r\nimport asyncio\r\nfrom typing import List\r\nfrom datasets import load_dataset, load_from_disk\r\nfrom ragas.metrics import faithfulness, context_recall, context_precision\r\nfrom ragas.metrics import AnswerRelevancy\r\nfrom ragas import evaluate\r\nfrom ragas.llms import BaseRagasLLM\r\nfrom langchain.schema import LLMResult\r\nfrom langchain.schema import Generation\r\nfrom langchain.callbacks.base import Callbacks\r\nfrom langchain.schema.embeddings import Embeddings\r\nfrom transformers import AutoModel, AutoTokenizer\r\nfrom ragas.llms.prompt import PromptValue\r\nfrom llama_index.llms.ollama import Ollama\r\nfrom llama_index.core import Settings\r\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\r\nfrom FlagEmbedding import FlagModel\r\nfrom FlagEmbedding import BGEM3FlagModel\r\nfrom ragas.metrics import answer_relevancy\r\nfrom langchain_core.language_models import BaseLanguageModel\r\nfrom langchain_core.embeddings import Embeddings\r\nfrom ragas.llms import BaseRagasLLM, LangchainLLMWrapper\r\nfrom ragas.embeddings import BaseRagasEmbeddings\r\nimport asyncio\r\nimport traceback\r\nfrom datasets import Dataset\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\nimport torch\r\nfrom ragas.run_config import RunConfig, add_async_retry, add_retry\r\nfrom abc import ABC\r\n\r\nclass MyLLM(BaseRagasLLM):\r\n\r\n    def __init__(self,llm_path):\r\n        self.tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = AutoModel.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = self.base_llm\r\n        self.base_llm = self.base_llm.eval()\r\n\r\n    @property\r\n    def llm(self):\r\n        return self.base_llm\r\n\r\n    def get_llm_result(self, prompt):\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n\r\n        print(content)\r\n        text, history = self.base_llm.chat(self.tokenizer, content, history=[])\r\n        print(f\'*\'*15)\r\n        print(("Generated text: %s", text))\r\n        generations.append([Generation(text=text)
            ])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'
            ] = token_total\r\n        return LLMResult(generations=generations, llm_output=llm_output)\r\n\r\n    def generate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = [],\r\n    ):\r\n        print(f\'runing generate_text function...\')\r\n        result = self.get_llm_result(prompt)\r\n        return result\r\n\r\n    async def agenerate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = [],\r\n    ) -> LLMResult:\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n        try:\r\n            # text, history = await asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,\r\n            #                                                            content,
            [])\r\n\r\n            text, history = await asyncio.wait_for(\r\n                asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,content),\r\n                timeout=42  # 例如，设置超时时间为60秒\r\n            )\r\n        except asyncio.TimeoutError:\r\n            print("操作超时，请检查代码或增加超时时间")\r\n        except asyncio.CancelledError:\r\n            print("任务被取消，请检查代码")\r\n            info = traceback.format_exc()\r\n            print(f"info ={info}")\r\n        except Exception as e:\r\n            print(f"发生未知错误：{e}")\r\n\r\n        generations.append([Generation(text=text)
            ])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'
            ] = token_total\r\n        result = LLMResult(generations=generations, llm_output=llm_output)\r\n        return result\r\n\r\n    async def generate(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: t.Optional[float
            ] = None,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = None,\r\n            is_async: bool = True,\r\n    ) -> LLMResult:\r\n        if temperature is None:\r\n            temperature = 1e-8\r\n        if is_async:\r\n            return await self.agenerate_text(prompt, n, temperature, stop, callbacks)\r\n        else:\r\n            return self.generate_text(prompt, n, temperature, stop, callbacks)\r\n\r\nclass TestEmbedding(Embeddings, ABC):\r\n    run_config: RunConfig\r\n    def __init__(self,model_path):\r\n        self.embed_texts = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\r\n\r\n    def embed_text(self, text: str) -> List[float
            ]:\r\n        embs = self.embed_texts([text
            ])\r\n        return embs[
                  0
            ]\r\n\r\n    def embed_texts(self, texts: List[str
            ]) -> t.List[t.List[float
                  ]
            ]:\r\n\r\n        # loop = asyncio.get_event_loop()\r\n        embed_documents_with_retry = add_retry(\r\n            self.embed_documents, self.run_config\r\n        )\r\n        return embed_documents_with_retry(texts)\r\n\r\n\r\n    async def aembed_text(self, text: str, is_async=True) -> List[float
            ]:\r\n        embs = await self.embed_texts([text
            ], is_async=False)\r\n        return embs[
                  0
            ]\r\n\r\n    async def aembed_texts(\r\n        self, texts: List[str
            ], is_async: bool = True\r\n    ) -> t.List[t.List[float
                  ]
            ]:\r\n        if is_async:\r\n            aembed_documents_with_retry = add_async_retry(\r\n                self.aembed_documents, self.run_config\r\n            )\r\n            return await aembed_documents_with_retry(texts)\r\n        else:\r\n            loop = asyncio.get_event_loop()\r\n            embed_documents_with_retry = add_retry(\r\n                self.embed_documents, self.run_config\r\n            )\r\n            return await loop.run_in_executor(None, embed_documents_with_retry, texts)\r\n\r\n    def set_run_config(self, run_config: RunConfig):\r\n        self.run_config = run_config\r\n\r\n    def embed_documents(self, texts: List[str
            ]) -> List[List[float
                  ]
            ]:\r\n        return self.embed_texts.encode_corpus(texts, self.batch_size, self.max_length).tolist()\r\n\r\n    def embed_query(self, text: str) -> List[float
            ]:\r\n        return self.embed_texts.encode_queries(text, self.batch_size, self.max_length).tolist()\r\n#数据\r\ndata_path = "/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa"\r\namnesty_qa = load_dataset("/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa")\r\n\r\n\r\n# MODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\n# MODEL_PATH = \'/home/kelvin/nlp/model/LLM/Qwen/Qwen1.5-32B\'\r\nMODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\n\r\n\r\n\r\nembed_model_path = \'/home/kelvin/nlp/model/Embedding/BAAI/bge-m3\'\r\n# embedding_model = MyEmbedding(embed_model_path)\r\nembedding_model = TestEmbedding(embed_model_path)\r\nmy_llm = MyLLM(MODEL_PATH)\r\n\r\n# Wrap the custom LLM and Embeddings\r\n# my_llm = LangchainLLMWrapper(my_llm)\r\n# embedding_model = LangchainEmbeddingsWrapper(embedding_model)\r\n\r\nans_relevancy = AnswerRelevancy()\r\n\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'
                  ],\r\n    \'answer\': [\'The first superbowl was held on Jan 15,
                        1967\', \'The most super bowls have been won by The New England Patriots\'
                  ],\r\n    \'contexts\' : [
                        [\'The First AFL–NFL World Championship Game was an American football game played on January 15,
                              1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'
                        ],\r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\'
                        ]
                  ],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15,
                        1967\', \'The New England Patriots have won the Super Bowl a record six times\'
                  ]\r\n
            }\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n# amnesty_qa[
                  "eval"
            ],\r\nresult = evaluate(\r\n    dataset,\r\n    metrics=[context_recall, context_precision, ans_relevancy, faithfulness
            ],\r\n    llm=my_llm,\r\n    embeddings=embedding_model,\r\n    raise_exceptions=True,\r\n    is_async=False\r\n)\r\n\r\ndf = result.to_pandas()\r\nprint(df.head())\r\ndf.to_csv("result.csv", index=False)\r\n\r\n# print(result)\r\n```\r\n\r\n\r\nand i have set is_async=False ,but it still run\r\nasync def agenerate_text(\r\nself,\r\nprompt: PromptValue,\r\nn: int = 1,\r\ntemperature: float = 1e-8,\r\nstop: t.Optional[t.List[str
                  ]
            ] = None,\r\ncallbacks: Callbacks = [],\r\n) .\r\n\r\nand then report a error\r\n```\r\nTraceback (most recent call last):\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/threading.py", line 1009, in _bootstrap_inner\r\n    self.run()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 75, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/asyncio/base_events.py", line 641, in run_until_complete\r\n    return future.result()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 63, in _aresults\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 58, in _aresults\r\n    r = await future\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/asyncio/tasks.py", line 575, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 91, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/base.py", line 91, in ascore\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/base.py", line 87, in ascore\r\n    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/_context_recall.py", line 113, in _ascore\r\n    result = await self.llm.generate(\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/llms/base.py", line 92, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter\r\n    result = await action(retry_state)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner\r\n    return call(*args, **kwargs)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check\r\n    raise retry_exc.reraise()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise\r\n    raise self.last_attempt.result()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/concurrent/futures/_base.py", line 438, in result\r\n    return self.__get_result()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/concurrent/futures/_base.py", line 390, in __get_result\r\n    raise self._exception\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "/home/kelvin/nlp/graphrag/eval.py", line 106, in agenerate_text\r\n    generations.append([Generation(text=text)
            ])\r\nUnboundLocalError: local variable \'text\' referenced before assignment\r\nTraceback (most recent call last):\r\n  File "/home/kelvin/nlp/graphrag/eval.py", line 205, in <module>\r\n    result = evaluate(\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/evaluation.py", line 231, in evaluate\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/evaluation.py", line 213, in evaluate\r\n    raise ExceptionInRunner()\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exception=False` incase you want to show only a warning message instead.\r\n\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1254/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1254/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1253',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1253/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1253/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1253/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1253',
  'id': 2509752505,
  'node_id': 'I_kwDOJgX1Gs6Vl8i5',
  'number': 1253,
  'title': 'How to turn off asynchronous when run local LLM and Embeddings',
  'user': {'login': 'minglong-huang',
   'id': 75299100,
   'node_id': 'MDQ6VXNlcjc1Mjk5MTAw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/75299100?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/minglong-huang',
   'html_url': 'https: //github.com/minglong-huang',
   'followers_url': 'https: //api.github.com/users/minglong-huang/followers',
   'following_url': 'https: //api.github.com/users/minglong-huang/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/minglong-huang/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/minglong-huang/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/minglong-huang/subscriptions',
   'organizations_url': 'https: //api.github.com/users/minglong-huang/orgs',
   'repos_url': 'https: //api.github.com/users/minglong-huang/repos',
   'events_url': 'https: //api.github.com/users/minglong-huang/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/minglong-huang/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-09-06T07: 43: 44Z',
  'updated_at': '2024-09-06T07: 45: 07Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Here is my code:\r\n```\r\nimport typing as t\r\nimport asyncio\r\nfrom typing import List\r\nfrom datasets import load_dataset, load_from_disk\r\nfrom ragas.metrics import faithfulness, context_recall, context_precision\r\nfrom ragas.metrics import AnswerRelevancy\r\nfrom ragas import evaluate\r\nfrom ragas.llms import BaseRagasLLM\r\nfrom langchain.schema import LLMResult\r\nfrom langchain.schema import Generation\r\nfrom langchain.callbacks.base import Callbacks\r\nfrom langchain.schema.embeddings import Embeddings\r\nfrom transformers import AutoModel, AutoTokenizer\r\nfrom ragas.llms.prompt import PromptValue\r\nfrom llama_index.llms.ollama import Ollama\r\nfrom llama_index.core import Settings\r\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\r\nfrom FlagEmbedding import FlagModel\r\nfrom FlagEmbedding import BGEM3FlagModel\r\nfrom ragas.metrics import answer_relevancy\r\nfrom langchain_core.language_models import BaseLanguageModel\r\nfrom langchain_core.embeddings import Embeddings\r\nfrom ragas.llms import BaseRagasLLM, LangchainLLMWrapper\r\nfrom ragas.embeddings import BaseRagasEmbeddings\r\nimport asyncio\r\nimport traceback\r\nfrom datasets import Dataset\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\nimport torch\r\nfrom ragas.run_config import RunConfig, add_async_retry, add_retry\r\nfrom abc import ABC\r\n\r\nclass MyLLM(BaseRagasLLM):\r\n\r\n    def __init__(self,llm_path):\r\n        self.tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = AutoModel.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = self.base_llm\r\n        self.base_llm = self.base_llm.eval()\r\n\r\n    @property\r\n    def llm(self):\r\n        return self.base_llm\r\n\r\n    def get_llm_result(self, prompt):\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n\r\n        print(content)\r\n        text, history = self.base_llm.chat(self.tokenizer, content, history=[])\r\n        print(f\'*\'*15)\r\n        print(("Generated text: %s", text))\r\n        generations.append([Generation(text=text)
            ])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'
            ] = token_total\r\n        return LLMResult(generations=generations, llm_output=llm_output)\r\n\r\n    def generate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = [],\r\n    ):\r\n        print(f\'runing generate_text function...\')\r\n        result = self.get_llm_result(prompt)\r\n        return result\r\n\r\n    async def agenerate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = [],\r\n    ) -> LLMResult:\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n        # print(\'\')\r\n        # print(\'*\' * 20)\r\n        # print(f\'{content
            }\')\r\n        # print(\'*\'*20)\r\n        # print(\'\')\r\n        try:\r\n            # text, history = await asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,\r\n            #                                                            content,
            [])\r\n\r\n            text, history = await asyncio.wait_for(\r\n                asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,content),\r\n                timeout=42  # 例如，设置超时时间为60秒\r\n            )\r\n        except asyncio.TimeoutError:\r\n            print("操作超时，请检查代码或增加超时时间")\r\n        except asyncio.CancelledError:\r\n            print("任务被取消，请检查代码")\r\n            info = traceback.format_exc()\r\n            print(f"info ={info}")\r\n        except Exception as e:\r\n            print(f"发生未知错误：{e}")\r\n\r\n        generations.append([Generation(text=text)
            ])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'
            ] = token_total\r\n        result = LLMResult(generations=generations, llm_output=llm_output)\r\n        return result\r\n\r\n\r\nclass MyEmbedding(Embeddings):\r\n\r\n    def __init__(self, path,max_length=8192, batch_size=256):\r\n        self.model = FlagModel(path, query_instruction_for_retrieval="为这个句子生成表示以用于检索相关文章：")\r\n        #self.model = BGEM3FlagModel(path, map_location=\'cuda\')\r\n        self.max_length = max_length\r\n        self.batch_size = batch_size\r\n\r\n    def embed_documents(self, texts: List[str
            ]) -> List[List[float
                  ]
            ]:\r\n        return self.model.encode_corpus(texts, self.batch_size, self.max_length).tolist()\r\n\r\n    def embed_query(self, text: str) -> List[float
            ]:\r\n        return self.model.encode_queries(text, self.batch_size, self.max_length).tolist()\r\n\r\n#数据\r\ndata_path = "/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa"\r\namnesty_qa = load_dataset("/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa")\r\n\r\n\r\n# MODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\n# MODEL_PATH = \'/home/kelvin/nlp/model/LLM/Qwen/Qwen1.5-32B\'\r\nMODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\n\r\n\r\n\r\nembed_model_path = \'/home/kelvin/nlp/model/Embedding/BAAI/bge-m3\'\r\nembedding_model = MyEmbedding(embed_model_path)\r\nmy_llm = MyLLM(MODEL_PATH)\r\n\r\n# Wrap the custom LLM and Embeddings\r\n# my_llm = LangchainLLMWrapper(my_llm)\r\n# embedding_model = LangchainEmbeddingsWrapper(embedding_model)\r\n\r\nans_relevancy = AnswerRelevancy()\r\n\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'
                  ],\r\n    \'answer\': [\'The first superbowl was held on Jan 15,
                        1967\', \'The most super bowls have been won by The New England Patriots\'
                  ],\r\n    \'contexts\' : [
                        [\'The First AFL–NFL World Championship Game was an American football game played on January 15,
                              1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'
                        ],\r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\'
                        ]
                  ],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15,
                        1967\', \'The New England Patriots have won the Super Bowl a record six times\'
                  ]\r\n
            }\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n# amnesty_qa[
                  "eval"
            ],\r\nresult = evaluate(\r\n    dataset,\r\n    metrics=[context_recall, context_precision, ans_relevancy, faithfulness
            ],\r\n    llm=my_llm,\r\n    embeddings=embedding_model,\r\n    raise_exceptions=True,\r\n    is_async=False\r\n)\r\n\r\ndf = result.to_pandas()\r\nprint(df.head())\r\ndf.to_csv("result.csv", index=False)\r\n\r\n```\r\n\r\nand i have set is_async=False ,but it still run    \r\n async def agenerate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str
                  ]
            ] = None,\r\n            callbacks: Callbacks = [],\r\n    ) .\r\n\r\nand then report a error\r\n```\r\nTraceback (most recent call last):\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/threading.py", line 1009, in _bootstrap_inner\r\n    self.run()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 75, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/asyncio/base_events.py", line 641, in run_until_complete\r\n    return future.result()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 63, in _aresults\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 58, in _aresults\r\n    r = await future\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/asyncio/tasks.py", line 575, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/executor.py", line 91, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/base.py", line 91, in ascore\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/base.py", line 87, in ascore\r\n    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/metrics/_context_recall.py", line 113, in _ascore\r\n    result = await self.llm.generate(\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/llms/base.py", line 92, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter\r\n    result = await action(retry_state)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner\r\n    return call(*args, **kwargs)\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/__init__.py", line 418, in exc_check\r\n    raise retry_exc.reraise()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/__init__.py", line 185, in reraise\r\n    raise self.last_attempt.result()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/concurrent/futures/_base.py", line 438, in result\r\n    return self.__get_result()\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/concurrent/futures/_base.py", line 390, in __get_result\r\n    raise self._exception\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "/home/kelvin/nlp/graphrag/eval.py", line 106, in agenerate_text\r\n    generations.append([Generation(text=text)
            ])\r\nUnboundLocalError: local variable \'text\' referenced before assignment\r\nTraceback (most recent call last):\r\n  File "/home/kelvin/nlp/graphrag/eval.py", line 205, in <module>\r\n    result = evaluate(\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/evaluation.py", line 231, in evaluate\r\n    raise e\r\n  File "/home/kelvin/anaconda3/envs/nlp/lib/python3.10/site-packages/ragas/evaluation.py", line 213, in evaluate\r\n    raise ExceptionInRunner()\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exception=False` incase you want to show only a warning message instead.\r\n\r\n```\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1253/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1253/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1251',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1251/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1251/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1251/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1251',
  'id': 2508674028,
  'node_id': 'I_kwDOJgX1Gs6Vh1Ps',
  'number': 1251,
  'title': 'Error while using azure chat open ai',
  'user': {'login': 'cjtejasai',
   'id': 37042989,
   'node_id': 'MDQ6VXNlcjM3MDQyOTg5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/37042989?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/cjtejasai',
   'html_url': 'https: //github.com/cjtejasai',
   'followers_url': 'https: //api.github.com/users/cjtejasai/followers',
   'following_url': 'https: //api.github.com/users/cjtejasai/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/cjtejasai/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/cjtejasai/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/cjtejasai/subscriptions',
   'organizations_url': 'https: //api.github.com/users/cjtejasai/orgs',
   'repos_url': 'https: //api.github.com/users/cjtejasai/repos',
   'events_url': 'https: //api.github.com/users/cjtejasai/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/cjtejasai/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-09-05T20: 41: 36Z',
  'updated_at': '2024-09-06T04: 51: 19Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ ] I have checked the [documentation](https://docs.ragas.io/) and related resources and couldn't resolve my bug.\r\n\r\n**Describe the bug**\r\nWhen we are using azurechatopenai method we are getting some issues, as have and addtional wrapper on top of azureopenai function call, but due to that we inside self.llm.set_run_config(run_config) is expecting values set_run_config which no matter what code i change on wapper side i could run\r\n \r\nRagas version:0.1.6\r\nPython version:3.13\r\n\r\n**Code to Reproduce**\r\nShare code to reproduce the issue\r\n\r\n**Error trace**\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don't worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1251/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1251/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1249',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1249/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1249/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1249/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/1249',
  'id': 2507554544,
  'node_id': 'PR_kwDOJgX1Gs56g2Y1',
  'number': 1249,
  'title': 'Add support to MultiTurn Metrics',
  'user': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745936,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uo0A',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:XL',
    'name': 'size:XL',
    'color': 'ff823f',
    'default': False,
    'description': 'This PR changes 500-999 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-09-05T11: 46: 22Z',
  'updated_at': '2024-09-07T10: 39: 25Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/1249',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/1249',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/1249.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/1249.patch',
   'merged_at': None
            },
  'body': '```python\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import rubrics_score_without_reference\r\nfrom ragas.dataset_schema import EvaluationDataset, MultiTurnSample\r\nfrom ragas.messages import HumanMessage\r\n\r\nsample1 = MultiTurnSample(user_input=[HumanMessage(content="What is X")
            ])\r\nsample2 = MultiTurnSample(user_input=[HumanMessage(content="What is X")
            ])\r\nds = EvaluationDataset(samples=[sample1, sample2
            ])\r\nevaluate(ds,metrics=[rubrics_score_without_reference
            ])\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1249/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1249/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1248',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1248/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1248/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1248/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1248',
  'id': 2507043797,
  'node_id': 'I_kwDOJgX1Gs6VbnPV',
  'number': 1248,
  'title': 'token usage parser for llama_index',
  'user': {'login': 'tarunn2799',
   'id': 28048963,
   'node_id': 'MDQ6VXNlcjI4MDQ4OTYz',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/28048963?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/tarunn2799',
   'html_url': 'https: //github.com/tarunn2799',
   'followers_url': 'https: //api.github.com/users/tarunn2799/followers',
   'following_url': 'https: //api.github.com/users/tarunn2799/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/tarunn2799/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/tarunn2799/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/tarunn2799/subscriptions',
   'organizations_url': 'https: //api.github.com/users/tarunn2799/orgs',
   'repos_url': 'https: //api.github.com/users/tarunn2799/repos',
   'events_url': 'https: //api.github.com/users/tarunn2799/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/tarunn2799/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-09-05T07: 48: 51Z',
  'updated_at': '2024-09-07T10: 57: 29Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ *] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nwhat is unclear to you? What would you like to know?\r\n\r\n\r\nHow do I use the token usage parser when I'm using llama_index evaluate? \r\n\r\n\r\n**Code Examples**\r\nThis community speaks code. Share your code snippets to help us understand your question better.\r\n\r\n**Additional context**\r\nAnything else you want to share with us? \r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1248/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1248/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1247',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1247/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1247/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1247/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1247',
  'id': 2505157270,
  'node_id': 'I_kwDOJgX1Gs6VUaqW',
  'number': 1247,
  'title': 'Facing error for evaluate() for Langchain instance LLM and Embedding models',
  'user': {'login': 'kartik-angadi',
   'id': 107455134,
   'node_id': 'U_kgDOBmeing',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/107455134?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/kartik-angadi',
   'html_url': 'https: //github.com/kartik-angadi',
   'followers_url': 'https: //api.github.com/users/kartik-angadi/followers',
   'following_url': 'https: //api.github.com/users/kartik-angadi/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/kartik-angadi/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/kartik-angadi/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/kartik-angadi/subscriptions',
   'organizations_url': 'https: //api.github.com/users/kartik-angadi/orgs',
   'repos_url': 'https: //api.github.com/users/kartik-angadi/repos',
   'events_url': 'https: //api.github.com/users/kartik-angadi/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/kartik-angadi/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-09-04T12: 05: 25Z',
  'updated_at': '2024-09-04T12: 07: 41Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n** Facing error with using Langchain wrapped hugging face models**\r\nI am using "Qwen/Qwen2-1.5B-Instruct" llm and "sentence-transformers/all-MiniLM-L6-v2" embedding model instead of default OpenAI model, both the models are initialized with langchain, but i am unable to generate score or use any metric,  getting "ERROR:ragas.executor:Exception raised in Job[0]: TimeoutError()" error.\r\n\r\n**Here is the entire code**\r\nfrom langchain.embeddings import HuggingFaceEmbeddings\r\nfrom langchain_huggingface.llms import HuggingFacePipeline\r\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, AutoModel\r\nfrom ragas.metrics import faithfulness\r\nfrom ragas import evaluate\r\nfrom datasets import Dataset \r\n\r\n\r\nmodel_id = "Qwen/Qwen2-1.5B-Instruct"\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\r\npipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=200)\r\nllm_model = HuggingFacePipeline(pipeline=pipe)\r\n\r\nembedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")\r\n\r\ndata_samples = {\r\n    \'question\': [\r\n        \'What is the capital of France?\'\r\n    ],\r\n    \'answer\': [\r\n        \'The capital of France is Paris.\'\r\n    ],\r\n    \'contexts\': [\r\n        [\'France is a country in Western Europe. Paris is its capital and most populous city.\']\r\n    ],\r\n}\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\nresults = evaluate(dataset, metrics=[faithfulness], llm=hf, embeddings=embedding_model)\r\n\r\n**Here is the snapshot of my issue**\r\nI ma using Colab for implementation so i cannot use bigger\r\n![raga_error](https://github.com/user-attachments/assets/e563ec69-e07a-46de-bfcb-20fac2a5fb59)\r\n models \r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1247/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1247/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1246',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1246/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1246/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1246/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1246',
  'id': 2504948907,
  'node_id': 'I_kwDOJgX1Gs6VTnyr',
  'number': 1246,
  'title': 'Can you ragas code with custom ollama and custom embedings',
  'user': {'login': 'Senthselvi',
   'id': 163379373,
   'node_id': 'U_kgDOCbz4rQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/163379373?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Senthselvi',
   'html_url': 'https: //github.com/Senthselvi',
   'followers_url': 'https: //api.github.com/users/Senthselvi/followers',
   'following_url': 'https: //api.github.com/users/Senthselvi/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Senthselvi/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Senthselvi/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Senthselvi/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Senthselvi/orgs',
   'repos_url': 'https: //api.github.com/users/Senthselvi/repos',
   'events_url': 'https: //api.github.com/users/Senthselvi/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Senthselvi/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-09-04T10: 34: 27Z',
  'updated_at': '2024-09-06T07: 34: 14Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I need code with llamaindex using bearer token and base url not with langchain.\r\n\r\nfrom langchain_community.vectorstores import FAISS\r\nfrom langchain_community.vectorstores import Chroma\r\nfrom langchain.text_splitter import CharacterTextSplitter\r\nfrom langchain_community.embeddings import OpenAIEmbeddings\r\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\r\nfrom langchain.chains import RetrievalQA\r\nimport  os\r\nimport openai\r\nimport  time\r\n\r\n \r\nfrom langchain.llms.base import LLM\r\nfrom langchain.callbacks.manager import CallbackManagerForLLMRun\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, LlamaTokenizerFast\r\nfrom typing import Any, List, Optional\r\nimport torch\r\n\r\n\r\nos.environ[
                  "CUDA_VISIBLE_DEVICES"
            ] = "6"\r\n\r\nclass Qwen_LLM(LLM):\r\n    # 基于本地 Qwen 自定义 LLM 类\r\n    tokenizer: AutoTokenizer = None\r\n    model: AutoModelForCausalLM = None\r\n    def __init__(self, mode_name_or_path :str):\r\n        super().__init__()\r\n        print("正在从本地加载模型...")\r\n        self.tokenizer = AutoTokenizer.from_pretrained(mode_name_or_path, use_fast=False)\r\n        self.model = AutoModelForCausalLM.from_pretrained(mode_name_or_path, torch_dtype=torch.bfloat16, device_map="auto")\r\n        self.model.generation_config = GenerationConfig.from_pretrained(mode_name_or_path)\r\n        print("完成本地模型的加载")\r\n\r\n    def _call(self, prompt : str, stop: Optional[List[str
                  ]
            ] = None,\r\n                run_manager: Optional[CallbackManagerForLLMRun
            ] = None,\r\n                **kwargs: Any):\r\n\r\n        messages = [
                  {
                        "role": "user",
                        "content": prompt
                  }
            ]\r\n        input_ids = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\r\n        model_inputs = self.tokenizer([input_ids
            ], return_tensors="pt").to(\'cuda\')\r\n        generated_ids = self.model.generate(model_inputs.input_ids,max_new_tokens=512)\r\n        generated_ids = [\r\n            output_ids[len(input_ids):
                  ] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\r\n
            ]\r\n        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[
                  0
            ]\r\n        \r\n        return response\r\n    \r\n    @property\r\n    def _llm_type(self) -> str:\r\n        return "Qwen_LLM"\r\n\r\nmode_path = ""\r\nllm = Qwen_LLM(mode_name_or_path = mode_path)\r\n\r\nembedding_model_dir = ""\r\nembedding_model_kwargs = {\'device\': \'cuda\'
            }\r\nencode_kwargs = {\'normalize_embeddings\': True
            } # set True to compute cosine similarity\r\nembedding_model = HuggingFaceBgeEmbeddings(\r\n    model_name=embedding_model_dir,\r\n    model_kwargs=embedding_model_kwargs,\r\n    encode_kwargs=encode_kwargs,\r\n    query_instruction="为这个句子生成表示以用于检索相关文章："\r\n)\r\n\r\n\r\nfrom ragas.llms import LangchainLLMWrapper\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\n\r\nllm = LangchainLLMWrapper(llm)\r\nembedding_model = LangchainEmbeddingsWrapper(embedding_model)\r\n\r\n\r\nfrom datasets import Dataset \r\nfrom ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\r\nfrom ragas import evaluate\r\n\r\n# faithfulness.llm = llm\r\n# faithfulness.embeddings = embedding_model\r\n\r\n# data_samples = {\r\n#     \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'
                  ],\r\n#     \'answer\': [\'The first superbowl was held on Jan 15,
                        1967\', \'The most super bowls have been won by The New England Patriots\'
                  ],\r\n#     \'contexts\' : [
                        [\'The First AFL–NFL World Championship Game was an American football game played on January 15,
                              1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'
                        ], \r\n#     [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\'
                        ]
                  ],\r\n#
            }\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'
                  ],\r\n    \'answer\': [\'The first superbowl was held on Jan 15,
                        1967\', \'The most super bowls have been won by The New England Patriots\'
                  ],\r\n    \'contexts\' : [
                        [\'The First AFL–NFL World Championship Game was an American football game played on January 15,
                              1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'
                        ], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\'
                        ]
                  ],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15,
                        1967\', \'The New England Patriots have won the Super Bowl a record six times\'
                  ]\r\n
            }\r\ndataset = Dataset.from_dict(data_samples)\r\n# score = evaluate(dataset,metrics=[faithfulness
            ])\r\nscore = evaluate(dataset,metrics=[faithfulness, answer_relevancy, context_precision, context_recall
            ],llm=llm,embeddings=embedding_model)\r\nscore.to_pandas()\r\nprint(score)\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1246/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1246/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1245',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1245/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1245/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1245/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1245',
  'id': 2504508099,
  'node_id': 'I_kwDOJgX1Gs6VR8LD',
  'number': 1245,
  'title': 'Ragas using llamaindex',
  'user': {'login': 'Senthselvi',
   'id': 163379373,
   'node_id': 'U_kgDOCbz4rQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/163379373?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Senthselvi',
   'html_url': 'https: //github.com/Senthselvi',
   'followers_url': 'https: //api.github.com/users/Senthselvi/followers',
   'following_url': 'https: //api.github.com/users/Senthselvi/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Senthselvi/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Senthselvi/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Senthselvi/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Senthselvi/orgs',
   'repos_url': 'https: //api.github.com/users/Senthselvi/repos',
   'events_url': 'https: //api.github.com/users/Senthselvi/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Senthselvi/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 7,
  'created_at': '2024-09-04T07: 19: 01Z',
  'updated_at': '2024-09-06T05: 00: 49Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '\r\nEvaluation failed: \'CustomOllama\' object has no attribute \'set_run_config\', what is the solution,\r\n\r\nRagas Version: 0.1.7\r\n\r\n**Code Examples**\r\n# Define a simple dataset using Pandas DataFrame\r\ndata =  {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'
                  ],\r\n    \'answer\': [\'The first superbowl was held on Jan 15,
                        1967\', \'The most super bowls have been won by The New England Patriots\'
                  ],\r\n    \'contexts\' : [
                        [\'The First AFL–NFL World Championship Game was an American football game played on January 15,
                              1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'
                        ], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\'
                        ]
                  ],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15,
                        1967\', \'The New England Patriots have won the Super Bowl a record six times\'
                  ]\r\n
            }\r\n\r\n\r\n\r\n\r\ndef evaluate_chat_performance(data, llm, embedding_model):\r\n    dataset = Dataset.from_dict(data)\r\n    print("Dataset preview:", dataset)\r\n\r\n    df = pd.DataFrame(data)\r\n\r\n    if "ground_truth" not in dataset.column_names:\r\n        dataset = dataset.add_column(\r\n            name="ground_truth",\r\n            column=dataset[
                  "ground_truth"
            ],\r\n            new_fingerprint=str(uuid4()),\r\n        )\r\n\r\n    print("Dataset after adding ground_truth:", dataset)\r\n\r\n    metrics = [\r\n        faithfulness,context_precision,answer_relevancy,\r\n        # Using AnswerRelevancy instance\r\n
            ]\r\n\r\n\r\n    try:\r\n        results = evaluate(\r\n            dataset=dataset,\r\n            metrics=metrics,\r\n            llm=llm,\r\n            embeddings=embedding_model,\r\n            raise_exceptions=False,\r\n        \r\n        )\r\n    except Exception as e:\r\n        print("Evaluation failed:", e)\r\n        return\r\n\r\n    print(results.to_pandas())\r\n    results.to_pandas().to_csv(r\'C:\\TestingBot\\Scripts\\V1\\myfile.csv\', sep=\',\')\r\n    return results\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1245/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1245/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1244',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1244/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1244/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1244/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1244',
  'id': 2504477641,
  'node_id': 'I_kwDOJgX1Gs6VR0vJ',
  'number': 1244,
  'title': "Addressing Duplicates Question and Incorrect 'Ground Truth' in RAG Evaluation with Ragas",
  'user': {'login': 'adityamity',
   'id': 92636710,
   'node_id': 'U_kgDOBYWGJg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/92636710?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/adityamity',
   'html_url': 'https: //github.com/adityamity',
   'followers_url': 'https: //api.github.com/users/adityamity/followers',
   'following_url': 'https: //api.github.com/users/adityamity/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/adityamity/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/adityamity/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/adityamity/subscriptions',
   'organizations_url': 'https: //api.github.com/users/adityamity/orgs',
   'repos_url': 'https: //api.github.com/users/adityamity/repos',
   'events_url': 'https: //api.github.com/users/adityamity/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/adityamity/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-09-04T07: 02: 30Z',
  'updated_at': '2024-09-04T07: 05: 41Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I am currently using Ragas to evaluate my RAG application, which is built using llama index . I\'ve encountered a few issues in the generated results:\r\n\r\n1- When generating queries using `TestsetGenerator`, I\'ve noticed that many of the questions are duplicated.\r\n2- In several instances, the \'ground_truth\' is incorrectly marked as "**The answer to the given question is not present in the context**," even though the context is actually available. This leads to a \'`context_precision`\' and \'`context_recall`\' of 0, negatively impacting the overall score.\r\n\r\nCould you advise on how to address these issues?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1244/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1244/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1238',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1238/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1238/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1238/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1238',
  'id': 2499344417,
  'node_id': 'I_kwDOJgX1Gs6U-Pgh',
  'number': 1238,
  'title': 'It takes two hours to evaluate two indicators with 500 data records. Is there any method to accelerate the evaluation?',
  'user': {'login': 'wangsir-cn',
   'id': 20264196,
   'node_id': 'MDQ6VXNlcjIwMjY0MTk2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/20264196?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/wangsir-cn',
   'html_url': 'https: //github.com/wangsir-cn',
   'followers_url': 'https: //api.github.com/users/wangsir-cn/followers',
   'following_url': 'https: //api.github.com/users/wangsir-cn/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/wangsir-cn/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/wangsir-cn/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/wangsir-cn/subscriptions',
   'organizations_url': 'https: //api.github.com/users/wangsir-cn/orgs',
   'repos_url': 'https: //api.github.com/users/wangsir-cn/repos',
   'events_url': 'https: //api.github.com/users/wangsir-cn/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/wangsir-cn/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-09-01T09: 37: 24Z',
  'updated_at': '2024-09-06T05: 22: 55Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'It takes two hours to evaluate two indicators with 500 data records. Is there any method to accelerate the evaluation?\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1238/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1238/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1237',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1237/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1237/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1237/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1237',
  'id': 2498916395,
  'node_id': 'I_kwDOJgX1Gs6U8nAr',
  'number': 1237,
  'title': '[R-296
            ] revamp documentation',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028618,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZyg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/documentation',
    'name': 'documentation',
    'color': '0075ca',
    'default': True,
    'description': 'Improvements or additions to documentation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-08-31T15: 54: 20Z',
  'updated_at': '2024-08-31T16: 29: 44Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '### Explore Features\n\n- [] code references type\n- [] jupyter notebook\n  - [] output and inputs - custom theme\n  - [] the objective is to have no distinction between .md code and .ipynb code\n- [] switch versions\n- [] explore hosting solutions\n- [] explore tab option for switching LLMs\n\n<details close>\n<summary>meeting notes</summary>\n<br>\n\n* how good is support for markdown notebooks as docs\n* how do we setup code references\n  * something like [Pydantic Settings - Pydantic
            ](https: //docs.pydantic.dev/latest/api/pydantic_settings/#pydantic_settings.BaseSettings)\n  * this also means we have to add more code documentation - that @jjmachan\n  * will also pitch in\n* search, need a fast search bar to find stuff\n* theming -> make black theme, consistent with ragas docs\n* what are the other cool stuff in material for mkdocs can we use to make our documentation the best in the world. This is a where you can use your expertise and creativity, just a list of possible items is enough\n* watch-docs: we should be able to setup something like live-reloading in webpages for documentations website locally\n* reference function directly. For example if I reference `evaluate()` in the documentation, it should point to the code refrence section.\n  porting\n* make sure the extra features of the theme work in markdown\n  if we can get those working we can switch\n  </details>\n\n<sub>From [SyncLinear.com](https://synclinear.com) | [R-296](https://linear.app/exploding-gradients/issue/R-296/revamp-documentation)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1237/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1237/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1236',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1236/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1236/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1236/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1236',
  'id': 2498916342,
  'node_id': 'I_kwDOJgX1Gs6U8m_2',
  'number': 1236,
  'title': '[R-295
            ] revamp documentation',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028618,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZyg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/documentation',
    'name': 'documentation',
    'color': '0075ca',
    'default': True,
    'description': 'Improvements or additions to documentation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-08-31T15: 54: 12Z',
  'updated_at': '2024-08-31T15: 56: 23Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'null\n\n<sub>[R-295
            ](https: //linear.app/exploding-gradients/issue/R-295/revamp-documentation)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1236/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1236/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1234',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1234/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1234/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1234/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1234',
  'id': 2495022922,
  'node_id': 'I_kwDOJgX1Gs6UtwdK',
  'number': 1234,
  'title': 'Can Ragas be used to evaluate Amazon Bedrock Agents w/ managed Knowledge Base?',
  'user': {'login': 'danielesalvatore',
   'id': 6150475,
   'node_id': 'MDQ6VXNlcjYxNTA0NzU=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/6150475?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/danielesalvatore',
   'html_url': 'https: //github.com/danielesalvatore',
   'followers_url': 'https: //api.github.com/users/danielesalvatore/followers',
   'following_url': 'https: //api.github.com/users/danielesalvatore/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/danielesalvatore/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/danielesalvatore/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/danielesalvatore/subscriptions',
   'organizations_url': 'https: //api.github.com/users/danielesalvatore/orgs',
   'repos_url': 'https: //api.github.com/users/danielesalvatore/repos',
   'events_url': 'https: //api.github.com/users/danielesalvatore/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/danielesalvatore/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-08-29T16: 30: 58Z',
  'updated_at': '2024-08-30T12: 31: 59Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[X] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nwhat is unclear to you? What would you like to know?\r\n\r\nI just discovered the MDD approach for RAG development implemented by Ragas, and it is fascinating.\r\n\r\nI have a conversational chatbot based on Amazon Bedrock Agent that uses `claude-3-haiku-20240307-v1` as LLM, configured to use a Bedrock Knowledge Base (AWS managed). The KB is built on top of Amazon OpenSearch Service Serverless with `titan-embed-text-v1` as the embedding model (chunking setup: fixed length size, max 300 tokens, 20% overlap). \r\n\r\nWould Ragas be able to be used to evaluate my RAG setup? If so, do you have any examples, or can you point me to relevant documentation/approaches?\r\n\r\nThank you!\r\n\r\n**Code Examples**\r\nThe chatbot infrastructure is scripted using AWS CD (python). I can provide relevant snippets if required.\r\n\r\n**Additional context**\r\nAnything else you want to share with us? \r\nI opted for this setup since AWS manages every service.",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1234/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1234/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1230',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1230/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1230/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1230/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1230',
  'id': 2493049465,
  'node_id': 'I_kwDOJgX1Gs6UmOp5',
  'number': 1230,
  'title': 'LangChain integration does not work for summarization_score',
  'user': {'login': 'Peilun-Li',
   'id': 11920339,
   'node_id': 'MDQ6VXNlcjExOTIwMzM5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/11920339?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Peilun-Li',
   'html_url': 'https: //github.com/Peilun-Li',
   'followers_url': 'https: //api.github.com/users/Peilun-Li/followers',
   'following_url': 'https: //api.github.com/users/Peilun-Li/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Peilun-Li/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Peilun-Li/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Peilun-Li/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Peilun-Li/orgs',
   'repos_url': 'https: //api.github.com/users/Peilun-Li/repos',
   'events_url': 'https: //api.github.com/users/Peilun-Li/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Peilun-Li/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-28T21: 51: 43Z',
  'updated_at': '2024-08-28T21: 55: 56Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '- [x
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\n`EvaluatorChain` errors out for summariztion_score metric. `ValueError: Missing some input keys: {\'answer\'}`\r\n\r\nRagas version: 0.1.15\r\nPython version: 3.9\r\n\r\n**Code to Reproduce**\r\n```\r\nfrom ragas.integrations.langchain import EvaluatorChain\r\nfrom ragas.metrics import summarization_score \r\n\r\nchain=EvaluatorChain(metric=summarization_score)\r\n\r\nchain.run({"contexts": ["hello"], "summary": "hello"})\r\n```\r\n\r\n**Error trace**\r\n```\r\nFile /.../python3.9/site-packages/langchain/chains/base.py:284, in Chain._validate_inputs(self, inputs)\r\n    282 missing_keys = set(self.input_keys).difference(inputs)\r\n    283 if missing_keys:\r\n--> 284     raise ValueError(f"Missing some input keys: {missing_keys}")\r\nValueError: Missing some input keys: {\'answer\'}\r\n```\r\n\r\n**Expected behavior**\r\nExpect summarization_score could work with LangChain (EvaluatorChain)\r\n\r\n**Additional context**\r\nThe same setting above works for other ragas metrics like faithfulness. Example\r\n```\r\nfrom ragas.integrations.langchain import EvaluatorChain\r\nfrom ragas.metrics import faithfulness \r\n\r\nchain=EvaluatorChain(metric=faithfulness)\r\n\r\nchain.run({"question": "What is the capital of France?",\r\n    "answer": "The capital of France is Paris.",\r\n    "contexts": [\r\n        "France, in Western Europe, encompasses medieval cities, alpine villages and Mediterranean beaches. Paris, its capital, is famed for its fashion houses, classical art museums including the Louvre and monuments like the Eiffel Tower.",\r\n        "Paris is the capital and most populous city of France. It has an area of 105 square kilometers and a population of over 2 million residents."\r\n    ],\r\n    "ground_truth": "Paris"\r\n})\r\n```\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1230/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1230/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1229',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1229/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1229/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1229/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1229',
  'id': 2492866966,
  'node_id': 'I_kwDOJgX1Gs6UliGW',
  'number': 1229,
  'title': 'How to get started question',
  'user': {'login': 'botchagalupeai',
   'id': 142898388,
   'node_id': 'U_kgDOCIR01A',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/142898388?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/botchagalupeai',
   'html_url': 'https: //github.com/botchagalupeai',
   'followers_url': 'https: //api.github.com/users/botchagalupeai/followers',
   'following_url': 'https: //api.github.com/users/botchagalupeai/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/botchagalupeai/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/botchagalupeai/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/botchagalupeai/subscriptions',
   'organizations_url': 'https: //api.github.com/users/botchagalupeai/orgs',
   'repos_url': 'https: //api.github.com/users/botchagalupeai/repos',
   'events_url': 'https: //api.github.com/users/botchagalupeai/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/botchagalupeai/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028618,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZyg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/documentation',
    'name': 'documentation',
    'color': '0075ca',
    'default': True,
    'description': 'Improvements or additions to documentation'
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 21,
  'created_at': '2024-08-28T19: 46: 29Z',
  'updated_at': '2024-08-29T04: 16: 16Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I am trying to follow the Get Started documentation on \r\n\r\nhttps: //docs.ragas.io/en/latest/getstarted/testset_generation.html\r\n\r\nI apologize for being a newbie upfront. \r\n\r\nI was able to create the synthetic test set from my data. However, I can\'t figure out how to convert the dataset (testset) into a format that the next step in the tutorial "Evaluating Using Your Test Set" (i.e., documentation example expects.)\r\n\r\nhttps://docs.ragas.io/en/latest/getstarted/evaluation.html\r\n\r\nIt would enhance the tutorial if there were an intermediate step (example) to make the process more seamless. Any assistance in this matter would be greatly appreciated.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1229/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1229/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1228',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1228/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1228/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1228/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1228',
  'id': 2491228079,
  'node_id': 'I_kwDOJgX1Gs6UfR-v',
  'number': 1228,
  'title': 'Failed to parse output.',
  'user': {'login': 'g-hano',
   'id': 113353248,
   'node_id': 'U_kgDOBsGiIA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/113353248?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/g-hano',
   'html_url': 'https: //github.com/g-hano',
   'followers_url': 'https: //api.github.com/users/g-hano/followers',
   'following_url': 'https: //api.github.com/users/g-hano/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/g-hano/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/g-hano/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/g-hano/subscriptions',
   'organizations_url': 'https: //api.github.com/users/g-hano/orgs',
   'repos_url': 'https: //api.github.com/users/g-hano/repos',
   'events_url': 'https: //api.github.com/users/g-hano/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/g-hano/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-08-28T06: 54: 41Z',
  'updated_at': '2024-08-28T07: 17: 34Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\nLocal LLMs either raise Timeout error or Fails to parse output.\r\n\r\nRagas version: 0.1.15\r\nPython version: 3.11.3\r\n\r\n**Code to Reproduce**\r\n```python\r\nfrom transformers import AutoTokenizer\r\ntokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.3")\r\nimport pandas as pd\r\ndf = pd.read_csv("output.csv", sep=";")\r\n\r\ndata_samples = {\r\n    \'question\': df[\'question\'
                  ].tolist(),\r\n    \'answer\': df[\'answer\'
                  ].tolist(),\r\n    \'contexts\': df[\'contexts\'
                  ].apply(lambda x: [x
                  ] if isinstance(x, str) else x).tolist(),\r\n    \'ground_truth\': df[\'ground_truth\'
                  ].tolist()\r\n
            }\r\n\r\nfrom datasets import Dataset \r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import (faithfulness, \r\n                           answer_correctness,    \r\n                           answer_relevancy,\r\n                           context_recall,\r\n                           context_precision)\r\n\r\nfrom langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\r\nend = HuggingFaceEndpoint(repo_id="mistralai/Mistral-7B-Instruct-v0.3", max_new_tokens=512)\r\nhuggingface_llm = ChatHuggingFace(llm=end, tokenizer=tokenizer)\r\nhuggingface_embeddings = HuggingFaceEmbeddings(model_name="nomic-ai/nomic-embed-text-v1.5")\r\n\r\nmetrics=[faithfulness, \r\n        answer_correctness,    \r\n        answer_relevancy,\r\n        context_recall,\r\n        context_precision
            ]\r\n\r\nscore = evaluate(dataset=dataset,\r\n        metrics=metrics,\r\n        llm=huggingface_llm,\r\n        embeddings=huggingface_embeddings,\r\n        raise_exceptions=False\r\n)\r\n```\r\n\r\n**Error trace**\r\n```bash\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  304
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  444
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nException raised in Job[
                  169
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None..\r\nException raised in Job[
                  309
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  174
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  449
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  179
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  314
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  184
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  454
            ]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 0 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 0 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nException raised in Job[
                  461
            ]: ClientResponseError(429, message=\'Too Many Requests\', url=URL(\'https: //api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3\'))\r\nException raised in Job[196]: ClientResponseError(429, message=\'Too Many Requests\', url=URL(\'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3\'))\r\nException raised in Job[462]: ClientResponseError(429, message=\'Too Many Requests\', url=URL(\'https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3\'))\r\n\r\n```\r\n\r\n**Additional context**\r\nit only evaluates for `answer_correctness`, other values are all `NaN`\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1228/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1228/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1227',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1227/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1227/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1227/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/1227',
  'id': 2489303063,
  'node_id': 'PR_kwDOJgX1Gs55khIj',
  'number': 1227,
  'title': 'bugfix: fixed prompt adapt from English to other languages',
  'user': {'login': 'yifan',
   'id': 104565,
   'node_id': 'MDQ6VXNlcjEwNDU2NQ==',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/104565?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/yifan',
   'html_url': 'https: //github.com/yifan',
   'followers_url': 'https: //api.github.com/users/yifan/followers',
   'following_url': 'https: //api.github.com/users/yifan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/yifan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/yifan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/yifan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/yifan/orgs',
   'repos_url': 'https: //api.github.com/users/yifan/repos',
   'events_url': 'https: //api.github.com/users/yifan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/yifan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745916,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uovA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:M',
    'name': 'size:M',
    'color': 'ebb800',
    'default': False,
    'description': 'This PR changes 30-99 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-08-27T13: 02: 53Z',
  'updated_at': '2024-09-02T18: 11: 34Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/1227',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/1227',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/1227.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/1227.patch',
   'merged_at': None
            },
  'body': 'Issue:\r\n\r\nthe adaptation failed to parse the result of translation, resulting the adapted prompts not usable.  Specifically:\r\n\r\n-  A indentation error causes json loaded output to be overwritten by raw string, causing output for json in adaptation to be not readable\r\n\r\n```\r\n   ```json\r\n   {\r\n     "blah": 1\r\n
            }\r\n   \r\n```\r\n\r\n- translation output for str_translation needs to be extracted before putting back to prompt. we fix it by cleaning llm translation output.\r\n- the code assumes use str_translation for every value except output, it does not take care of contexts, which is an array of string. deal with translation for non-output items such as ```contexts: [ str1, str2, str3
            ]```, fix with json_loader.\r\n\r\nSolution:\r\n\r\n- fix indentation error\r\n- parse translation results correctly by only taking the translation result\r\n- check field value, and use json_loader with json_translation when the value in original prompt is a list instead of str\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1227/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1227/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1226',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1226/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1226/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1226/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1226',
  'id': 2489161616,
  'node_id': 'I_kwDOJgX1Gs6UXZeQ',
  'number': 1226,
  'title': 'Local Model Runner in Executor raises exceptions',
  'user': {'login': 'g-hano',
   'id': 113353248,
   'node_id': 'U_kgDOBsGiIA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/113353248?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/g-hano',
   'html_url': 'https: //github.com/g-hano',
   'followers_url': 'https: //api.github.com/users/g-hano/followers',
   'following_url': 'https: //api.github.com/users/g-hano/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/g-hano/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/g-hano/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/g-hano/subscriptions',
   'organizations_url': 'https: //api.github.com/users/g-hano/orgs',
   'repos_url': 'https: //api.github.com/users/g-hano/repos',
   'events_url': 'https: //api.github.com/users/g-hano/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/g-hano/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-08-27T12: 08: 57Z',
  'updated_at': '2024-08-27T13: 19: 53Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\nI want to use local llms to evaluate my rag app, I have tried Ollama and HuggingFace models but neither of them is working.\r\n\r\nRagas version: 0.1.11\r\nPython version: 3.11.3\r\n\r\n**Code to Reproduce**\r\n```python\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\r\n\r\ntokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.3")\r\ntokenizer.pad_token_id=tokenizer.eos_token_id\r\nmodel = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.3")\r\n\r\ndf = pd.read_csv("output.csv", sep=";")\r\ndata_samples = {\r\n    \'question\': df[\'question\'
                  ].tolist(),\r\n    \'answer\': df[\'answer\'
                  ].tolist(),\r\n    \'contexts\': df[\'contexts\'
                  ].apply(lambda x: [x
                  ] if isinstance(x, str) else x).tolist(),\r\n    \'ground_truth\': df[\'ground_truth\'
                  ].tolist()\r\n
            }\r\n\r\nfrom datasets import Dataset \r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import (faithfulness, \r\n                           answer_correctness,    \r\n                           answer_relevancy,\r\n                           context_recall,\r\n                           context_precision)\r\n\r\nfrom langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\r\nfrom ragas.llms import LangchainLLMWrapper\r\n\r\npipe = pipeline(model=model, tokenizer=tokenizer, task="text-generation")\r\nhf_pipe = HuggingFacePipeline(pipeline=pipe)\r\nragas_llm = LangchainLLMWrapper(langchain_llm=hf_pipe)\r\nragas_embed = HuggingFaceEmbeddings(model_name="nomic-ai/nomic-embed-text-v1.5", model_kwargs={
                  "trust_remote_code": True
            })\r\n\r\nmetrics=[faithfulness, \r\n        answer_correctness, \r\n        answer_relevancy, \r\n        context_recall,\r\n        context_precision
            ]\r\nscore = evaluate(dataset=dataset,\r\n                 metrics=metrics,\r\n                 llm=ragas_llm,\r\n                 embeddings=ragas_embed,\r\n                 raise_exceptions=False\r\n                 )\r\n\r\n```\r\n\r\n**Error trace**\r\n```bash\r\nRunner in Executor raised an exception\r\nRunner in Executor raised an exception\r\nRunner in Executor raised an exception\r\nRunner in Executor raised an exception\r\nRunner in Executor raised an exception\r\nRunner in Executor raised an exception\r\nRunner in Executor raised an exception\r\nRunner in Executor raised an exception\r\n```\r\n**Expected behavior**\r\nSuccesfuly evaluating\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1226/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1226/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1224',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1224/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1224/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1224/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1224',
  'id': 2487364765,
  'node_id': 'I_kwDOJgX1Gs6UQiyd',
  'number': 1224,
  'title': 'Ragas',
  'user': {'login': 'Senthselvi',
   'id': 163379373,
   'node_id': 'U_kgDOCbz4rQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/163379373?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Senthselvi',
   'html_url': 'https: //github.com/Senthselvi',
   'followers_url': 'https: //api.github.com/users/Senthselvi/followers',
   'following_url': 'https: //api.github.com/users/Senthselvi/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Senthselvi/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Senthselvi/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Senthselvi/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Senthselvi/orgs',
   'repos_url': 'https: //api.github.com/users/Senthselvi/repos',
   'events_url': 'https: //api.github.com/users/Senthselvi/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Senthselvi/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 12,
  'created_at': '2024-08-26T17: 20: 07Z',
  'updated_at': '2024-09-01T13: 56: 59Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'what is the correct code?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1224/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1224/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1220',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1220/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1220/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1220/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1220',
  'id': 2484289666,
  'node_id': 'I_kwDOJgX1Gs6UE0CC',
  'number': 1220,
  'title': '[R-294
            ] Generation for data types',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-08-24T06: 33: 48Z',
  'updated_at': '2024-08-24T06: 33: 53Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'null\n\n<sub>[R-294
            ](https: //linear.app/exploding-gradients/issue/R-294/generation-for-data-types)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1220/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1220/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1218',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1218/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1218/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1218/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1218',
  'id': 2483841836,
  'node_id': 'I_kwDOJgX1Gs6UDGss',
  'number': 1218,
  'title': 'How is it ensured that ground truth answers are complete and not just partially correct?',
  'user': {'login': 'neerajchhimwal',
   'id': 30681809,
   'node_id': 'MDQ6VXNlcjMwNjgxODA5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/30681809?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/neerajchhimwal',
   'html_url': 'https: //github.com/neerajchhimwal',
   'followers_url': 'https: //api.github.com/users/neerajchhimwal/followers',
   'following_url': 'https: //api.github.com/users/neerajchhimwal/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/neerajchhimwal/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/neerajchhimwal/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/neerajchhimwal/subscriptions',
   'organizations_url': 'https: //api.github.com/users/neerajchhimwal/orgs',
   'repos_url': 'https: //api.github.com/users/neerajchhimwal/repos',
   'events_url': 'https: //api.github.com/users/neerajchhimwal/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/neerajchhimwal/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-23T20: 28: 05Z',
  'updated_at': '2024-08-23T20: 30: 42Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[👍
            ] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Your Question**\r\nDuring testset generation using langchain docs, is one question (let\'s say simple) answered by looking at the entire document? How is it ensured that the ground truth answer will be complete if the document is long? Could it be that the answer comes from one of the "chunks" from this document and is hence only partially correct?\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1218/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1218/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1217',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1217/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1217/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1217/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1217',
  'id': 2483794028,
  'node_id': 'I_kwDOJgX1Gs6UC7Bs',
  'number': 1217,
  'title': 'How to integrate with latest LangChain?',
  'user': {'login': 'cdennison',
   'id': 7264710,
   'node_id': 'MDQ6VXNlcjcyNjQ3MTA=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/7264710?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/cdennison',
   'html_url': 'https: //github.com/cdennison',
   'followers_url': 'https: //api.github.com/users/cdennison/followers',
   'following_url': 'https: //api.github.com/users/cdennison/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/cdennison/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/cdennison/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/cdennison/subscriptions',
   'organizations_url': 'https: //api.github.com/users/cdennison/orgs',
   'repos_url': 'https: //api.github.com/users/cdennison/repos',
   'events_url': 'https: //api.github.com/users/cdennison/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/cdennison/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028618,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZyg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/documentation',
    'name': 'documentation',
    'color': '0075ca',
    'default': True,
    'description': 'Improvements or additions to documentation'
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-23T19: 51: 44Z',
  'updated_at': '2024-08-23T22: 51: 12Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'The existing documentation has several issues:\r\nhttps: //docs.ragas.io/en/latest/howtos/integrations/langchain.html\r\n\r\n1. The imports are wrong see https://github.com/explodinggradients/ragas/issues/571\r\n2. I have no idea how to use VectorstoreIndexCreator - all the LangChain examples I see use Chroma or FAISS\r\n3. The example from the LangChain cookbooks is also broken https://github.com/langchain-ai/langsmith-cookbook/blob/main/testing-examples/ragas/ragas.ipynb\r\n\r\n**Your Question**\r\nDoes Ragas plan to offer long terms support for LangChain (if not you can ignore the rest I\'ll have to abandon Ragas)? Can you please review the following code to see if it\'s correct? It\'s based on https://docs.ragas.io/en/latest/howtos/applications/compare_llms.html and https://docs.smith.langchain.com/old/cookbook/hub-examples/retrieval-qa-chain\r\n\r\n**Code Examples**\r\n\r\nragas==0.1.14\r\nlangchain==0.2.14\r\n\r\n```python\r\nfrom langchain_community.vectorstores import Chroma\r\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\nfrom langchain_community.document_loaders import TextLoader\r\nfrom langchain.chains import RetrievalQA\r\n\r\nget a token: https://platform.openai.com/account/api-keys\r\nfrom getpass import getpass\r\nos.environ["OPENAI_API_KEY"] = getpass()\r\n\r\nllm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)\r\n\r\ndef build_query_engine(llm):\r\n  loader = TextLoader("./notebooks_nyc_wikipedia_nyc_text.txt")\r\n  data = loader.load()\r\n\r\n  text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\r\n  all_splits = text_splitter.split_documents(data)\r\n\r\n  vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\r\n\r\n  return RetrievalQA.from_chain_type(\r\n      llm,\r\n      retriever=vectorstore.as_retriever(),\r\n      return_source_documents=True\r\n  )\r\n\r\n#Ragas data\r\neval_questions = [\r\n  "What is the population of New York City as of 2020?",\r\n  "Which borough of New York City has the highest population?",\r\n  "What is the economic significance of New York City?",\r\n  "How did New York City get its name?",\r\n  "What is the significance of the Statue of Liberty in New York City?",\r\n]\r\n\r\neval_answers = [\r\n  "8,804,190",\r\n  "Brooklyn",\r\n  "New York City\'s economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city\'s transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.",\r\n  "New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.",\r\n  "The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.",\r\n]\r\n\r\nexamples = [\r\n  {"query": q, "ground_truth": [eval_answers[i]]}\r\n  for i, q in enumerate(eval_questions)\r\n]\r\n\r\n# run the queries as a batch for efficiency\r\nqa_chain = build_query_engine(llm)\r\npredictions = qa_chain.batch(examples)\r\n\r\n#Ragas code starts here\r\nfrom datasets import Dataset\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import (\r\n  faithfulness,\r\n  answer_relevancy,\r\n  answer_correctness,\r\n)\r\n\r\nmetrics = [\r\n  faithfulness,\r\n  answer_relevancy,\r\n  answer_correctness,\r\n]\r\n\r\n#these seems cumbersome to have to convert the predictions/results differently for every type of integration\r\ndef generate_responses(predictions):\r\n  answers = []\r\n  contexts = []\r\n  test_answers = []\r\n  test_questions = []\r\n  for r in predictions:\r\n    test_questions.append(r[\'query\'])\r\n    answers.append(r[\'result\'])\r\n    test_answers.append(str(r[\'ground_truth\'][0]))\r\n    contexts.append([c.page_content for c in r[\'source_documents\']])\r\n\r\n  dataset_dict = {\r\n    "question": test_questions,\r\n    "answer": answers,\r\n    "contexts": contexts,\r\n    "ground_truth": test_answers\r\n  }\r\n\r\n  return Dataset.from_dict(dataset_dict)\r\n\r\nres = evaluate(\r\n    generate_responses(predictions),\r\n    metrics=metrics,\r\n)\r\n\r\nprint(res)\r\n\r\n#result\r\n#{\'faithfulness\': 0.8714, \'answer_relevancy\': 0.9611, \'answer_correctness\': 0.5776}\r\n```\r\n\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1217/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1217/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1214',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1214/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1214/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1214/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1214',
  'id': 2482634004,
  'node_id': 'I_kwDOJgX1Gs6T-f0U',
  'number': 1214,
  'title': 'HOW to use LOCAL LLMS and Embeddings for ragas？',
  'user': {'login': 'minglong-huang',
   'id': 75299100,
   'node_id': 'MDQ6VXNlcjc1Mjk5MTAw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/75299100?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/minglong-huang',
   'html_url': 'https: //github.com/minglong-huang',
   'followers_url': 'https: //api.github.com/users/minglong-huang/followers',
   'following_url': 'https: //api.github.com/users/minglong-huang/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/minglong-huang/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/minglong-huang/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/minglong-huang/subscriptions',
   'organizations_url': 'https: //api.github.com/users/minglong-huang/orgs',
   'repos_url': 'https: //api.github.com/users/minglong-huang/repos',
   'events_url': 'https: //api.github.com/users/minglong-huang/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/minglong-huang/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 4,
  'created_at': '2024-08-23T08: 40: 58Z',
  'updated_at': '2024-09-04T06: 22: 35Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I have down model weights in my computer，but i don\'t how to use LOCAL LLMS and Embeddings for ragas according to <[Ragas
            ](https: //docs.ragas.io/en/stable/index.html)\r\n/\r\n[🛠️ How-to Guides](https://docs.ragas.io/en/stable/howtos/index.html)\r\n/\r\n[Customizations](https://docs.ragas.io/en/stable/howtos/customisations/index.html)\r\n/\r\nBring Your Own LLMs and Embeddings>\r\n\r\nHere is My code but it did\'t work\r\n```\r\nimport typing as t\r\nimport asyncio\r\nfrom typing import List\r\nfrom datasets import load_dataset, load_from_disk\r\nfrom ragas.metrics import faithfulness, context_recall, context_precision\r\nfrom ragas.metrics import AnswerRelevancy\r\nfrom ragas import evaluate\r\nfrom ragas.llms import BaseRagasLLM\r\nfrom langchain.schema import LLMResult\r\nfrom langchain.schema import Generation\r\nfrom langchain.callbacks.base import Callbacks\r\nfrom langchain.schema.embeddings import Embeddings\r\nfrom transformers import AutoModel, AutoTokenizer\r\nfrom ragas.llms.prompt import PromptValue\r\nfrom llama_index.llms.ollama import Ollama\r\nfrom llama_index.core import Settings\r\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\r\nfrom FlagEmbedding import FlagModel\r\nfrom FlagEmbedding import BGEM3FlagModel\r\nfrom ragas.metrics import answer_relevancy\r\nfrom langchain_core.language_models import BaseLanguageModel\r\nfrom langchain_core.embeddings import Embeddings\r\nfrom ragas.llms import BaseRagasLLM\r\nfrom ragas.embeddings import BaseRagasEmbeddings\r\nimport asyncio\r\nimport traceback\r\nfrom datasets import Dataset\r\nfrom Langchain_my_llm import GLM_4\r\n\r\nclass MyLLM(BaseRagasLLM):\r\n\r\n    def __init__(self,llm_path):\r\n        self.tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = AutoModel.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = self.base_llm.eval()\r\n\r\n    @property\r\n    def llm(self):\r\n        return self.base_llm\r\n\r\n    def get_llm_result(self, prompt):\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n        generate_config ={\r\n            \'max_tokens\':8192,\r\n            \'stream\':True\r\n\r\n        }\r\n        print(content)\r\n        text, history = self.base_llm.chat(self.tokenizer, content, history=[])\r\n        print(("Generated text: %s", text))\r\n        generations.append([Generation(text=text)])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'] = token_total\r\n        return LLMResult(generations=generations, llm_output=llm_output)\r\n\r\n    def generate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str]] = None,\r\n            callbacks: Callbacks = [],\r\n    ):\r\n        result = self.get_llm_result(prompt)\r\n        return result\r\n\r\n    async def agenerate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str]] = None,\r\n            callbacks: Callbacks = [],\r\n    ) -> LLMResult:\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n        print(\'\')\r\n        print(\'*\' * 20)\r\n        print(f\'content={content}\')\r\n        print(\'*\'*20)\r\n        print(\'\')\r\n        try:\r\n            # text, history = await asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,\r\n            #                                                            content, [])\r\n            # 使用更合理的超时时间\r\n            text, history = await asyncio.wait_for(\r\n                asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,content, []),\r\n                timeout=150  # 例如，设置超时时间为60秒\r\n            )\r\n        except asyncio.TimeoutError:\r\n            print("操作超时，请检查代码或增加超时时间")\r\n        except asyncio.CancelledError:\r\n            print("任务被取消，请检查代码")\r\n            info = traceback.format_exc()\r\n            print(f"info ={info}")\r\n        except Exception as e:\r\n            print(f"发生未知错误：{e}")\r\n\r\n        generations.append([Generation(text=text)])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'] = token_total\r\n        result = LLMResult(generations=generations, llm_output=llm_output)\r\n        return result\r\n\r\n\r\nclass MyEmbedding(Embeddings):\r\n\r\n    def __init__(self, path,max_length=8192, batch_size=256):\r\n        #self.model = AutoModel.from_pretrained(path, trust_remote_code=True).cuda()\r\n        self.model = FlagModel(path, query_instruction_for_retrieval="为这个句子生成表示以用于检索相关文章：")\r\n        #self.model = BGEM3FlagModel(path, map_location=\'cuda\')\r\n        self.max_length = max_length\r\n        self.batch_size = batch_size\r\n\r\n    def embed_documents(self, texts: List[str]) -> List[List[float]]:\r\n        return self.model.encode_corpus(texts, self.batch_size, self.max_length).tolist()\r\n\r\n    def embed_query(self, text: str) -> List[float]:\r\n        return self.model.encode_queries(text, self.batch_size, self.max_length).tolist()\r\n\r\n\r\n#数据\r\ndata_path = "/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa"\r\namnesty_qa = load_dataset("/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa")\r\n\r\n\r\n# MODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\nMODEL_PATH = \'/home/kelvin/nlp/model/LLM/Qwen/Qwen1.5-32B\'\r\nembed_model_path = \'/home/kelvin/nlp/model/Embedding/BAAI/bge-m3\'\r\n\r\n\r\nMODEL_PATH = \'/home/kelvin/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\nembedding_model = MyEmbedding(embed_model_path)\r\nmy_llm = MyLLM(MODEL_PATH)\r\n\r\n\r\nans_relevancy = AnswerRelevancy()\r\n\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n    \'contexts\' : [[\'The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'],\r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\']],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n}\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n# amnesty_qa["eval"],\r\nresult = evaluate(\r\n    dataset,\r\n    metrics=[context_recall, context_precision, ans_relevancy, faithfulness],\r\n    llm=my_llm,\r\n    embeddings=embedding_model,\r\n    raise_exceptions=True\r\n)\r\n\r\ndf = result.to_pandas()\r\nprint(df.head())\r\ndf.to_csv("result.csv", index=False)\r\n```\r\n\r\nHas anyone successfully tested the local model? I hope to receive everyone\'s help\r\nThanks\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1214/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1214/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1212',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1212/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1212/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1212/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1212',
  'id': 2480110874,
  'node_id': 'I_kwDOJgX1Gs6T030a',
  'number': 1212,
  'title': 'RuntimeError',
  'user': {'login': 'minglong-huang',
   'id': 75299100,
   'node_id': 'MDQ6VXNlcjc1Mjk5MTAw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/75299100?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/minglong-huang',
   'html_url': 'https: //github.com/minglong-huang',
   'followers_url': 'https: //api.github.com/users/minglong-huang/followers',
   'following_url': 'https: //api.github.com/users/minglong-huang/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/minglong-huang/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/minglong-huang/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/minglong-huang/subscriptions',
   'organizations_url': 'https: //api.github.com/users/minglong-huang/orgs',
   'repos_url': 'https: //api.github.com/users/minglong-huang/repos',
   'events_url': 'https: //api.github.com/users/minglong-huang/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/minglong-huang/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-08-22T08: 03: 21Z',
  'updated_at': '2024-08-22T12: 36: 42Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Here is my result：\r\n![image
            ](https: //github.com/user-attachments/assets/8926ce7f-17a0-490c-9ef2-912c59bbdb67)\r\n\r\nand my code：\r\n\r\n```\r\nimport typing as t\r\nimport asyncio\r\nfrom typing import List\r\nfrom datasets import load_dataset, load_from_disk\r\nfrom ragas.metrics import faithfulness, context_recall, context_precision\r\nfrom ragas.metrics import AnswerRelevancy\r\nfrom ragas import evaluate\r\nfrom ragas.llms import BaseRagasLLM\r\nfrom langchain.schema import LLMResult\r\nfrom langchain.schema import Generation\r\nfrom langchain.callbacks.base import Callbacks\r\nfrom langchain.schema.embeddings import Embeddings\r\nfrom transformers import AutoModel, AutoTokenizer\r\nfrom ragas.llms.prompt import PromptValue\r\nfrom llama_index.llms.ollama import Ollama\r\nfrom llama_index.core import Settings\r\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\r\nfrom FlagEmbedding import FlagModel\r\nfrom ragas.metrics import answer_relevancy\r\nfrom langchain_core.language_models import BaseLanguageModel\r\nfrom langchain_core.embeddings import Embeddings\r\nfrom ragas.llms import BaseRagasLLM\r\nfrom ragas.embeddings import BaseRagasEmbeddings\r\n\r\n\r\nclass MyLLM(BaseRagasLLM):\r\n\r\n    def __init__(self,llm_path):\r\n        self.tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\r\n        self.base_llm = AutoModel.from_pretrained(llm_path, trust_remote_code=True).cuda()\r\n        self.base_llm = self.base_llm.eval()\r\n\r\n    @property\r\n    def llm(self):\r\n        return self.base_llm\r\n\r\n    def get_llm_result(self, prompt):\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n        text, history = self.base_llm.chat(self.tokenizer, content, history=[])\r\n\r\n        generations.append([Generation(text=text)])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'] = token_total\r\n        return LLMResult(generations=generations, llm_output=llm_output)\r\n\r\n    def generate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str]] = None,\r\n            callbacks: Callbacks = [],\r\n    ):\r\n        result = self.get_llm_result(prompt)\r\n        return result\r\n\r\n    async def agenerate_text(\r\n            self,\r\n            prompt: PromptValue,\r\n            n: int = 1,\r\n            temperature: float = 1e-8,\r\n            stop: t.Optional[t.List[str]] = None,\r\n            callbacks: Callbacks = [],\r\n    ) -> LLMResult:\r\n        generations = []\r\n        llm_output = {}\r\n        token_total = 0\r\n        content = prompt.to_string()\r\n        text, history = await asyncio.get_event_loop().run_in_executor(None, self.base_llm.chat, self.tokenizer,\r\n                                                                       content, [])\r\n\r\n        generations.append([Generation(text=text)])\r\n        token_total += len(text)\r\n        llm_output[\'token_total\'] = token_total\r\n        result = LLMResult(generations=generations, llm_output=llm_output)\r\n        return result\r\n\r\n\r\nclass MyEmbedding(Embeddings):\r\n\r\n    def __init__(self, path,max_length=8192, batch_size=256):\r\n        # self.model = AutoModel.from_pretrained(llm_path, trust_remote_code=True).cuda()\r\n        self.model = FlagModel(path, query_instruction_for_retrieval="为这个句子生成表示以用于检索相关文章：")\r\n        self.max_length = max_length\r\n        self.batch_size = batch_size\r\n\r\n    def embed_documents(self, texts: List[str]) -> List[List[float]]:\r\n        return self.model.encode_corpus(texts, self.batch_size, self.max_length).tolist()\r\n\r\n    def embed_query(self, text: str) -> List[float]:\r\n        return self.model.encode_queries(text, self.batch_size, self.max_length).tolist()\r\n\r\n\r\n#数据\r\ndata_path = "/home/nlp/graphrag/eval_dataset/amnesty_qa"\r\namnesty_qa = load_dataset("/home/kelvin/nlp/graphrag/eval_dataset/amnesty_qa")\r\n\r\n\r\nMODEL_PATH = \'/home/nlp/model/LLM/THUDM/glm-4-9b-chat\'\r\nembed_model_path = \'/home/nlp/model/Embedding/BAAI/bge-m3\'\r\n\r\nembedding_model = MyEmbedding(embed_model_path)\r\nmy_llm = MyLLM(MODEL_PATH)\r\n\r\nans_relevancy = AnswerRelevancy()\r\n\r\nresult = evaluate(\r\n    amnesty_qa["eval"],\r\n    metrics=[context_recall, context_precision, ans_relevancy, faithfulness],\r\n    llm=my_llm,\r\n    embeddings=embedding_model\r\n\r\n)\r\n\r\ndf = result.to_pandas()\r\nprint(df.head())\r\ndf.to_csv("result.csv", index=False)\r\n\r\n```\r\n\r\nDataset source：https://huggingface.co/datasets/explodinggradients/amnesty_qa\r\n![image](https://github.com/user-attachments/assets/34807c73-9cf6-49b2-9ec6-b4e75ada7158)\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1212/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1212/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1211',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1211/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1211/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1211/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1211',
  'id': 2480083071,
  'node_id': 'I_kwDOJgX1Gs6T0xB_',
  'number': 1211,
  'title': 'Recalculation of Answers and Contexts in evaluate Function',
  'user': {'login': 'pds13193',
   'id': 147268569,
   'node_id': 'U_kgDOCMcj2Q',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/147268569?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/pds13193',
   'html_url': 'https: //github.com/pds13193',
   'followers_url': 'https: //api.github.com/users/pds13193/followers',
   'following_url': 'https: //api.github.com/users/pds13193/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/pds13193/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/pds13193/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/pds13193/subscriptions',
   'organizations_url': 'https: //api.github.com/users/pds13193/orgs',
   'repos_url': 'https: //api.github.com/users/pds13193/repos',
   'events_url': 'https: //api.github.com/users/pds13193/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/pds13193/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-08-22T07: 49: 28Z',
  'updated_at': '2024-08-26T14: 16: 51Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Context:** I am calling the evaluate function to calculate faithfulness and answer correctness. The dataset, which contains answer, context, question, and ground_truth, is passed as input. The evaluate function is defined in llama_index.py (path to file -> ragas/integrations).\r\n\r\n**Concern:** I noticed that inside the evaluate function, answers and contexts are recalculated for the user query and passed for evaluation. My main question is: why are the answers and contexts recalculated, and why are these recalculated values used for evaluation instead of the original answers and contexts generated by our model?\r\n\r\nIn my opinion, recalculating the answers and contexts and using them in the evaluation could lead to incorrect faithfulness and answer correctness scores. This might be a bug. Please clarify if this behavior is intentional or provide the reasoning behind it.\r\n\r\nBelow is a snapshot of the code in llama_index.py where the answers and contexts are recalculated:\r\n<img width="786" alt="image" src="https://github.com/user-attachments/assets/c893e52e-2766-4316-86bf-1e2bc3329fb5">\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1211/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1211/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1210',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1210/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1210/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1210/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1210',
  'id': 2480000710,
  'node_id': 'I_kwDOJgX1Gs6T0c7G',
  'number': 1210,
  'title': "cannot import name 'context_relevancy' from 'ragas.metrics' ",
  'user': {'login': 'Zabih-khan',
   'id': 126310221,
   'node_id': 'U_kgDOB4dXTQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/126310221?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Zabih-khan',
   'html_url': 'https: //github.com/Zabih-khan',
   'followers_url': 'https: //api.github.com/users/Zabih-khan/followers',
   'following_url': 'https: //api.github.com/users/Zabih-khan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Zabih-khan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Zabih-khan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Zabih-khan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Zabih-khan/orgs',
   'repos_url': 'https: //api.github.com/users/Zabih-khan/repos',
   'events_url': 'https: //api.github.com/users/Zabih-khan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Zabih-khan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  },
                  {'id': 6872728239,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaWCrw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/answered',
    'name': 'answered',
    'color': 'B9EF08',
    'default': False,
    'description': '🤖 The question has been answered. Will be closed automatically if no new comments'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 6,
  'created_at': '2024-08-22T07: 02: 52Z',
  'updated_at': '2024-08-31T13: 39: 03Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '```\r\n\r\nfrom ragas.metrics.critique import harmfulness\r\nfrom ragas import evaluate\r\n\r\nfrom ragas.metrics import (\r\n    answer_relevancy,\r\n    faithfulness,\r\n    context_recall,\r\n    context_precision,\r\n    context_relevancy,\r\n    answer_correctness,\r\n    answer_similarity\r\n)\r\n\r\n\r\n\r\ndef create_ragas_dataset(rag_pipeline, eval_dataset):\r\n  rag_dataset = []\r\n  for row in tqdm(eval_dataset):\r\n    answer = rag_pipeline.invoke({
                  "question": row[
                        "question"
                  ]
            })\r\n    rag_dataset.append(\r\n        {
                  "question": row[
                        "question"
                  ],\r\n         "answer": answer[
                        "response"
                  ].content,\r\n         "contexts": [context.page_content for context in answer[
                              "context"
                        ]
                  ],\r\n         "ground_truths": [row[
                              "ground_truth"
                        ]
                  ]\r\n
            }\r\n    )\r\n  rag_df = pd.DataFrame(rag_dataset)\r\n  rag_eval_dataset = Dataset.from_pandas(rag_df)\r\n  return rag_eval_dataset\r\n\r\ndef evaluate_ragas_dataset(ragas_dataset):\r\n  result = evaluate(\r\n    ragas_dataset,\r\n    metrics=[\r\n        context_precision,\r\n        faithfulness,\r\n        answer_relevancy,\r\n        context_recall,\r\n        context_relevancy,\r\n        answer_correctness,\r\n        answer_similarity\r\n
            ],\r\n  )\r\n  return result\r\n  \r\n```\r\n  \r\n  When i run the above code I give me this error.\r\n  \r\n  \r\n**ImportError: cannot import name \'context_relevancy\' from \'ragas.metrics\' (c:\\Users\\khan\\anaconda3\\Lib\\site-packages\\ragas\\metrics\\__init__.py)**\r\n  \r\n  ',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1210/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1210/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1208',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1208/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1208/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1208/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1208',
  'id': 2474489294,
  'node_id': 'I_kwDOJgX1Gs6TfbXO',
  'number': 1208,
  'title': 'Cannot generate synthetic data using documented code, gives error',
  'user': {'login': 'dividor',
   'id': 8402586,
   'node_id': 'MDQ6VXNlcjg0MDI1ODY=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/8402586?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/dividor',
   'html_url': 'https: //github.com/dividor',
   'followers_url': 'https: //api.github.com/users/dividor/followers',
   'following_url': 'https: //api.github.com/users/dividor/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/dividor/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/dividor/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/dividor/subscriptions',
   'organizations_url': 'https: //api.github.com/users/dividor/orgs',
   'repos_url': 'https: //api.github.com/users/dividor/repos',
   'events_url': 'https: //api.github.com/users/dividor/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/dividor/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-20T00: 24: 39Z',
  'updated_at': '2024-08-20T00: 26: 58Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[X
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nI am following [this RAGAs documentation](https://docs.ragas.io/en/stable/getstarted/testset_generation.html) to generate test data, but I get a module import error. \r\n\r\nRagas version: 0.1.14\r\nPython version: 3.11.4\r\n\r\n**Code to Reproduce**\r\nCode from RAGAs documentation ...\r\n\r\n```\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\n# generator with openai models\r\ngenerator_llm = ChatOpenAI(model="gpt-4o")\r\ncritic_llm = ChatOpenAI(model="gpt-4o")\r\nembeddings = OpenAIEmbeddings()\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\n# generate testset\r\ntestset = generator.generate_with_langchain_docs(docs, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\r\n```\r\n\r\n**Error trace**\r\n\r\n```\r\nImportError                               Traceback (most recent call last)\r\nCell In[59], [line 1](vscode-notebook-cell:?execution_count=59&line=1)\r\n----> [1](vscode-notebook-cell:?execution_count=59&line=1) from ragas.testset.generator import TestsetGenerator\r\n      [2](vscode-notebook-cell:?execution_count=59&line=2) from ragas.testset.evolutions import simple, reasoning, multi_context\r\n      [3](vscode-notebook-cell:?execution_count=59&line=3) from langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\nFile ~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/__init__.py:1\r\n----> [1](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/__init__.py:1) from ragas.testset.generator import TestsetGenerator\r\n      [3](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/__init__.py:3) __all__ = ["TestsetGenerator"]\r\n\r\nFile ~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:13\r\n     [10](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:10) from langchain_openai.chat_models import ChatOpenAI\r\n     [11](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:11) from langchain_openai.embeddings import OpenAIEmbeddings\r\n---> [13](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:13) from ragas._analytics import TestsetGenerationEvent, track, track_was_completed\r\n     [14](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:14) from ragas.embeddings.base import (\r\n     [15](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:15)     BaseRagasEmbeddings,\r\n     [16](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:16)     LangchainEmbeddingsWrapper,\r\n     [17](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:17)     LlamaIndexEmbeddingsWrapper,\r\n     [18](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:18) )\r\n     [19](https://file+.vscode-resource.vscode-cdn.net/Users/matthewharris/Desktop/git/llm_eval_research/~/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/testset/generator.py:19) from ragas.exceptions import ExceptionInRunner\r\n\r\nImportError: cannot import name \'TestsetGenerationEvent\' from \'ragas._analytics\' (/Users/matthewharris/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/_analytics.py)\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n```\r\n\r\n\r\n**Additional context**\r\nThanks!\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1208/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1208/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1207',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1207/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1207/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1207/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1207',
  'id': 2474481972,
  'node_id': 'I_kwDOJgX1Gs6TfZk0',
  'number': 1207,
  'title': "cannot import name 'context_precision' from 'ragas.metrics'",
  'user': {'login': 'dividor',
   'id': 8402586,
   'node_id': 'MDQ6VXNlcjg0MDI1ODY=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/8402586?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/dividor',
   'html_url': 'https: //github.com/dividor',
   'followers_url': 'https: //api.github.com/users/dividor/followers',
   'following_url': 'https: //api.github.com/users/dividor/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/dividor/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/dividor/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/dividor/subscriptions',
   'organizations_url': 'https: //api.github.com/users/dividor/orgs',
   'repos_url': 'https: //api.github.com/users/dividor/repos',
   'events_url': 'https: //api.github.com/users/dividor/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/dividor/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-20T00: 17: 15Z',
  'updated_at': '2024-08-20T00: 19: 30Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[X ] I have checked the [documentation](https://docs.ragas.io/) and related resources and couldn't resolve my bug.\r\n\r\n**Describe the bug**\r\nI am trying to follow [this](https://docs.ragas.io/en/stable/getstarted/evaluation.html) documentation, but it doesn't work because `context_precision` seems to be missing. \r\n\r\nRagas version: ragas-0.1.14\r\nPython version: 3.11.4\r\n\r\n**Code to Reproduce**\r\nThe code from Ragas' documentation ...\r\n\r\n```\r\nfrom ragas.metrics import (\r\n    answer_relevancy,\r\n    faithfulness,\r\n    context_recall,\r\n    context_precision,\r\n)\r\n\r\n```\r\n**Error trace**\r\n\r\n```\r\nCell In[52], [line 1](vscode-notebook-cell:?execution_count=52&line=1)\r\n----> [1](vscode-notebook-cell:?execution_count=52&line=1) from ragas.metrics import (\r\n      [2](vscode-notebook-cell:?execution_count=52&line=2)     faithfulness,\r\n      [3](vscode-notebook-cell:?execution_count=52&line=3)     answer_relevancy,\r\n      [4](vscode-notebook-cell:?execution_count=52&line=4)     context_precision,\r\n      [5](vscode-notebook-cell:?execution_count=52&line=5)     context_recall,\r\n      [6](vscode-notebook-cell:?execution_count=52&line=6) )\r\n\r\nImportError: cannot import name 'context_precision' from 'ragas.metrics' (/Users/ME/opt/miniconda3/envs/eval_demo/lib/python3.11/site-packages/ragas/metrics/__init__.py)\r\n```\r\n\r\n\r\n**Expected behavior**\r\nThe documented code should work. \r\n\r\n\r\n**Additional context**\r\nRAGAs is great, thanks!\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don't worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1207/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1207/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1206',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1206/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1206/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1206/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1206',
  'id': 2474369284,
  'node_id': 'I_kwDOJgX1Gs6Te-EE',
  'number': 1206,
  'title': 'Failed to parse output. Returning None.',
  'user': {'login': 'surengunturuamazon',
   'id': 143133277,
   'node_id': 'U_kgDOCIgKXQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/143133277?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/surengunturuamazon',
   'html_url': 'https: //github.com/surengunturuamazon',
   'followers_url': 'https: //api.github.com/users/surengunturuamazon/followers',
   'following_url': 'https: //api.github.com/users/surengunturuamazon/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/surengunturuamazon/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/surengunturuamazon/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/surengunturuamazon/subscriptions',
   'organizations_url': 'https: //api.github.com/users/surengunturuamazon/orgs',
   'repos_url': 'https: //api.github.com/users/surengunturuamazon/repos',
   'events_url': 'https: //api.github.com/users/surengunturuamazon/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/surengunturuamazon/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-19T22: 39: 22Z',
  'updated_at': '2024-08-19T22: 41: 39Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[ X
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nWhen calling evaluate on Ragas using AWS Bedrock, there are some examples that give the warning: "Failed to parse output. Returning None." and error: "__root__ -> 1 -> reason\r\n  field required (type=value_error.missing)" for a few examples. \r\n\r\nRagas version: 0.1.13\r\nPython version: 3.10.14\r\n\r\n**Code to Reproduce**\r\nfrom langchain_community.chat_models import BedrockChat\r\nfrom langchain_community.embeddings import BedrockEmbeddings\r\nfrom datasets import load_dataset\r\n\r\namnesty_qa = load_dataset("explodinggradients/amnesty_qa", "english_v2")\r\n\r\nconfig = {\r\n    "region_name": "us-east-1",  # E.g. "us-east-1"\r\n    "model_id": \'anthropic.claude-3-haiku-20240307-v1:0\',  # E.g "anthropic.claude-v2"\r\n    "model_kwargs": {"temperature": 0.4},\r\n}\r\n\r\nbedrock_model = BedrockChat(\r\n    region_name=config["region_name"],\r\n    endpoint_url=f"https://bedrock-runtime.{config[\'region_name\']}.amazonaws.com",\r\n    model_id=config["model_id"],\r\n    model_kwargs=config["model_kwargs"],\r\n)\r\n\r\n\r\nbedrock_embeddings = BedrockEmbeddings(\r\n    region_name=config["region_name"],\r\n)\r\n\r\nfrom ragas import evaluate\r\nimport nest_asyncio  # CHECK NOTES\r\n\r\nnest_asyncio.apply()\r\n\r\nresult = evaluate(\r\n    amnesty_qa["eval"],\r\n    metrics=metrics,\r\n    llm=bedrock_model,\r\n    embeddings=bedrock_embeddings,\r\n)\r\n\r\nresult\r\n\r\n**Error trace**\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nException raised in Job[34]: ValidationError(2 validation errors for ContextPrecisionVerifications\r\n__root__ -> 1 -> reason\r\n  field required (type=value_error.missing)\r\n__root__ -> 1 -> verdict\r\n  field required (type=value_error.missing))\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\n\r\nThe above is for a subset of 20 examples that are evaluated. \r\n\r\n**Expected behavior**\r\nNone of the warnings above should come\r\n\r\n\r\n**Additional context**\r\nThis error/warning doesn\'t stop execution and a lot of examples do get evaluated smoothly. It is just that some examples can\'t be evaluated and results in a NaN value for the metric. \r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1206/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1206/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1205',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1205/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1205/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1205/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1205',
  'id': 2473091985,
  'node_id': 'I_kwDOJgX1Gs6TaGOR',
  'number': 1205,
  'title': 'Can Custom Metrics be added?',
  'user': {'login': 'LDelPinoNT',
   'id': 141906251,
   'node_id': 'U_kgDOCHVRSw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/141906251?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/LDelPinoNT',
   'html_url': 'https: //github.com/LDelPinoNT',
   'followers_url': 'https: //api.github.com/users/LDelPinoNT/followers',
   'following_url': 'https: //api.github.com/users/LDelPinoNT/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/LDelPinoNT/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/LDelPinoNT/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/LDelPinoNT/subscriptions',
   'organizations_url': 'https: //api.github.com/users/LDelPinoNT/orgs',
   'repos_url': 'https: //api.github.com/users/LDelPinoNT/repos',
   'events_url': 'https: //api.github.com/users/LDelPinoNT/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/LDelPinoNT/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 6,
  'created_at': '2024-08-19T11: 07: 31Z',
  'updated_at': '2024-08-19T12: 16: 26Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[x] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nwhat is unclear to you? What would you like to know?\r\nCan I add custom metrics? I didn't find information related to it. \r\n\r\n\r\n**Additional context**\r\nAnything else you want to share with us? \r\nI'm thinking in creating a metric to reflect how many times the input and the response are in the same language. \r\n\r\nThank you!",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1205/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1205/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1204',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1204/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1204/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1204/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/1204',
  'id': 2469930970,
  'node_id': 'PR_kwDOJgX1Gs54j4ge',
  'number': 1204,
  'title': 'Fix ensure_ascii for json.dumps',
  'user': {'login': 'ifsheldon',
   'id': 39153080,
   'node_id': 'MDQ6VXNlcjM5MTUzMDgw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/39153080?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ifsheldon',
   'html_url': 'https: //github.com/ifsheldon',
   'followers_url': 'https: //api.github.com/users/ifsheldon/followers',
   'following_url': 'https: //api.github.com/users/ifsheldon/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ifsheldon/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ifsheldon/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ifsheldon/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ifsheldon/orgs',
   'repos_url': 'https: //api.github.com/users/ifsheldon/repos',
   'events_url': 'https: //api.github.com/users/ifsheldon/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ifsheldon/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745915,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uouw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:S',
    'name': 'size:S',
    'color': '77b800',
    'default': False,
    'description': 'This PR changes 10-29 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-08-16T09: 58: 18Z',
  'updated_at': '2024-08-16T09: 58: 22Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/1204',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/1204',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/1204.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/1204.patch',
   'merged_at': None
            },
  'body': 'Hi! This PR simply fixes all `json.dumps`. With `ensure_ascii=False`, unicodes can be properly serialized into JSON files in the modern days when UTF-8 is basically universal. This may also prevent silent behavioral bugs from LLMs, since they can hardly understand literal strings like "\\u00x" except common ones.\r\n\r\nSome cases do not necessarily need `ensure_ascii=False`, but they are added for consistency.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1204/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1204/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1199',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1199/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1199/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1199/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1199',
  'id': 2467504489,
  'node_id': 'I_kwDOJgX1Gs6TEyFp',
  'number': 1199,
  'title': 'Manually translate prompts from English to Chinese',
  'user': {'login': 'Xiyuche',
   'id': 81409168,
   'node_id': 'MDQ6VXNlcjgxNDA5MTY4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/81409168?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Xiyuche',
   'html_url': 'https: //github.com/Xiyuche',
   'followers_url': 'https: //api.github.com/users/Xiyuche/followers',
   'following_url': 'https: //api.github.com/users/Xiyuche/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Xiyuche/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Xiyuche/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Xiyuche/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Xiyuche/orgs',
   'repos_url': 'https: //api.github.com/users/Xiyuche/repos',
   'events_url': 'https: //api.github.com/users/Xiyuche/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Xiyuche/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 7,
  'created_at': '2024-08-15T06: 36: 36Z',
  'updated_at': '2024-08-22T10: 46: 14Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '- [x
            ] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Question**\r\nHi. I\'ve tried language adaptation, it works totally fine the first time. But after that I received many different errors when the adaptor is trying to load the cached json files.\r\n\r\nSo I decide to use gpt-4o to translate all the english prompt content in `src/ragas/testset/prompts.py` to chinese , like this. I\'m not very familiar with the project code, so I\'m not sure about the effect, but the testset result seems to be fine.\r\n\r\n- Will this work properly?\r\n- Could this cause any unexpected issues? \r\n- Is there anything else I should translate?\r\n\r\nNo need to worry about the chinese content if you cant read, I\'ve manually checked the translated content, they are all good.\r\n\r\n**Code Examples**\r\n```python\r\n\r\nfrom langchain_core.pydantic_v1 import BaseModel\r\n\r\nfrom ragas.llms.output_parser import RagasoutputParser, get_json_format_instructions\r\nfrom ragas.llms.prompt import Prompt\r\n\r\n\r\nclass AnswerFormat(BaseModel):\r\n    answer: str\r\n    verdict: int\r\n\r\n\r\nquestion_answer_parser = RagasoutputParser(pydantic_object=AnswerFormat)\r\n\r\n\r\nreasoning_question_prompt = Prompt(\r\n    name="reasoning_question",\r\n    instruction="""将给定的问题复杂化，通过改写问题将其转化为基于提供的上下文的多跳推理问题。\r\n    回答问题应要求读者使用给定上下文中的信息进行多个逻辑连接或推断。\r\n    重写问题时要遵循以下规则：\r\n    1. 确保重写后的问题可以完全从上下文中提供的信息中得到答案。\r\n    2. 不要构建包含超过15个单词的问题。尽可能使用缩写。\r\n    3. 确保问题清晰且明确。\r\n    4. 像“基于提供的上下文”，“根据上下文”等短语不能出现在问题中。""",\r\n    examples=[\r\n        {\r\n            "question": "法国的首都是哪里？",\r\n            "context": "法国是西欧的一个国家。它有几个城市，包括巴黎、里昂和马赛。巴黎不仅以埃菲尔铁塔和卢浮宫等文化地标闻名，还作为行政中心。",\r\n            "output": "将埃菲尔铁塔与行政中心联系起来，哪个城市同时具备这两者？",\r\n        },\r\n        {\r\n            "question": "Python中的append()方法有什么作用？",\r\n            "context": "在Python中，列表用于在一个变量中存储多个项目。列表是4种内置数据类型之一，用于存储数据集合。append()方法将一个项目添加到列表的末尾。",\r\n            "output": "如果一个列表代表一个可变的集合，哪个方法可以将其扩展一个项目？",\r\n        },\r\n    ],\r\n    input_keys=["question", "context"],\r\n    output_key="output",\r\n    output_type="str",\r\n    language="english",\r\n)\r\n\r\n\r\nmulti_context_question_prompt = Prompt(\r\n    name="multi_context_question",\r\n    instruction="""\r\n    任务是改写并复杂化给定的问题，使得回答它需要从context1和context2中获得信息。\r\n    重写问题时遵循以下规则：\r\n        1. 重写的问题不应过长。尽可能使用缩写。\r\n        2. 重写的问题必须合理，并且能够被人类理解和回答。\r\n        3. 重写的问题必须能够从context1和context2中提供的信息中完全得到答案。\r\n        4. 阅读并理解这两个上下文，重写问题，使回答需要结合context1和context2中的见解。\r\n        5. 短语如“基于提供的上下文”，“根据上下文”等不允许出现在问题中。""",\r\n    examples=[\r\n        {\r\n            "question": "是什么过程使植物变绿？",\r\n            "context1": "叶绿素是使植物呈现绿色的色素，并帮助它们进行光合作用。",\r\n            "context2": "植物的光合作用通常发生在叶子中，叶绿体在此集中。",\r\n            "output": "在哪些植物结构中，负责其绿色的色素促进了能量生产？",\r\n        },\r\n        {\r\n            "question": "如何计算矩形的面积？",\r\n            "context1": "形状的面积根据其尺寸计算。对于矩形，这涉及到将长度和宽度相乘。",\r\n            "context2": "矩形有四条边，相对的两边长度相等。它们是一种四边形。",\r\n            "output": "哪个涉及相对相等的乘积产生四边形的面积？",\r\n        },\r\n    ],\r\n    input_keys=["question", "context1", "context2"],\r\n    output_key="output",\r\n    output_type="str",\r\n    language="english",\r\n)\r\n\r\nconditional_question_prompt = Prompt(\r\n    name="conditional_question",\r\n    instruction="""通过引入条件元素来增加提供的问题的复杂性。\r\n    目标是通过加入一个影响问题背景的场景或条件，使问题更加复杂。\r\n    重写问题时遵循以下规则：\r\n        1. 重写后的问题不应超过25个字。尽可能使用缩写。\r\n        2. 重写的问题必须合理，并且能够被人类理解和回答。\r\n        3. 重写的问题必须能够从提供的上下文中完全得到答案。\r\n        4. 短语如“提供的上下文”，“根据上下文”等不允许出现在问题中。""",\r\n    examples=[\r\n        {\r\n            "question": "植物根部的功能是什么？",\r\n            "context": "植物的根部从土壤中吸收水分和养分，将植物固定在地面上，并储存食物。",\r\n            "output": "植物根部在土壤养分和稳定性方面的双重作用是什么？",\r\n        },\r\n        {\r\n            "question": "疫苗如何预防疾病？",\r\n            "context": "疫苗通过刺激身体的免疫反应产生抗体，这些抗体识别并对抗病原体，从而预防疾病。",\r\n            "output": "疫苗如何利用身体的免疫系统来防御病原体？",\r\n        },\r\n    ],\r\n    input_keys=["question", "context"],\r\n    output_key="output",\r\n    output_type="str",\r\n    language="english",\r\n)\r\n\r\ncompress_question_prompt = Prompt(\r\n    name="compress_question",\r\n    instruction="""重写以下问题，使其更间接并更短，同时保持原问题的本质。\r\n    目标是创造一个传达相同含义但表达更间接的问题。重写后的问题应更短，因此尽可能使用缩写。""",\r\n    examples=[\r\n        {\r\n            "question": "地球与月球之间的距离是多少？",\r\n            "output": "月球离地球多远？",\r\n        },\r\n        {\r\n            "question": "制作巧克力蛋糕需要哪些原料？",\r\n            "output": "制作巧克力蛋糕需要什么？",\r\n        },\r\n    ],\r\n    input_keys=["question"],\r\n    output_key="output",\r\n    output_type="str",\r\n    language="english",\r\n)\r\n\r\nconversational_question_prompt = Prompt(\r\n    name="conversation_question",\r\n    instruction="""将提供的问题重新格式化为两个独立的问题，就像它们是对话的一部分一样。每个问题都应专注于原问题的特定方面或子主题。\r\n    重写问题时遵循以下规则：\r\n        1. 重写的问题不应超过25个字。尽可能使用缩写。\r\n        2. 重写的问题必须合理，并且能够被人类理解和回答。\r\n        3. 重写的问题必须能够从提供的上下文中完全得到答案。\r\n        4. 短语如“提供的上下文”，“根据上下文”等不允许出现在问题中。""",\r\n    examples=[\r\n        {\r\n            "question": "远程工作的优点和缺点是什么？",\r\n            "output": {\r\n                "first_question": "远程工作的好处是什么？",\r\n                "second_question": "反过来，远程工作有哪些挑战？",\r\n            },\r\n        }\r\n    ],\r\n    input_keys=["question"],\r\n    output_key="output",\r\n    output_type="json",\r\n    language="english",\r\n)\r\n\r\nquestion_answer_prompt = Prompt(\r\n    name="answer_formulate",\r\n    instruction="""使用给定的上下文信息回答问题。如果答案在上下文中存在，输出结果为 \'1\'，如果答案不存在，输出结果为 \'-1\'。""",\r\n    output_format_instruction=get_json_format_instructions(AnswerFormat),\r\n    examples=[\r\n        {\r\n            "context": """气候变化受到人类活动的显著影响，特别是化石燃料燃烧产生的温室气体排放。这些温室气体在大气中的浓度增加，导致更多的热量被困，进而导致全球变暖和气候模式的变化。""",\r\n            "question": "人类活动如何影响气候变化？",\r\n            "answer": AnswerFormat.parse_obj(\r\n                {\r\n                    "answer": "人类活动通过化石燃料燃烧产生的温室气体排放对气候变化产生影响。这些排放增加了大气中的温室气体浓度，导致更多的热量被困，引起全球变暖和气候模式的变化。",\r\n                    "verdict": "1",\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "context": """人工智能（AI）的概念随着时间的推移不断发展，但基本上是指旨在模拟人类认知功能的机器。AI能够学习、推理、感知，并在某些情况下像人类一样做出反应，这使得它在从医疗到自动驾驶汽车等领域具有重要意义。""",\r\n            "question": "人工智能的关键能力是什么？",\r\n            "answer": AnswerFormat.parse_obj(\r\n                {\r\n                    "answer": "人工智能旨在模拟人类认知功能，其关键能力包括学习、推理、感知和对环境的反应。这些能力使AI在医疗和自动驾驶等各个领域中具有重要作用。",\r\n                    "verdict": "1",\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "context": """简·奥斯汀的小说《傲慢与偏见》围绕角色伊丽莎白·班纳特及其家庭展开。故事发生在19世纪的英国乡村，涉及婚姻、道德和误解等问题。""",\r\n            "question": "《傲慢与偏见》是什么年份出版的？",\r\n            "answer": AnswerFormat.parse_obj(\r\n                {\r\n                    "answer": "给定问题的答案不在上下文中。",\r\n                    "verdict": "-1",\r\n                }\r\n            ).dict(),\r\n        },\r\n    ],\r\n    input_keys=["context", "question"],\r\n    output_key="answer",\r\n    output_type="json",\r\n    language="english",\r\n)\r\n\r\nkeyphrase_extraction_prompt = Prompt(\r\n    name="keyphrase_extraction",\r\n    instruction="从提供的文本中提取出最重要和最独特的3到5个关键词。",\r\n    examples=[\r\n        {\r\n            "text": "黑洞是时空中的一个区域，那里重力强大到没有任何物质，包括光和其他电磁波，能够逃脱。广义相对论预测，足够紧凑的质量可以扭曲时空形成黑洞。",\r\n            "output": {\r\n                "keyphrases": [\r\n                    "黑洞",\r\n                    "时空区域",\r\n                    "强大重力",\r\n                    "光和电磁波",\r\n                    "广义相对论",\r\n                ]\r\n            },\r\n        },\r\n        {\r\n            "text": "中国的长城是一系列古代城墙和防御工事，位于中国北部，建于大约500年前。这座巨大的城墙绵延13000多英里，是古代中国工程师技能和毅力的见证。",\r\n            "output": {\r\n                "keyphrases": [\r\n                    "中国长城",\r\n                    "古代防御工事",\r\n                    "中国北部",\r\n                ]\r\n            },\r\n        },\r\n    ],\r\n    input_keys=["text"],\r\n    output_key="output",\r\n    output_type="json",\r\n)\r\n\r\nseed_question_prompt = Prompt(\r\n    name="seed_question",\r\n    instruction="生成一个可以从给定上下文中完全回答的问题。问题应围绕主题形成。",\r\n    examples=[\r\n        {\r\n            "context": "植物的光合作用涉及将光能转化为化学能，利用叶绿素和其他色素吸收光。这一过程对植物生长和氧气的产生至关重要。",\r\n            "keyphrase": "光合作用",\r\n            "question": "光合作用在植物生长中有什么作用？",\r\n        },\r\n        {\r\n            "context": "工业革命始于18世纪，是历史上的一个重大转折点，因为它导致了工厂的发展和城市化。",\r\n            "keyphrase": "工业革命",\r\n            "question": "工业革命如何成为历史上的一个重大转折点？",\r\n        },\r\n        {\r\n            "context": "蒸发过程在水循环中起着至关重要的作用，将水从液态转化为蒸汽，并使其上升到大气中。",\r\n            "keyphrase": "蒸发",\r\n            "question": "为什么蒸发在水循环中很重要？",\r\n        },\r\n    ],\r\n    input_keys=["context", "keyphrase"],\r\n    output_key="question",\r\n    output_type="str",\r\n)\r\n\r\n\r\nmain_topic_extraction_prompt = Prompt(\r\n    name="main_topic_extraction",\r\n    instruction="识别并提取给定文本中深入讨论的两个主要主题。",\r\n    examples=[\r\n        {\r\n            "text": "区块链技术提供了一个去中心化的分类账，确保数据交易的完整性和透明度。它支持比特币等加密货币，提供了一个安全且不可变的所有交易记录。除了金融领域，区块链在供应链管理中也具有潜在应用，它可以简化操作，增强可追溯性，并提高欺诈预防能力。它允许实时跟踪货物和透明共享数据。",\r\n            "output": {\r\n                "topics": [\r\n                    "区块链技术及其在加密货币中的基础作用",\r\n                    "区块链在供应链管理中的应用",\r\n                ]\r\n            },\r\n        },\r\n        {\r\n            "text": "远程医疗革命了医疗服务的提供方式，特别是在农村和服务不足的地区。它允许患者通过视频会议与医生进行咨询，改善了医疗服务的可及性，减少了旅行的需要。医疗领域的另一个重大进步是精准医疗，它根据个体的基因概况定制治疗方法。这一方法已经为多种疾病，包括某些癌症和慢性病，提供了更有效的疗法。",\r\n            "output": {\r\n                "topics": [\r\n                    "远程医疗及其对医疗服务可及性的影响",\r\n                    "精准医疗及其在根据基因定制治疗中的作用",\r\n                ]\r\n            },\r\n        },\r\n    ],\r\n    input_keys=["text"],\r\n    output_key="output",\r\n    output_type="json",\r\n)\r\n\r\n\r\nfind_relevant_context_prompt = Prompt(\r\n    name="find_relevant_context",\r\n    instruction="给定一个问题和一组上下文，找出最相关的上下文来回答该问题。",\r\n    examples=[\r\n        {\r\n            "question": "法国的首都是哪里？",\r\n            "contexts": [\r\n                "1. 法国是西欧的一个国家。它有几个城市，包括巴黎、里昂和马赛。巴黎不仅以埃菲尔铁塔和卢浮宫等文化地标闻名，还作为行政中心。",\r\n                "2. 法国的首都是巴黎。它也是法国人口最多的城市，拥有超过200万人口。巴黎以埃菲尔铁塔和卢浮宫等文化地标而闻名。",\r\n                "3. 巴黎是法国的首都。它也是法国人口最多的城市，拥有超过200万人口。巴黎以埃菲尔铁塔和卢浮宫等文化地标而闻名。",\r\n            ],\r\n            "output": {\r\n                "relevant_contexts": [1, 2],\r\n            },\r\n        },\r\n        {\r\n            "question": "咖啡因如何影响身体？它的常见来源是什么？",\r\n            "contexts": [\r\n                "1. 咖啡因是一种中枢神经系统兴奋剂。它可以暂时抵抗困倦并恢复警觉。它主要影响大脑，在那里它改变神经递质的功能。",\r\n                "2. 定期的体育活动对保持健康至关重要。它可以帮助控制体重，抵抗健康问题，提高能量，并促进更好的睡眠。",\r\n                "3. 咖啡因的常见来源包括咖啡、茶、可乐和能量饮料。这些饮品在全球范围内被消费，以提供快速的能量提升。",\r\n            ],\r\n            "output": {"relevant_contexts": [1, 2]},\r\n        },\r\n    ],\r\n    input_keys=["question", "contexts"],\r\n    output_key="output",\r\n    output_type="json",\r\n    language="english",\r\n)\r\n\r\n\r\nquestion_rewrite_prompt = Prompt(\r\n    name="rewrite_question",\r\n    instruction="""给定上下文、问题和反馈，基于提供的反馈重写问题以提高其清晰度和可回答性。""",\r\n    examples=[\r\n        {\r\n            "context": "埃菲尔铁塔使用铁建造，最初是为1889年巴黎世博会的临时展品。尽管最初的目的是临时的，埃菲尔铁塔迅速成为巴黎巧思的象征，并成为这个城市的标志性地标，每年吸引数百万游客。这座塔的设计由古斯塔夫·埃菲尔创作，最初受到一些法国艺术家和知识分子的批评，但后来被誉为结构工程和建筑设计的杰作。",\r\n            "question": "谁设计了这座塔？",\r\n            "feedback": "问题询问了\'这座塔\'的设计者，但没有具体说明是哪座塔。世界上有许多塔，如果不明确说明是哪一座塔，问题就显得不清晰且无法回答。为了改进问题，应包括塔的名称或对特定塔的清晰描述。",\r\n            "output": "谁设计了埃菲尔铁塔？",\r\n        },\r\n        {\r\n            "context": "\'探索神经网络中的零样本学习\'由Smith和Lee于2021年发表，重点讨论了零样本学习技术在人工智能中的应用。",\r\n            "question": "在这项研究中，用于零样本评估的数据集是什么？",\r\n            "feedback": "问题询问了用于零样本评估的\'这项研究\'的数据集，但没有具体说明或提供任何关于这项研究的细节。这使得对不了解具体研究的人来说问题显得不清晰。为了提高清晰度和可回答性，问题应明确说明它所指的研究，或提供足够的研究背景，以便问题能够独立理解和回答。",\r\n            "output": "在探索神经网络中的零样本学习论文中，使用了哪些数据集进行零样本评估？",\r\n        },\r\n    ],\r\n    input_keys=["context", "question", "feedback"],\r\n    output_key="output",\r\n    output_type="str",\r\n    language="english",\r\n)\r\n\r\n### Filters\r\n\r\n\r\nclass ContextScoring(BaseModel):\r\n    clarity: int\r\n    depth: int\r\n    structure: int\r\n    relevance: int\r\n\r\n\r\nclass QuestionFilter(BaseModel):\r\n    feedback: str\r\n    verdict: int\r\n\r\n\r\nclass EvolutionElimination(BaseModel):\r\n    reason: str\r\n    verdict: int\r\n\r\n\r\ncontext_scoring_parser = RagasoutputParser(pydantic_object=ContextScoring)\r\nquestion_filter_parser = RagasoutputParser(pydantic_object=QuestionFilter)\r\nevolution_elimination_parser = RagasoutputParser(pydantic_object=EvolutionElimination)\r\n\r\ncontext_scoring_prompt = Prompt(\r\n    name="score_context",\r\n    instruction="""\r\n    给定一个上下文，执行以下任务并以有效的JSON格式输出答案：评估所提供的上下文，并为以下每个标准分配1（低）、2（中）或3（高）的分数：\r\n\r\n清晰度：评估所呈现信息的准确性和易懂性。高分（3）留给信息准确且易懂的上下文。低分（1）则适用于信息模糊或难以理解的上下文。\r\n深度：确定上下文中详细检查的程度以及创新见解的包含程度。高分表示全面且有见解的分析，而低分则表示对主题的表面处理。\r\n结构：评估内容的组织程度及其逻辑性。高分会颁发给展示出有条理且逻辑进展的上下文，而低分则表明结构或逻辑进展缺乏。\r\n相关性：判断内容与主题的相关性，高分颁发给紧密聚焦于主题且没有不必要插曲的上下文，低分则给充满不相关信息的上下文。\r\n将您的JSON输出结构化，以这些标准为键，其对应的分数为值。\r\n    """,\r\n    output_format_instruction=get_json_format_instructions(ContextScoring),\r\n    examples=[\r\n        {\r\n            "context": "勾股定理是几何中的一个基本原理。它指出，在直角三角形中，斜边（直角对边）的长度的平方等于其他两边长度的平方之和。这可以表示为a^2 + b^2 = c^2，其中c表示斜边的长度，a和b表示其他两边的长度。",\r\n            "output": ContextScoring.parse_obj(\r\n                {"clarity": 3, "depth": 1, "structure": 3, "relevance": 3}\r\n            ).dict(),\r\n        },\r\n        {\r\n            "context": "阿尔伯特·爱因斯坦（1879年3月14日-1955年4月18日）是德国出生的理论物理学家，广泛被认为是有史以来最伟大和最有影响力的科学家之一。",\r\n            "output": ContextScoring.parse_obj(\r\n                {"clarity": 3, "depth": 2, "structure": 3, "relevance": 3}\r\n            ).dict(),\r\n        },\r\n        {\r\n            "context": "我爱巧克力。它真的很美味。哦，顺便说一句，地球围绕太阳运行，而不是相反。此外，我最喜欢的颜色是蓝色。",\r\n            "output": ContextScoring.parse_obj(\r\n                {"clarity": 2, "depth": 1, "structure": 1, "relevance": 1}\r\n            ).dict(),\r\n        },\r\n    ],\r\n    input_keys=["context"],\r\n    output_key="output",\r\n    output_type="json",\r\n    language="english",\r\n)\r\n\r\n\r\nfilter_question_prompt = Prompt(\r\n    name="filter_question",\r\n    instruction="""\r\n根据以下标准评估给定问题的清晰度和可回答性：\r\n1.独立性：问题是否可以在不需要额外的上下文或外部引用的情况下理解和回答？问题应当是自足的，意味着它不依赖于特定文档、表格或未提供的先验知识。\r\n2.明确意图：问题的类型或信息需求是否明确？问题应清楚地传达其目的，没有歧义，从而允许直接且相关的回应。\r\n根据这些标准，如果问题具体、独立且意图明确，使其可以根据提供的细节理解和回答，则分配“1”的裁决。如果由于模糊性、依赖外部引用或意图不明确而不符合这些标准之一，则分配“0”。\r\n以JSON格式提供反馈和裁决，如果问题被认为不清楚，请提供改进建议。突出问题清晰度或缺乏清晰度的方面，并提出如何重新构架或详细说明以便更好地理解和回答的建议。\r\n""",\r\n    output_format_instruction=get_json_format_instructions(QuestionFilter),\r\n    examples=[\r\n        {\r\n            "question": "关于太空的发现是什么？",\r\n            "output": QuestionFilter.parse_obj(\r\n                {\r\n                    "feedback": "问题太模糊且过于广泛，询问\'关于太空的发现\'，而没有指定任何特定的方面、时间框架或感兴趣的上下文。这可能涉及从新天体的发现到太空旅行技术的进步等广泛话题。为了提高清晰度和可回答性，问题可以具体化，明确发现的类型（如天文学、技术）、时间框架（如近期、历史），或上下文（如在特定研究或太空任务中）。",\r\n                    "verdict": "0",\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "question": "根据context1和context2中的结果，ALMA-13B-R在WMT\'23研究中与其他翻译模型相比表现如何？",\r\n            "output": QuestionFilter.parse_obj(\r\n                {\r\n                    "feedback": "该问题询问ALMA-13B-R模型在WMT\'23研究中与其他翻译模型的表现对比，特别是指代context1和context2中的结果。尽管它明确指定了感兴趣的模型（ALMA-13B-R）和研究（WMT\'23），但它假设了解并理解“context1”和“context2”，而没有解释这些上下文包含的内容。这使得不熟悉WMT\'23研究或这些特定上下文的人难以理解该问题。为了让更广泛的受众更清楚和可回答，问题可以通过定义或描述\'context1\'和\'context2\'或解释这些上下文中用于比较的标准来改进。",\r\n                    "verdict": "0",\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "question": "KIWI-XXL和XCOMET与表1中的金标准参考相比，在评估得分、翻译模型性能和超越参考的成功率方面表现如何？",\r\n            "output": QuestionFilter.parse_obj(\r\n                {\r\n                    "feedback": "该问题请求KIWI-XXL和XCOMET模型与\'表1\'中的金标准参考的比较，侧重于评估得分、翻译模型性能和超越参考的成功率。它明确指定了模型和比较标准，意图清晰。然而，该问题假设可以访问“表1”，而没有提供其内容或上下文，使得没有直接访问源材料的人难以理解。为了更清楚和更广泛的受众可回答，问题可以包括“表1”的内容或关键发现的简要描述，或者以不依赖特定、未公开文件的方式构架问题。",\r\n                    "verdict": 0,\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "question": "UL2训练目标在OpenMoE中的配置是什么？为什么它是预训练的更好选择？",\r\n            "output": QuestionFilter.parse_obj(\r\n                {\r\n                    "feedback": "该问题询问OpenMoE框架中UL2训练目标的配置以及其在预训练中适用性的原因。它明确指定了感兴趣的主题（UL2训练目标，OpenMoE），并寻求关于配置和其有效性原因的详细信息。然而，对于不熟悉特定术语或OpenMoE和UL2背景的人来说，问题可能具有挑战性。为了更广泛的清晰度和可回答性，问题可以通过包括关于OpenMoE和UL2训练目标的简要解释或背景，或澄清其提到的预训练有效性的方面（如效率、准确性、泛化）来改进。",\r\n                    "verdict": 1,\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "question": "基于提供的上下文，OpenMoE中UL2训练目标的详细配置是什么？",\r\n            "output": QuestionFilter.parse_obj(\r\n                {\r\n                    "feedback": "该问题要求在OpenMoE框架中详细描述UL2训练目标的配置，并提到“提供的上下文”，但在查询中实际上并未包含或描述该上下文。这使得对那些没有访问到未指定上下文的人来说问题显得不清晰。为了使问题清晰且可回答，需要在问题中直接包含相关上下文或以不需要外部信息的方式构架问题。详细说明感兴趣的配置方面（如损失函数、数据增强技术）也可以帮助澄清查询。",\r\n                    "verdict": 0,\r\n                }\r\n            ).dict(),\r\n        },\r\n    ],\r\n    input_keys=["question"],\r\n    output_key="output",\r\n    output_type="json",\r\n    language="english",\r\n)\r\n\r\nevolution_elimination_prompt = Prompt(\r\n    name="evolution_elimination",\r\n    instruction="""检查给定的两个问题是否符合以下要求：\r\n    1. 它们具有相同的约束和要求。\r\n    2. 它们具有相同的深度和广度的探究。\r\n    如果它们相等，输出裁决为1，如果不相等，则为0。""",\r\n    output_format_instruction=get_json_format_instructions(EvolutionElimination),\r\n    examples=[\r\n        {\r\n            "question1": "气候变化的主要原因是什么？",\r\n            "question2": "是什么因素导致全球变暖？",\r\n            "output": EvolutionElimination.parse_obj(\r\n                {\r\n                    "reason": "虽然这两个问题都涉及环境问题，但“气候变化”涵盖的范围比“全球变暖”更广，导致探究深度的不同。",\r\n                    "verdict": 0,\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "question1": "植物中的光合作用如何工作？",\r\n            "question2": "你能解释一下植物中的光合作用过程吗？",\r\n            "output": EvolutionElimination.parse_obj(\r\n                {\r\n                    "reason": "这两个问题都要求解释植物中的光合作用过程，具有相同的深度、广度和答案要求。",\r\n                    "verdict": 1,\r\n                }\r\n            ).dict(),\r\n        },\r\n        {\r\n            "question1": "定期锻炼对健康有什么好处？",\r\n            "question2": "你能列出定期锻炼对健康的好处吗？",\r\n            "output": EvolutionElimination.parse_obj(\r\n                {\r\n                    "reason": "这两个问题都在寻找有关定期锻炼对健康的积极影响的信息。它们要求列出健康好处的相似程度。",\r\n                    "verdict": 1,\r\n                }\r\n            ).dict(),\r\n        },\r\n    ],\r\n    input_keys=["question1", "question2"],\r\n    output_key="output",\r\n    output_type="json",\r\n    language="english",\r\n)\r\n\r\ntestset_prompts = [\r\n    reasoning_question_prompt,\r\n    multi_context_question_prompt,\r\n    conditional_question_prompt,\r\n    compress_question_prompt,\r\n    conversational_question_prompt,\r\n    question_answer_prompt,\r\n    keyphrase_extraction_prompt,\r\n    seed_question_prompt,\r\n    main_topic_extraction_prompt,\r\n    find_relevant_context_prompt,\r\n    question_rewrite_prompt,\r\n    context_scoring_prompt,\r\n    filter_question_prompt,\r\n    evolution_elimination_prompt,\r\n]\r\n```\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1199/reactions',
   'total_count': 6,
   '+1': 5,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 1
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1199/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1194',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1194/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1194/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1194/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1194',
  'id': 2462962329,
  'node_id': 'I_kwDOJgX1Gs6SzdKZ',
  'number': 1194,
  'title': 'ValueError: a cannot be empty unless no samples are taken',
  'user': {'login': 'Qin-xb',
   'id': 162324777,
   'node_id': 'U_kgDOCazhKQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/162324777?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Qin-xb',
   'html_url': 'https: //github.com/Qin-xb',
   'followers_url': 'https: //api.github.com/users/Qin-xb/followers',
   'following_url': 'https: //api.github.com/users/Qin-xb/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Qin-xb/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Qin-xb/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Qin-xb/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Qin-xb/orgs',
   'repos_url': 'https: //api.github.com/users/Qin-xb/repos',
   'events_url': 'https: //api.github.com/users/Qin-xb/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Qin-xb/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-13T10: 13: 12Z',
  'updated_at': '2024-08-13T10: 15: 31Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\nValueError: a cannot be empty unless no samples are taken\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nRagas version:\r\nPython version:\r\n\r\n**Code to Reproduce**\r\nShare code to reproduce the issue\r\n\r\n\r\nfrom llama_index.core import SimpleDirectoryReader\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\r\n\r\n\r\ndocuments = SimpleDirectoryReader(CONFIG.file_path).load_data()\r\nprint("load file num:", len(documents))\r\n\r\ngenerator_llm = ChatOpenAI(\r\n    model = CONFIG.generator_llm_model,\r\n    api_key = CONFIG.generator_llm_api_key,\r\n    base_url = CONFIG.generator_llm_base_url\r\n)\r\n\r\ncritic_llm =  ChatOpenAI(\r\n    model = CONFIG.critic_llm_model,\r\n    api_key = CONFIG.critic_llm_api_key,\r\n    base_url = CONFIG.critic_llm_base_url\r\n)\r\n\r\nmodel_kwargs = {"device": CONFIG.embed_model_gpu}\r\nencode_kwargs = {"normalize_embeddings": True}\r\nembeddings = HuggingFaceBgeEmbeddings(\r\n    model_name=CONFIG.embed_model, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\r\n)\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n# generate testset\r\ntestset = generator.generate_with_llamaindex_docs(\r\n    documents, \r\n    test_size=CONFIG.generate_question_size, \r\n    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\r\n    with_debugging_logs=True\r\n)\r\n\r\ntest_df = testset.to_pandas()\r\ntest_df.to_excel(CONFIG.save_file_path, index=False)\r\n\r\n\r\n**Error trace**\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1194/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1194/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1192',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1192/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1192/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1192/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1192',
  'id': 2462454086,
  'node_id': 'I_kwDOJgX1Gs6SxhFG',
  'number': 1192,
  'title': 'Answer Relevancy giving same questions everytime',
  'user': {'login': 'knpunk',
   'id': 101012377,
   'node_id': 'U_kgDOBgVTmQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/101012377?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/knpunk',
   'html_url': 'https: //github.com/knpunk',
   'followers_url': 'https: //api.github.com/users/knpunk/followers',
   'following_url': 'https: //api.github.com/users/knpunk/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/knpunk/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/knpunk/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/knpunk/subscriptions',
   'organizations_url': 'https: //api.github.com/users/knpunk/orgs',
   'repos_url': 'https: //api.github.com/users/knpunk/repos',
   'events_url': 'https: //api.github.com/users/knpunk/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/knpunk/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-08-13T06: 01: 06Z',
  'updated_at': '2024-08-13T07: 25: 46Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "@dosu I've gone through the library and first of all, the prompt needs to have something that instructs to go through the context, rather than just providing in few shot.\r\nSecond, I streamed the questions through your help but all three questions are exactly same, and that is happening for every row. Maybe that is why the score is inconsistent, help me fix it please.",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1192/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1192/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1188',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1188/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1188/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1188/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1188',
  'id': 2460451890,
  'node_id': 'I_kwDOJgX1Gs6Sp4Qy',
  'number': 1188,
  'title': 'Integrating third-party LLMs for Evaluating Chinese-native RAGs',
  'user': {'login': 'hurenjun',
   'id': 7581110,
   'node_id': 'MDQ6VXNlcjc1ODExMTA=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/7581110?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/hurenjun',
   'html_url': 'https: //github.com/hurenjun',
   'followers_url': 'https: //api.github.com/users/hurenjun/followers',
   'following_url': 'https: //api.github.com/users/hurenjun/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/hurenjun/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/hurenjun/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/hurenjun/subscriptions',
   'organizations_url': 'https: //api.github.com/users/hurenjun/orgs',
   'repos_url': 'https: //api.github.com/users/hurenjun/repos',
   'events_url': 'https: //api.github.com/users/hurenjun/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/hurenjun/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 8,
  'created_at': '2024-08-12T09: 16: 12Z',
  'updated_at': '2024-09-06T04: 42: 21Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "Hi there,\r\n\r\nThank you for bringing the elegant RAG Assessment framework to the community.\r\n\r\nI am an AI engineer from Alibaba Cloud, and our team has been fine-tuning LLM-as-a-Judge models based on the Qwen foundation LLMs. Through extensive optimizations, our latest model has achieved GPT-4 level alignment with human preferences (indeed, it's performing approximately 5% better on our benchmarks) and it is particularly optimized for Chinese language support.\r\n\r\n**We are very interested in integrating our model as an evaluation LLM within RAGAS. Additionally, we would be happy to support the use of LLM hosted on Alibaba Cloud's LLM serving platform, EAS, as extension to the current support of AWA, Azure, and Google Vertex AI.**\r\n\r\nPlease let me know if these contributions could be included in RAGAS.\r\n\r\nI look forward to your response.\r\n\r\nBest regards,\r\n Renjun\r\n\r\n<!-- PS: Thanks for your valuable feedback. Really! Its feedback from valuable community members like you that help us make Ragas event better for the whole community. So thanks again for taking the time to improve our community 🙂 -->\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1188/reactions',
   'total_count': 4,
   '+1': 4,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1188/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1187',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1187/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1187/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1187/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/1187',
  'id': 2459253575,
  'node_id': 'PR_kwDOJgX1Gs54BH5S',
  'number': 1187,
  'title': 'Fixed metric adaptation issue with the prompt factory',
  'user': {'login': 'ssoima',
   'id': 7611434,
   'node_id': 'MDQ6VXNlcjc2MTE0MzQ=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/7611434?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ssoima',
   'html_url': 'https: //github.com/ssoima',
   'followers_url': 'https: //api.github.com/users/ssoima/followers',
   'following_url': 'https: //api.github.com/users/ssoima/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ssoima/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ssoima/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ssoima/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ssoima/orgs',
   'repos_url': 'https: //api.github.com/users/ssoima/repos',
   'events_url': 'https: //api.github.com/users/ssoima/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ssoima/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745916,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uovA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:M',
    'name': 'size:M',
    'color': 'ebb800',
    'default': False,
    'description': 'This PR changes 30-99 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-10T18: 49: 57Z',
  'updated_at': '2024-08-17T08: 31: 40Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/1187',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/1187',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/1187.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/1187.patch',
   'merged_at': None
            },
  'body': 'Issue:\r\nRuntime metric language adaptation (e.g. adapting to italian and then to german in the same run) does not work. \r\n\r\nThe reason is that the @dataclass factories in the metrics use singleton objects (which only get initialized when the module is loaded) => when the prompt is instantiated a second time, the same object gets returned. Check out this loom for a debug preview: https: //www.loom.com/share/2a500a4d83064489936886674e8641f9?sid=682f87fc-4052-4a33-89e4-5e4d1a6663dd \r\n\r\nSolution: \r\nChanged the prompts to factory methods that returns a new prompt at every call',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1187/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1187/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1186',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1186/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1186/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1186/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1186',
  'id': 2459144572,
  'node_id': 'I_kwDOJgX1Gs6Sk5F8',
  'number': 1186,
  'title': "Evaluation with IBM WatsonX LLM's",
  'user': {'login': 'swayam-khandelwal',
   'id': 173885318,
   'node_id': 'U_kgDOCl1Hhg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/173885318?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/swayam-khandelwal',
   'html_url': 'https: //github.com/swayam-khandelwal',
   'followers_url': 'https: //api.github.com/users/swayam-khandelwal/followers',
   'following_url': 'https: //api.github.com/users/swayam-khandelwal/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/swayam-khandelwal/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/swayam-khandelwal/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/swayam-khandelwal/subscriptions',
   'organizations_url': 'https: //api.github.com/users/swayam-khandelwal/orgs',
   'repos_url': 'https: //api.github.com/users/swayam-khandelwal/repos',
   'events_url': 'https: //api.github.com/users/swayam-khandelwal/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/swayam-khandelwal/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-08-10T15: 55: 06Z',
  'updated_at': '2024-08-10T15: 57: 23Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Hey!\r\nI have tried my hands on RAGAS with Watson LLM, the major issue I am facing is getting the warning:\r\n"Failed to parse output. Returning None." \r\nContinuously.\r\n\r\nIs there any fix for this?\r\nIs it because of the type of response sent by the WatsonX LLM\'s?\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1186/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1186/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1179',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1179/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1179/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1179/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1179',
  'id': 2457342285,
  'node_id': 'I_kwDOJgX1Gs6SeBFN',
  'number': 1179,
  'title': 'Synthetic dataset generation produces undesired Introductory Phrases with Bedrock LLM',
  'user': {'login': 'CosaroLisa',
   'id': 113430756,
   'node_id': 'U_kgDOBsLQ5A',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/113430756?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/CosaroLisa',
   'html_url': 'https: //github.com/CosaroLisa',
   'followers_url': 'https: //api.github.com/users/CosaroLisa/followers',
   'following_url': 'https: //api.github.com/users/CosaroLisa/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/CosaroLisa/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/CosaroLisa/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/CosaroLisa/subscriptions',
   'organizations_url': 'https: //api.github.com/users/CosaroLisa/orgs',
   'repos_url': 'https: //api.github.com/users/CosaroLisa/repos',
   'events_url': 'https: //api.github.com/users/CosaroLisa/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/CosaroLisa/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-08-09T07: 56: 22Z',
  'updated_at': '2024-08-09T11: 38: 41Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[x
            ] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Your Question**\r\nHi, I\'m trying to use this library for generating a synthetic dataset using the LLM and Bedrock embeddings, according to the section of the documentation titled: \'[Using Amazon Bedrock](https://docs.ragas.io/en/stable/howtos/customisations/aws-bedrock.html)\'. What I\'m noticing is that most of the generated questions have this form: \'Based on the feedback, here is a rewritten version of the question that incorporates the relevant context:..\', or \'Based on the given context and keyphrase, here is a potential question:...\', \'Based on the given context and keyphrase "X", a relevant question could be:.....\'. Could someone help me understand how to avoid this behavior, so that I can obtain questions in a direct form, without these \'introductory parts\'?\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1179/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1179/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1177',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1177/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1177/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1177/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1177',
  'id': 2455688246,
  'node_id': 'I_kwDOJgX1Gs6SXtQ2',
  'number': 1177,
  'title': 'Answer Relevance doesnt need context',
  'user': {'login': 'mohamad-tohidi',
   'id': 138975632,
   'node_id': 'U_kgDOCEiZkA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/138975632?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/mohamad-tohidi',
   'html_url': 'https: //github.com/mohamad-tohidi',
   'followers_url': 'https: //api.github.com/users/mohamad-tohidi/followers',
   'following_url': 'https: //api.github.com/users/mohamad-tohidi/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/mohamad-tohidi/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/mohamad-tohidi/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/mohamad-tohidi/subscriptions',
   'organizations_url': 'https: //api.github.com/users/mohamad-tohidi/orgs',
   'repos_url': 'https: //api.github.com/users/mohamad-tohidi/repos',
   'events_url': 'https: //api.github.com/users/mohamad-tohidi/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/mohamad-tohidi/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-08-08T12: 35: 06Z',
  'updated_at': '2024-08-09T11: 48: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ ] I have checked the [documentation](https://docs.ragas.io/) and related resources and couldn't resolve my bug.\r\n\r\n**Describe the bug**\r\nthe answer relevance metric, does not need context as input, it doesnt use it anywhere\r\nso why is it when i try to run it without contexts list it gives me error?\r\n\r\neven in the documentation you mentioned that it needs contexts, but you did not used it anywhere\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1177/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1177/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1175',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1175/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1175/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1175/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1175',
  'id': 2451847570,
  'node_id': 'I_kwDOJgX1Gs6SJDmS',
  'number': 1175,
  'title': 'Vunerable version for the onnx package in the poetry.lock',
  'user': {'login': 'linqiu0-0',
   'id': 73025661,
   'node_id': 'MDQ6VXNlcjczMDI1NjYx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/73025661?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/linqiu0-0',
   'html_url': 'https: //github.com/linqiu0-0',
   'followers_url': 'https: //api.github.com/users/linqiu0-0/followers',
   'following_url': 'https: //api.github.com/users/linqiu0-0/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/linqiu0-0/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/linqiu0-0/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/linqiu0-0/subscriptions',
   'organizations_url': 'https: //api.github.com/users/linqiu0-0/orgs',
   'repos_url': 'https: //api.github.com/users/linqiu0-0/repos',
   'events_url': 'https: //api.github.com/users/linqiu0-0/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/linqiu0-0/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-08-06T23: 32: 06Z',
  'updated_at': '2024-08-07T12: 19: 07Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ ] I have checked the [documentation](https://docs.ragas.io/) and related resources and couldn't resolve my bug.\r\n\r\n**Describe the bug**\r\nI’ve identified that the onnx package listed in the [src/experimental/poetry.lock](https://github.com/explodinggradients/ragas/blob/ee6ff5f3eb7540ef3fb35cfbc17bd3e1c1d0e7cb/src/experimental/poetry.lock#L598) file has a version defined as 1.16.1, which contains a path traversal vulnerability. This issue has been documented in Snyk, as indicated in [this report](https://security.snyk.io/vuln/SNYK-PYTHON-ONNX-7231121).\r\n\r\nThis vulnerability will likely trigger some CVE issues during the vulnerability scans in our Docker image build and push process with Ragas as a dependency. To ensure the integrity and security of this package, could we please update the onnx package to the safe version 1.16.2?\r\n\r\nRagas version: lastest\r\n\r\nThank you!\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1175/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1175/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1170',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1170/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1170/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1170/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1170',
  'id': 2448337562,
  'node_id': 'I_kwDOJgX1Gs6R7qqa',
  'number': 1170,
  'title': '[R-289
            ] better support for ollama models',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028618,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZyg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/documentation',
    'name': 'documentation',
    'color': '0075ca',
    'default': True,
    'description': 'Improvements or additions to documentation'
                  },
                  {'id': 6872832665,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmacamQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/Feature',
    'name': 'Feature',
    'color': 'BB87FC',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                  ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
            },
  'comments': 1,
  'created_at': '2024-08-05T11: 39: 43Z',
  'updated_at': '2024-09-02T07: 06: 44Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': "ref\n\n* [Handle large context windows using Ollama's LLMs for evaluation purpose · Issue #1120 · explodinggradients/ragas](https://github.com/explodinggradients/ragas/issues/1120)\n\nfeats\n\n* check how good ollama models are performing\n* context window issue, need to throw and error if that is the case\n* make a documentation and see if you can figure out a PR?\n\n<sub>From [SyncLinear.com](https://synclinear.com) | [R-289](https://linear.app/exploding-gradients/issue/R-289/better-support-for-ollama-models)</sub>",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1170/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1170/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1167',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1167/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1167/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1167/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1167',
  'id': 2447793355,
  'node_id': 'I_kwDOJgX1Gs6R5lzL',
  'number': 1167,
  'title': 'Why Context Precision and Context Recall are yielding a binary score instead a range between 0 and 1?',
  'user': {'login': 'Anjalisoni99-byte',
   'id': 64090095,
   'node_id': 'MDQ6VXNlcjY0MDkwMDk1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/64090095?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Anjalisoni99-byte',
   'html_url': 'https: //github.com/Anjalisoni99-byte',
   'followers_url': 'https: //api.github.com/users/Anjalisoni99-byte/followers',
   'following_url': 'https: //api.github.com/users/Anjalisoni99-byte/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Anjalisoni99-byte/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Anjalisoni99-byte/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Anjalisoni99-byte/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Anjalisoni99-byte/orgs',
   'repos_url': 'https: //api.github.com/users/Anjalisoni99-byte/repos',
   'events_url': 'https: //api.github.com/users/Anjalisoni99-byte/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Anjalisoni99-byte/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6872728239,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaWCrw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/answered',
    'name': 'answered',
    'color': 'B9EF08',
    'default': False,
    'description': '🤖 The question has been answered. Will be closed automatically if no new comments'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 8,
  'created_at': '2024-08-05T07: 14: 07Z',
  'updated_at': '2024-08-06T09: 48: 09Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '\r\n<img width="184" alt="Screenshot 2024-08-05 124328" src="https://github.com/user-attachments/assets/62105f3a-0280-476b-8ff8-efa0d5e10b1f">\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1167/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1167/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1165',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1165/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1165/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1165/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1165',
  'id': 2447145812,
  'node_id': 'I_kwDOJgX1Gs6R3HtU',
  'number': 1165,
  'title': 'Swiftide integration',
  'user': {'login': 'timonv',
   'id': 49373,
   'node_id': 'MDQ6VXNlcjQ5Mzcz',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/49373?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/timonv',
   'html_url': 'https: //github.com/timonv',
   'followers_url': 'https: //api.github.com/users/timonv/followers',
   'following_url': 'https: //api.github.com/users/timonv/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/timonv/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/timonv/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/timonv/subscriptions',
   'organizations_url': 'https: //api.github.com/users/timonv/orgs',
   'repos_url': 'https: //api.github.com/users/timonv/repos',
   'events_url': 'https: //api.github.com/users/timonv/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/timonv/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-08-04T13: 55: 05Z',
  'updated_at': '2024-08-07T12: 17: 17Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "Hey everyone, amazing work on Ragas! Recently I've been working on [Swiftide](https://github.com/bosun-ai/swiftide), and I'm looking to integrate with an evaluation framework. Rust is great at performance, Python is king at data anytics.\r\n\r\nWe don't have python bindings yet, but I'd be happy to do everything on the Swiftide side to put down something cool.",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1165/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1165/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1162',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1162/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1162/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1162/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1162',
  'id': 2446253862,
  'node_id': 'I_kwDOJgX1Gs6Rzt8m',
  'number': 1162,
  'title': 'Problem with `answer_relevancy` Metric in Ragas Framework',
  'user': {'login': 'huangxuyh',
   'id': 90031786,
   'node_id': 'MDQ6VXNlcjkwMDMxNzg2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/90031786?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/huangxuyh',
   'html_url': 'https: //github.com/huangxuyh',
   'followers_url': 'https: //api.github.com/users/huangxuyh/followers',
   'following_url': 'https: //api.github.com/users/huangxuyh/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/huangxuyh/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/huangxuyh/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/huangxuyh/subscriptions',
   'organizations_url': 'https: //api.github.com/users/huangxuyh/orgs',
   'repos_url': 'https: //api.github.com/users/huangxuyh/repos',
   'events_url': 'https: //api.github.com/users/huangxuyh/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/huangxuyh/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 4,
  'created_at': '2024-08-03T09: 02: 59Z',
  'updated_at': '2024-08-06T05: 31: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "### GitHub Issue Title:\r\nProblem with `answer_relevancy` Metric in Ragas Framework\r\n\r\n### Description:\r\nHello,\r\n\r\nI am experiencing an issue with the Ragas evaluation framework when using the `answer_relevancy` metric. Other metrics work fine, but the `answer_relevancy` metric causes an error. Below is a snippet of the code I am using and the corresponding error message.\r\n\r\n#### Code:\r\n```python\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import (\r\n   faithfulness,\r\n   answer_relevancy,\r\n   context_recall,\r\n   context_precision,\r\n   answer_similarity,\r\n   answer_correctness\r\n)\r\n\r\nresult = evaluate(\r\n    dataset = dataset,\r\n    llm = llm,\r\n    embeddings = embeddings,\r\n    metrics = [\r\n        faithfulness,\r\n        answer_relevancy,\r\n        context_recall,\r\n        context_precision,\r\n        answer_similarity,\r\n        answer_correctness\r\n    ],\r\n)\r\nresult\r\n```\r\n\r\n#### Error Message:\r\n```\r\nBadRequestError: Error code: 400 - {'object': 'error', 'message': 'best_of must be 1 when using greedy sampling.Got 3.', 'type': 'BadRequestError', 'param': None, 'code': 400}\r\n```\r\n\r\nIt seems that the error is related to a `BadRequestError` with a message indicating that `best_of` must be 1 when using greedy sampling. I have verified that I am not explicitly setting the `best_of` parameter. \r\n\r\nAny guidance on how to resolve this issue would be greatly appreciated.\r\n\r\nThank you!",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1162/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1162/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1155',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1155/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1155/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1155/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1155',
  'id': 2443249977,
  'node_id': 'I_kwDOJgX1Gs6RoQk5',
  'number': 1155,
  'title': '[R-286
            ] release `Prompt` object as experimental',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                  ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
            },
  'comments': 0,
  'created_at': '2024-08-01T19: 31: 51Z',
  'updated_at': '2024-09-02T07: 06: 48Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-286](https://linear.app/exploding-gradients/issue/R-286/release-prompt-object-as-experimental)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1155/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1155/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1151',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1151/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1151/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1151/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1151',
  'id': 2442254134,
  'node_id': 'I_kwDOJgX1Gs6Rkdc2',
  'number': 1151,
  'title': '[R-283
            ] Adding more `token_usage_parser`s for various LLM providers',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-08-01T11: 52: 03Z',
  'updated_at': '2024-08-01T11: 52: 08Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': "There are a lot more LLM providers for whom we don't have parsers. We would really apprecite you inputs here in \r\n1. suggesting parsers that you need. This will help us prioritize which ones most used.\r\n2. contribute your own. If you make any for your usecase do consider contributing back too 🙂 \r\n\r\n### Supported Currently\r\n(will keep this updated as we add more)\r\n- OpenAI\r\n- Anthropic\r\n\r\n### Need Support for\r\n(will use this to tally the requests from the community)\r\n- AWS Bedrock\r\n- GCP and Gemni\n\n<sub>[R-283](https://linear.app/exploding-gradients/issue/R-283/adding-more-token-usage-parsers-for-various-llm-providers)</sub>",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1151/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1151/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1150',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1150/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1150/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1150/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1150',
  'id': 2441791070,
  'node_id': 'I_kwDOJgX1Gs6RisZe',
  'number': 1150,
  'title': 'Getting error "Failed to parse output. Returning None" on faithfulness metric',
  'user': {'login': 'ableiweiss',
   'id': 81077407,
   'node_id': 'MDQ6VXNlcjgxMDc3NDA3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/81077407?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ableiweiss',
   'html_url': 'https: //github.com/ableiweiss',
   'followers_url': 'https: //api.github.com/users/ableiweiss/followers',
   'following_url': 'https: //api.github.com/users/ableiweiss/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ableiweiss/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ableiweiss/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ableiweiss/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ableiweiss/orgs',
   'repos_url': 'https: //api.github.com/users/ableiweiss/repos',
   'events_url': 'https: //api.github.com/users/ableiweiss/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ableiweiss/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 8,
  'created_at': '2024-08-01T08: 15: 19Z',
  'updated_at': '2024-08-06T05: 42: 13Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I am getting error "Failed to parse output. Returning None" on faithfulness metric for some inputs. This is inconsistent behavior as it is haphazard and sometimes works, sometimes doesn\'t for the same input. I don\'t see this error on any of the other metrics. I get the error regardless of the LLM I use (Mixtral, LLama, etc.)\r\n\r\nAny solutions to this issue?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1150/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1150/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1149',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1149/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1149/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1149/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1149',
  'id': 2441352181,
  'node_id': 'I_kwDOJgX1Gs6RhBP1',
  'number': 1149,
  'title': '【HELP!!  TimeoutError，seems that can not connect to the api server】',
  'user': {'login': 'haohao0725',
   'id': 58727127,
   'node_id': 'MDQ6VXNlcjU4NzI3MTI3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/58727127?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/haohao0725',
   'html_url': 'https: //github.com/haohao0725',
   'followers_url': 'https: //api.github.com/users/haohao0725/followers',
   'following_url': 'https: //api.github.com/users/haohao0725/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/haohao0725/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/haohao0725/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/haohao0725/subscriptions',
   'organizations_url': 'https: //api.github.com/users/haohao0725/orgs',
   'repos_url': 'https: //api.github.com/users/haohao0725/repos',
   'events_url': 'https: //api.github.com/users/haohao0725/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/haohao0725/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-08-01T03: 11: 35Z',
  'updated_at': '2024-08-02T04: 56: 11Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'ragas version 0.1.12\r\n\r\n**Describe the bug**\r\nI try to run the demo with my openai key, which i have test my key is valid and i can get the correct response via:\r\ncurl https: //api.gptsapi.net/v1/models \\-H "Authorization: Bearer sk-WBR2fc39b876ab1..“ \r\nHowever, when i run the demo, it can not work well, and output was like:\r\n```\r\nEvaluating:   0%|                                                                                                                 | 0/4 [01:20<?, ?it/s]\r\n\r\nTraceback (most recent call last):\r\n  File "/usr/local/lib/python3.10/site-packages/openai/_base_client.py", line 1558, in _request\r\n    response = await self._client.send(\r\n  File "/usr/local/lib/python3.10/site-packages/httpx/_client.py", line 1661, in send\r\n    response = await self._send_handling_auth(\r\n  File "/usr/local/lib/python3.10/site-packages/httpx/_client.py", line 1689, in _send_handling_auth\r\n    response = await self._send_handling_redirects(\r\n  File "/usr/local/lib/python3.10/site-packages/httpx/_client.py", line 1726, in _send_handling_redirects\r\n    response = await self._send_single_request(request)\r\n  File "/usr/local/lib/python3.10/site-packages/httpx/_client.py", line 1763, in _send_single_request\r\n    response = await transport.handle_async_request(request)\r\n  File "/usr/local/lib/python3.10/site-packages/httpx/_transports/default.py", line 373, in handle_async_request\r\n    resp = await self._pool.handle_async_request(req)\r\n  File "/usr/local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py", line 216, in handle_async_request\r\n    raise exc from None\r\n  File "/usr/local/lib/python3.10/site-packages/httpcore/_async/connection_pool.py", line 196, in handle_async_request\r\n    response = await connection.handle_async_request(\r\n  File "/usr/local/lib/python3.10/site-packages/httpcore/_async/connection.py", line 99, in handle_async_request\r\n    raise exc\r\n  File "/usr/local/lib/python3.10/site-packages/httpcore/_async/connection.py", line 76, in handle_async_request\r\n    stream = await self._connect(request)\r\n  File "/usr/local/lib/python3.10/site-packages/httpcore/_async/connection.py", line 122, in _connect\r\n    stream = await self._network_backend.connect_tcp(**kwargs)\r\n  File "/usr/local/lib/python3.10/site-packages/httpcore/_backends/auto.py", line 30, in connect_tcp\r\n    return await self._backend.connect_tcp(\r\n  File "/usr/local/lib/python3.10/site-packages/httpcore/_backends/anyio.py", line 116, in connect_tcp\r\n    stream: anyio.abc.ByteStream = await anyio.connect_tcp(\r\n  File "/usr/local/lib/python3.10/site-packages/anyio/_core/_sockets.py", line 214, in connect_tcp\r\n    async with create_task_group() as tg:\r\n  File "/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 690, in __aexit__\r\n    raise cancelled_exc_while_waiting_tasks\r\n  File "/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py", line 670, in __aexit__\r\n    await asyncio.wait(self._tasks)\r\n  File "/usr/local/lib/python3.10/asyncio/tasks.py", line 384, in wait\r\n    return await _wait(fs, timeout, return_when, loop)\r\n  File "/usr/local/lib/python3.10/asyncio/tasks.py", line 491, in _wait\r\n    await waiter\r\nasyncio.exceptions.CancelledError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/metrics/_answer_correctness.py", line 220, in _ascore\r\n    item_statement = await self.llm.generate(p_value, callbacks=callbacks)\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/llms/base.py", line 95, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter\r\n    result = await action(retry_state)\r\n  File "/usr/local/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner\r\n    return call(*args, **kwargs)\r\n  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>\r\n    self._add_action_func(lambda rs: rs.outcome.result())\r\n  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 451, in result\r\n    return self.__get_result()\r\n  File "/usr/local/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result\r\n    raise self._exception\r\n  File "/usr/local/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/llms/base.py", line 176, in agenerate_text\r\n    return await self.langchain_llm.agenerate_prompt(\r\n  File "/usr/local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 724, in agenerate_prompt\r\n    return await self.agenerate(\r\n  File "/usr/local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 650, in agenerate\r\n    results = await asyncio.gather(\r\nasyncio.exceptions.CancelledError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "/usr/local/lib/python3.10/asyncio/tasks.py", line 456, in wait_for\r\n    return fut.result()\r\nasyncio.exceptions.CancelledError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "/mnt/workspace/test.py", line 18, in <module>\r\n    score = evaluate(dataset,metrics=[faithfulness,answer_correctness])\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/evaluation.py", line 247, in evaluate\r\n    raise e\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/evaluation.py", line 227, in evaluate\r\n    results = executor.results()\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/executor.py", line 107, in results\r\n    results = asyncio.run(_aresults())\r\n  File "/usr/local/lib/python3.10/asyncio/runners.py", line 44, in run\r\n    return loop.run_until_complete(main)\r\n  File "/usr/local/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete\r\n    return future.result()\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/executor.py", line 102, in _aresults\r\n    r = await future\r\n  File "/usr/local/lib/python3.10/asyncio/tasks.py", line 571, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/executor.py", line 34, in sema_coro\r\n    return await coro\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/executor.py", line 59, in wrapped_callable_async\r\n    raise e\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/executor.py", line 53, in wrapped_callable_async\r\n    result = await callable(*args, **kwargs)\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/metrics/base.py", line 127, in ascore\r\n    raise e\r\n  File "/usr/local/lib/python3.10/site-packages/ragas/metrics/base.py", line 120, in ascore\r\n    score = await asyncio.wait_for(\r\n  File "/usr/local/lib/python3.10/asyncio/tasks.py", line 458, in wait_for\r\n    raise exceptions.TimeoutError() from exc\r\nasyncio.exceptions.TimeoutError\r\n```\r\nRagas version: 0.1.12\r\nPython version: 3.10\r\n\r\n**Code to Reproduce**\r\n```py\r\nfrom datasets import Dataset \r\nimport os\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import faithfulness, answer_correctness\r\n\r\nos.environ["OPENAI_API_KEY"] = "sk-WBR2fc39b876ab1dc7ee7..."\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n    \'contexts\' : [[\'The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\']],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n}\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nscore = evaluate(dataset,metrics=[faithfulness,answer_correctness])\r\nprint(score.to_pandas())\r\n```\r\n\r\n**Additional context**\r\ncan anybody give my some useful advise, thank u sooo much!!\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1149/reactions',
   'total_count': 3,
   '+1': 3,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1149/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1145',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1145/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1145/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1145/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1145',
  'id': 2440569182,
  'node_id': 'I_kwDOJgX1Gs6ReCFe',
  'number': 1145,
  'title': "Synthetic Test Data generation doesn't output columns ['answer'] on testset",
  'user': {'login': 'shayefarti',
   'id': 46104730,
   'node_id': 'MDQ6VXNlcjQ2MTA0NzMw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/46104730?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shayefarti',
   'html_url': 'https: //github.com/shayefarti',
   'followers_url': 'https: //api.github.com/users/shayefarti/followers',
   'following_url': 'https: //api.github.com/users/shayefarti/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shayefarti/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shayefarti/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shayefarti/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shayefarti/orgs',
   'repos_url': 'https: //api.github.com/users/shayefarti/repos',
   'events_url': 'https: //api.github.com/users/shayefarti/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shayefarti/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-07-31T17: 43: 37Z',
  'updated_at': '2024-08-02T04: 51: 18Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '\r\n\r\n**Your Question**\r\nSynthetic Test Data generation doesn\'t output columns [\'answer\'
            ] as in this [Example
            ](https: //docs.ragas.io/en/latest/concepts/testset_generation.html#example)\r\n\r\n**Code Examples**\r\n***Load Doc***\r\n```python\r\nfrom langchain_community.document_loaders import DirectoryLoader\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\n\r\nloader = DirectoryLoader(\r\n    "./Docs/", use_multithreading=True, silent_errors=True, sample_size=1\r\n)\r\ndocuments = loader.load()\r\n\r\nfor document in documents:\r\n    document.metadata["filename"] = document.metadata["source"]`\r\n```\r\n***Load Modules (I Use Azure Open AI )***\r\n```python\r\nfrom langchain_openai.chat_models import AzureChatOpenAI\r\nfrom langchain_openai.embeddings import AzureOpenAIEmbeddings\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\n\r\ngenerator_llm = AzureChatOpenAI(\r\n    azure_deployment=\'gpt-4o\',\r\n    api_version="2024-02-15-preview",\r\n    temperature=0,\r\n    max_tokens=None,\r\n    timeout=None,\r\n    max_retries=2,\r\n    validate_base_url=False\r\n)\r\ncritic_llm = AzureChatOpenAI(\r\n    azure_deployment=\'gpt-4o\',\r\n    api_version="2024-02-15-preview",\r\n    temperature=0,\r\n    max_tokens=None,\r\n    timeout=None,\r\n    max_retries=2,\r\n    validate_base_url=False\r\n)\r\nembeddings = AzureOpenAIEmbeddings(\r\n    azure_deployment="text-embedding-3-large",\r\n    openai_api_version="2024-02-15-preview",\r\n)\r\n```\r\n***Generate Test***\r\n```python\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm=generator_llm, critic_llm=critic_llm, embeddings=embeddings\r\n)\r\n\r\ntestset = generator.generate_with_langchain_docs(\r\n    documents,\r\n    test_size=10,\r\n    raise_exceptions=False,\r\n    with_debugging_logs=False,\r\n    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\r\n)\r\n\r\n```\r\n***Display dataset/testset columns****\r\n```python\r\n # testset to panda\r\ntestset.to_pandas().columns\r\nIndex([\'question\', \'contexts\', \'ground_truth\', \'evolution_type\', \'metadata\',\r\n       \'episode_done\'],\r\n      dtype=\'object\')\r\n\r\ntestset_to_dataset  = testset.to_dataset()\r\nDataset({\r\n    features: [\'question\', \'contexts\', \'ground_truth\', \'evolution_type\', \'metadata\', \'episode_done\'],\r\n    num_rows: 10\r\n```\r\n\r\n***Run evaluate on the testset_to_dataset***\r\n```python\r\nfrom ragas.metrics import (\r\n    context_precision,\r\n    answer_relevancy,\r\n    faithfulness,\r\n    context_recall,\r\n)\r\nfrom ragas.metrics.critique import harmfulness\r\n\r\n# list of metrics we\'re going to use\r\nmetrics = [\r\n    faithfulness,\r\n    answer_relevancy,\r\n    context_recall,\r\n    context_precision,\r\n    harmfulness,\r\n]\r\nresult = evaluate(\r\n    testset_to_dataset, metrics=metrics, llm=generator_llm, embeddings=embeddings\r\n)\r\n\r\nresult\r\n\r\nValueError: The metric [faithfulness] that that is used requires the following additional columns [\'answer\'] to be present in the dataset.\r\n```\r\n\r\n})\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1145/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1145/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1143',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1143/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1143/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1143/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1143',
  'id': 2440335757,
  'node_id': 'I_kwDOJgX1Gs6RdJGN',
  'number': 1143,
  'title': '[R-288
            ] Limit Evolution',
  'user': {'login': 'ArjunBakhale',
   'id': 109678629,
   'node_id': 'U_kgDOBomQJQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/109678629?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ArjunBakhale',
   'html_url': 'https: //github.com/ArjunBakhale',
   'followers_url': 'https: //api.github.com/users/ArjunBakhale/followers',
   'following_url': 'https: //api.github.com/users/ArjunBakhale/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ArjunBakhale/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ArjunBakhale/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ArjunBakhale/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ArjunBakhale/orgs',
   'repos_url': 'https: //api.github.com/users/ArjunBakhale/repos',
   'events_url': 'https: //api.github.com/users/ArjunBakhale/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ArjunBakhale/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-07-31T15: 28: 00Z',
  'updated_at': '2024-08-02T05: 17: 20Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ ] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\nIs there a way to add a arg to testset generation that sets max evolutions to something like 1 instead of 5\r\n\r\ni.e\r\n```py\r\nrun_config = RunConfig(timeout= 360, max_retries=2, max_wait=60, max_workers=32, log_tenacity=True, **max_evolutions=2**)\r\n\r\ncurrent_testset = generator.generate_with_langchain_docs(document, test_size=test_size_gen, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25}, run_config = run_config )\r\n```\r\n\r\nThank you :)\r\n\n\n<sub>[R-288](https://linear.app/exploding-gradients/issue/R-288/limit-evolution)</sub>",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1143/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1143/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1139',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1139/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1139/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1139/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1139',
  'id': 2439591700,
  'node_id': 'I_kwDOJgX1Gs6RaTcU',
  'number': 1139,
  'title': '[R-281
            ] add callbacks to trace reasoning of evaluations',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                  ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
            },
  'comments': 0,
  'created_at': '2024-07-31T09: 35: 41Z',
  'updated_at': '2024-09-02T07: 06: 53Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-281](https://linear.app/exploding-gradients/issue/R-281/add-callbacks-to-trace-reasoning-of-evaluations)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1139/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1139/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1137',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1137/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1137/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1137/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1137',
  'id': 2439387625,
  'node_id': 'I_kwDOJgX1Gs6RZhnp',
  'number': 1137,
  'title': 'Empty generation does not raise a `ragas.exceptions.ExceptionInRunner`',
  'user': {'login': 'Gwenn-LR',
   'id': 95341944,
   'node_id': 'U_kgDOBa7NeA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/95341944?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Gwenn-LR',
   'html_url': 'https: //github.com/Gwenn-LR',
   'followers_url': 'https: //api.github.com/users/Gwenn-LR/followers',
   'following_url': 'https: //api.github.com/users/Gwenn-LR/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Gwenn-LR/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Gwenn-LR/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Gwenn-LR/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Gwenn-LR/orgs',
   'repos_url': 'https: //api.github.com/users/Gwenn-LR/repos',
   'events_url': 'https: //api.github.com/users/Gwenn-LR/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Gwenn-LR/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-07-31T07: 55: 36Z',
  'updated_at': '2024-07-31T08: 00: 52Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'body': '[x
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nHi! I\'m currently working with `ragas` to test different RAG architectures, so I\'m using `Ollama`, `HuggingFace` and `LangChain` framework on top of `ragas` and I\'m facing an issue when I\'m trying to implement an unit test around the synthetic generation : the generated `ragas.testset.generator.TestsetGenerator` object has empty rows.\r\n\r\nI think it comes from a specific parametrization of each frameworks but after having looked over the repository, I think you\'ve tried to avoid such a situation but your checking does not raise any error.\r\n\r\nRagas version: 0.1.11\r\nPython version: 3.10.12\r\n\r\n**Code to Reproduce**\r\nThe `example.pdf` file used here can be found at: https://css4.pub/2015/usenix/example.pdf\r\n\r\n```python\r\nfrom langchain_community.chat_models import ChatOllama\r\nfrom ragas.testset import TestsetGenerator\r\nfrom rag_sandbox.embedding.huggingface import HuggingFaceEmbeddings\r\nfrom langchain_community.document_loaders.pdf import UnstructuredPDFLoader\r\n\r\nif __name__ == "__main__":\r\n    llm = ChatOllama(base_url="http://localhost:11434", model="qwen2:7b")\r\n\r\n    generator = TestsetGenerator.from_langchain(\r\n        generator_llm=llm,\r\n        critic_llm=llm,\r\n        embeddings=HuggingFaceEmbeddings()\r\n    )\r\n\r\n    documents = UnstructuredPDFLoader(\r\n        "./tests/data/pdf/example.pdf",\r\n        mode="elements",\r\n        strategy="hi_res",\r\n        infer_table_structure=True,\r\n        hi_res_model_name="yolox",\r\n        extract_images_in_pdf=True,\r\n        extract_image_block_output_dir="./results/data_extraction/images"\r\n        ).load()\r\n\r\n    dataset = generator.generate_with_langchain_docs(\r\n        documents=documents,\r\n        test_size=1\r\n    )\r\n```\r\n\r\n**Error trace**\r\nNo error, but that is the problem.\r\n\r\n**Expected behavior**\r\nAccording to your code, one can expect to get a `ragas.exceptions.ExceptionInRunner` in such a situation.\r\n\r\n**Additional context**\r\nI\'ll offer a PR to fix this issue, but I don\'t know if it won\'t conflict with another part of the code.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1137/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1137/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1136',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1136/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1136/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1136/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1136',
  'id': 2436823162,
  'node_id': 'I_kwDOJgX1Gs6RPvh6',
  'number': 1136,
  'title': "[R-291] RuntimeError: There is no current event loop in thread 'MainThread'.",
  'user': {'login': 'Mervyn-1',
   'id': 55747445,
   'node_id': 'MDQ6VXNlcjU1NzQ3NDQ1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/55747445?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Mervyn-1',
   'html_url': 'https: //github.com/Mervyn-1',
   'followers_url': 'https: //api.github.com/users/Mervyn-1/followers',
   'following_url': 'https: //api.github.com/users/Mervyn-1/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Mervyn-1/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Mervyn-1/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Mervyn-1/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Mervyn-1/orgs',
   'repos_url': 'https: //api.github.com/users/Mervyn-1/repos',
   'events_url': 'https: //api.github.com/users/Mervyn-1/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Mervyn-1/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                  ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
            },
  'comments': 6,
  'created_at': '2024-07-30T03: 51: 20Z',
  'updated_at': '2024-09-02T07: 06: 49Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\n```\r\nRuntimeError: There is no current event loop in thread \'MainThread\'.\r\nsys:1: RuntimeWarning: coroutine \'Executor.wrap_callable_with_index.<locals>.wrapped_callable_async\' was never awaited\r\n```\r\nI encountered this issue during batch evaluation: when the batch list exceeds a certain length (15), the following errors occur. Even after completing the first evaluation loop, the second loop triggers the error:\r\n```\r\nRuntimeError: Task <Task pending name=\'Task-31\' coro=<as_completed.<locals>.sema_coro() running at /Users/.../python3.9/site-packages/ragas/executor.py:33> cb=[as_completed.<locals>._on_completion() at /Users/.../python3.9/asyncio/tasks.py:598]> got Future <Future pending> attached to a different loop\r\n\r\nRuntimeError: There is no current event loop in thread \'MainThread\'. sys:1: RuntimeWarning: coroutine \'Executor.wrap_callable_with_index.<locals>.wrapped_callable_async\' was never awaited\r\n```\r\nRagas version:0.1.12.dev3+g95d8318\r\nPython version:3.9.19\r\n\r\n**Code to Reproduce**\r\n```py\r\nclass RagEvaluator:\r\n    def __init__(self):\r\n        self.llm = ChatOpenAI(model="deepseek-chat",api_key="",base_url="https://api.deepseek.com/v1" ,temperature=0.7)\r\n        self.wrapped_embeddings = EmbeddingFactory.build_embedding_eas_service()\r\n    def evaluate_rag(self,question, answer,ground_truth):\r\n        data_samples = {\r\n            \'question\': question,\r\n            \'answer\': answer,\r\n            \'ground_truth\': ground_truth\r\n        }\r\n        dataset = Dataset.from_dict(data_samples)\r\n        result = evaluate(dataset, metrics=[answer_correctness], llm=self.llm, embeddings=self.wrapped_embeddings)\r\n        return result\r\n\r\ndf = pd.read_csv(\'/Users/.../merged_results.csv\', encoding=\'utf-8\')\r\nquestion = df[\'question\'].tolist()\r\nanswer = df[\'answer\'].tolist()\r\nground_truth = df[\'ground_truth\'].tolist()\r\n\r\ndata = {\r\n    \'question\': question,\r\n    \'answer\': answer,\r\n    \'ground_truth\': ground_truth\r\n}\r\n\r\ndataset = Dataset.from_dict(data)\r\nevaluator = RagEvaluator()\r\n\r\nresult = evaluator.evaluate_rag(question[:15],answer[:15],ground_truth[:15])\r\nprint(result)\r\n\r\nresult2 = evaluator.evaluate_rag(question[15:],answer[15:],ground_truth[15:])\r\n```\r\n**Error trace**\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n\n\n<sub>[R-291](https://linear.app/exploding-gradients/issue/R-291/runtimeerror-there-is-no-current-event-loop-in-thread-mainthread)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1136/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1136/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1133',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1133/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1133/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1133/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1133',
  'id': 2434923916,
  'node_id': 'I_kwDOJgX1Gs6RIf2M',
  'number': 1133,
  'title': 'ValidationError with OpenAIEmbeddings in Ragas',
  'user': {'login': 'SushmitaSingh96',
   'id': 40317759,
   'node_id': 'MDQ6VXNlcjQwMzE3NzU5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/40317759?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/SushmitaSingh96',
   'html_url': 'https: //github.com/SushmitaSingh96',
   'followers_url': 'https: //api.github.com/users/SushmitaSingh96/followers',
   'following_url': 'https: //api.github.com/users/SushmitaSingh96/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/SushmitaSingh96/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/SushmitaSingh96/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/SushmitaSingh96/subscriptions',
   'organizations_url': 'https: //api.github.com/users/SushmitaSingh96/orgs',
   'repos_url': 'https: //api.github.com/users/SushmitaSingh96/repos',
   'events_url': 'https: //api.github.com/users/SushmitaSingh96/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/SushmitaSingh96/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-07-29T09: 32: 20Z',
  'updated_at': '2024-07-30T05: 58: 26Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'A `ValidationError` occurs when trying to use the `evaluate` function from Ragas with the `OpenAIEmbeddings` model. The error message suggests using `AzureOpenAIEmbeddings` when using Azure, but I am using the standard OpenAI API.\r\n\r\n**To Reproduce**\r\n\r\nSteps to reproduce the behavior:\r\n1. Use the following code from the Ragas documentation: [Metrics - Answer Correctness
            ](https: //docs.ragas.io/en/latest/concepts/metrics/answer_correctness.html)\r\n2. Run the code, and observe the error.\r\n\r\n```python\r\nfrom datasets import Dataset \r\nfrom ragas.metrics import answer_correctness\r\nfrom ragas import evaluate\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n}\r\ndataset = Dataset.from_dict(data_samples)\r\nscore = evaluate(dataset, metrics=[answer_correctness])\r\nscore.to_pandas()\r\n```\r\n\r\n**Error Message**\r\n\r\n```...\r\n  181 def embedding_factory(\r\n  182     model: str = "text-embedding-ada-002", run_config: t.Optional[RunConfig] = None\r\n  183 ) -> BaseRagasEmbeddings:\r\n--> 184     openai_embeddings = OpenAIEmbeddings(model=model)\r\n  185     if run_config is not None:\r\n...\r\n  343     object_setattr(__pydantic_self__, \'__dict__\', values)\r\n\r\nValidationError: 1 validation error for OpenAIEmbeddings\r\n__root__\r\n  If you are using Azure, please use the `AzureOpenAIEmbeddings` class. (type=value_error)\r\n```\r\n\r\n**Expected behavior**\r\n\r\nThe code should execute without errors, generating the evaluation scores and converting them to a pandas DataFrame.\r\n\r\n**Suggested Workaround**\r\n\r\nThe issue seems to be related to the LangChain framework, and a suggested workaround can be found [here](https://github.com/langchain-ai/langchain/issues/18727).\r\n\r\nThe code change is:\r\n\r\n```python\r\nembeddings = OpenAIEmbeddings(openai_api_type="openai")\r\n```\r\n\r\n**Environment:**\r\n- OS: MacOS\r\n- Python version: 3.11.9\r\n- Ragas version: 0.1.10\r\n- langchain_openai version: 0.1.7\r\n- openai version: 1.36.1\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1133/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1133/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1131',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1131/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1131/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1131/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1131',
  'id': 2433895481,
  'node_id': 'I_kwDOJgX1Gs6REkw5',
  'number': 1131,
  'title': 'get keyphrases from TestGenerator',
  'user': {'login': 'ableiweiss',
   'id': 81077407,
   'node_id': 'MDQ6VXNlcjgxMDc3NDA3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/81077407?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ableiweiss',
   'html_url': 'https: //github.com/ableiweiss',
   'followers_url': 'https: //api.github.com/users/ableiweiss/followers',
   'following_url': 'https: //api.github.com/users/ableiweiss/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ableiweiss/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ableiweiss/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ableiweiss/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ableiweiss/orgs',
   'repos_url': 'https: //api.github.com/users/ableiweiss/repos',
   'events_url': 'https: //api.github.com/users/ableiweiss/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ableiweiss/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-07-28T11: 59: 59Z',
  'updated_at': '2024-07-30T06: 15: 02Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Is it get the keyphrases extracted by TestGenerator using the API?\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1131/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1131/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1121',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1121/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1121/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1121/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1121',
  'id': 2423091112,
  'node_id': 'I_kwDOJgX1Gs6QbW-o',
  'number': 1121,
  'title': 'Custom prompt for test set generation',
  'user': {'login': 'harvey1992',
   'id': 157509364,
   'node_id': 'U_kgDOCWNm9A',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/157509364?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/harvey1992',
   'html_url': 'https: //github.com/harvey1992',
   'followers_url': 'https: //api.github.com/users/harvey1992/followers',
   'following_url': 'https: //api.github.com/users/harvey1992/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/harvey1992/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/harvey1992/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/harvey1992/subscriptions',
   'organizations_url': 'https: //api.github.com/users/harvey1992/orgs',
   'repos_url': 'https: //api.github.com/users/harvey1992/repos',
   'events_url': 'https: //api.github.com/users/harvey1992/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/harvey1992/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 20,
  'created_at': '2024-07-22T14: 55: 20Z',
  'updated_at': '2024-09-06T03: 13: 11Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "Is there a way to customize a prompt using the TestsetGenerator class? I looked at the documentation, and it only provides examples with default prompts used under the hood. I also looked at the code associated with the test generation class, but I didn't understand how to do it, if it is possible. ",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1121/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1121/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1120',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1120/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1120/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1120/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1120',
  'id': 2422081837,
  'node_id': 'I_kwDOJgX1Gs6QXgkt',
  'number': 1120,
  'title': "Handle large context windows using Ollama's LLMs for evaluation purpose",
  'user': {'login': 'TM02',
   'id': 77006076,
   'node_id': 'MDQ6VXNlcjc3MDA2MDc2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/77006076?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/TM02',
   'html_url': 'https: //github.com/TM02',
   'followers_url': 'https: //api.github.com/users/TM02/followers',
   'following_url': 'https: //api.github.com/users/TM02/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/TM02/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/TM02/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/TM02/subscriptions',
   'organizations_url': 'https: //api.github.com/users/TM02/orgs',
   'repos_url': 'https: //api.github.com/users/TM02/repos',
   'events_url': 'https: //api.github.com/users/TM02/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/TM02/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-07-22T06: 47: 41Z',
  'updated_at': '2024-08-02T05: 22: 43Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[/
            ] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\nI integrated Langfuse with Ragas for evaluation purposes. Referring to issue #53, it\'s mentioned that by default, "we are using \'gpt-3.5-16k\', so you don\'t have to reduce document size when running the evals." However, when using different Ollama LLMs like llama3, mistral, phi3..., I noticed that Ragas limits the context window to between 500-700 tokens. I want it to handle larger document sizes, similar to \'gpt-3.5-16k\'. Is this possible?\r\n\r\n\r\n```py\r\n# setup ragas evaluation ----------------------------------------------------\r\n\r\n# import metrics\r\nfrom ragas.metrics import faithfulness, answer_relevancy, context_precision\r\nfrom ragas.metrics.critique import SUPPORTED_ASPECTS, harmfulness\r\nfrom ragas.run_config import RunConfig\r\nfrom ragas.metrics.base import MetricWithLLM, MetricWithEmbeddings\r\nfrom langchain_openai.chat_models import ChatOpenAI\r\nfrom langchain_openai.embeddings import OpenAIEmbeddings\r\n\r\n# wrappers\r\nfrom ragas.llms import LangchainLLMWrapper\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\n\r\nfrom langchain_community.chat_models import ChatOllama\r\nfrom ragas import evaluate\r\nfrom langchain_community.embeddings import OllamaEmbeddings\r\n# information found here: https://docs.ragas.io/en/latest/howtos/customisations/bring-your-own-llm-or-embs.html\r\n\r\n# metrics you chose\r\nmetrics = [answer_relevancy]\r\n\r\n# util function to init Ragas Metrics\r\ndef init_ragas_metrics(metrics, llm, embedding):\r\n    for metric in metrics:\r\n        if isinstance(metric, MetricWithLLM):\r\n            metric.llm = llm\r\n        if isinstance(metric, MetricWithEmbeddings):\r\n            metric.embeddings = embedding\r\n        run_config = RunConfig()\r\n        metric.init(run_config)\r\n\r\nllm = ChatOllama(model="deepseek-coder-v2:latest")\r\nemb = OllamaEmbeddings(model="nomic-embed-text")\r\n\r\n# llm = ChatOpenAI(model="gpt-3.5-turbo-16k")\r\n# emb = OpenAIEmbeddings()\r\n\r\ninit_ragas_metrics(\r\n    metrics,\r\n    llm=LangchainLLMWrapper(llm),\r\n    embedding=LangchainEmbeddingsWrapper(emb),\r\n)\r\n\r\nasync def score_with_ragas(query, chunks, answer):\r\n    scores = {}\r\n    for m in metrics:\r\n        print(f"calculating {m.name}")\r\n        scores[m.name] = await m.ascore(   # call each metric\'s ascore, pass dict with question, context, and answer(calculation here)\r\n            row={"question": query, "contexts": chunks, "answer": answer}  # result stored in \'scores\' dict with the metric\'s name as key\r\n        )\r\n    return scores\r\n\r\nfrom langchain_core.runnables import RunnableLambda\r\n\r\n# Define a global variable to store the context\r\ncontext_retrieved = None\r\n\r\ndef inspect(state):\r\n    """Print the state passed between Runnables in a langchain and pass it on"""\r\n    global context_retrieved\r\n    context_retrieved = state.get("context")\r\n    print(state)\r\n    return state\r\n\r\nchain = (\r\n    RunnableParallel(\r\n        {\r\n            "context": _search_query | retriever,\r\n            "question": RunnablePassthrough(),\r\n        }\r\n    )\r\n    | RunnableLambda(inspect)\r\n    | prompt\r\n    | llm2\r\n    | StrOutputParser()\r\n)\r\n\r\nimport pprint\r\n\r\nuser_question = "What happened to Alice after she ate the cake?"\r\nanswer = chain.invoke({"question": user_question})\r\npprint.pprint(answer)\r\n\r\n\r\ncontext_retrieved = \'\'\'\r\nShe ate a little bit, and said anxiously to herself, “Which way? Which\r\nway?”, holding her hand on the top of her head to feel which way it was\r\ngrowing, and she was quite surprised to find that she remained the same\r\nsize: to be sure, this generally happens when one eats cake, but Alice\r\nhad got so much into the way of expecting nothing but out-of-the-way\r\nthings to happen, that it seemed quite dull and stupid for life to go\r\non in the common way.\r\n\'\'\'\r\n\r\ncontext_red_retrieved = context_retrieved[:700]\r\nquestion, contexts, answer = user_question, context_red_retrieved, answer\r\neval_ans = await score_with_ragas(question, contexts, answer) \r\nprint(eval_ans)\r\n```\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1120/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1120/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1119',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1119/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1119/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1119/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1119',
  'id': 2421751873,
  'node_id': 'I_kwDOJgX1Gs6QWQBB',
  'number': 1119,
  'title': 'Ensuring Consistent Question Sets for Summarization Score Evaluation',
  'user': {'login': 'noweymik',
   'id': 72730302,
   'node_id': 'MDQ6VXNlcjcyNzMwMzAy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/72730302?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/noweymik',
   'html_url': 'https: //github.com/noweymik',
   'followers_url': 'https: //api.github.com/users/noweymik/followers',
   'following_url': 'https: //api.github.com/users/noweymik/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/noweymik/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/noweymik/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/noweymik/subscriptions',
   'organizations_url': 'https: //api.github.com/users/noweymik/orgs',
   'repos_url': 'https: //api.github.com/users/noweymik/repos',
   'events_url': 'https: //api.github.com/users/noweymik/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/noweymik/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                  },
                  {'login': 'sky-2002',
    'id': 84656834,
    'node_id': 'MDQ6VXNlcjg0NjU2ODM0',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/84656834?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/sky-2002',
    'html_url': 'https: //github.com/sky-2002',
    'followers_url': 'https: //api.github.com/users/sky-2002/followers',
    'following_url': 'https: //api.github.com/users/sky-2002/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/sky-2002/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/sky-2002/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/sky-2002/subscriptions',
    'organizations_url': 'https: //api.github.com/users/sky-2002/orgs',
    'repos_url': 'https: //api.github.com/users/sky-2002/repos',
    'events_url': 'https: //api.github.com/users/sky-2002/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/sky-2002/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': None,
  'comments': 6,
  'created_at': '2024-07-22T02: 09: 12Z',
  'updated_at': '2024-08-10T14: 48: 26Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Hi!\r\n\r\nI have a question regarding the generation of question sets for the Summarization Score metric. I am working on creating a high-quality summary and need reliable evaluation metrics to assess it. I have found the Summarization Score metric to be very useful for checking the quality of my summaries.\r\n\r\nHowever, I am experiencing some issues with the volatility of the scores. Even though the input is always the same, the questions generated differ each time. Is there a way to ensure that the set of questions remains consistent when the input is the same?\r\n\r\n\r\nI have an idea related to this issue. If it is not possible to generate a consistent set of questions using an LLM, what do you think about attempting to score the summary multiple times (n times) and averaging the results to get a more stable score? If you have any other good suggestions, I would greatly appreciate it.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1119/reactions',
   'total_count': 3,
   '+1': 3,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1119/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1109',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1109/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1109/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1109/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1109',
  'id': 2415608977,
  'node_id': 'I_kwDOJgX1Gs6P-0SR',
  'number': 1109,
  'title': 'ValueError: a cannot be empty unless no samples are taken',
  'user': {'login': 'Rugved2204',
   'id': 96412167,
   'node_id': 'U_kgDOBb8iBw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/96412167?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Rugved2204',
   'html_url': 'https: //github.com/Rugved2204',
   'followers_url': 'https: //api.github.com/users/Rugved2204/followers',
   'following_url': 'https: //api.github.com/users/Rugved2204/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Rugved2204/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Rugved2204/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Rugved2204/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Rugved2204/orgs',
   'repos_url': 'https: //api.github.com/users/Rugved2204/repos',
   'events_url': 'https: //api.github.com/users/Rugved2204/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Rugved2204/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-07-18T07: 33: 06Z',
  'updated_at': '2024-08-02T06: 14: 47Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nValueError: a cannot be empty unless no samples are taken\r\n\r\nRagas version:0.1.10\r\nPython version:\r\n\r\n**Code to Reproduce**\r\n\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nimport nest_asyncio\r\nfrom langchain_community.document_loaders import PubMedLoader\r\nfrom langchain.text_splitter import CharacterTextSplitter\r\nfrom ragas.testset.docstore import InMemoryDocumentStore\r\nfrom ragas.testset.extractor import KeyphraseExtractor\r\nfrom langchain.embeddings import HuggingFaceEmbeddings\r\nfrom transformers import (\r\n    AutoModelForCausalLM,\r\n    AutoTokenizer,\r\n    BitsAndBytesConfig,\r\n    pipeline\r\n)\r\nfrom langchain.llms import HuggingFacePipeline\r\nimport torch\r\n\r\nmodel_name=\'mistralai/Mistral-7B-Instruct-v0.2\'\r\n\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\r\ntokenizer.pad_token = tokenizer.eos_token\r\ntokenizer.padding_side = "right"\r\n\r\n\r\n\r\nuse_4bit = True\r\n\r\nbnb_4bit_compute_dtype = "float16"\r\n\r\nbnb_4bit_quant_type = "nf4"\r\n\r\nuse_nested_quant = False\r\n\r\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\r\n\r\nbnb_config = BitsAndBytesConfig(\r\n    load_in_4bit=use_4bit,\r\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\r\n    bnb_4bit_compute_dtype=compute_dtype,\r\n    bnb_4bit_use_double_quant=use_nested_quant,\r\n)\r\n\r\nmistral_model = AutoModelForCausalLM.from_pretrained(\r\n    model_name,\r\n    quantization_config=bnb_config,\r\n)\r\n\r\nembedding_model_name = \'BAAI/bge-small-en-v1.5\'\r\nembeddings = HuggingFaceEmbeddings(\r\n    model_name=embedding_model_name,\r\n    model_kwargs={\'device\': \'cuda:0\'}\r\n)\r\n\r\nresponse_generation_pipeline = pipeline(\r\n model=mistral_model,\r\n tokenizer=tokenizer,\r\n task="text-generation",\r\n temperature=0.1,\r\n repetition_penalty=1.1,\r\n return_full_text=True,\r\n max_new_tokens=500,\r\n do_sample=True,\r\n\r\n)\r\nresponse_generation_llm = HuggingFacePipeline(pipeline=response_generation_pipeline)\r\n\r\nnest_asyncio.apply()\r\nloader = PubMedLoader("liver", load_max_docs=10)\r\ndocuments = loader.load()\r\nprint(len(documents))\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm=response_generation_llm,\r\n    critic_llm=response_generation_llm,\r\n    embeddings=embeddings,\r\n)\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=2, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},is_async = False,raise_exceptions=False)\r\n\r\n**Error trace**\r\n File "/home/ubuntu/scp-analyzer/rag-old/test_set.py", line 100, in <module>\r\n    testset = generator.generate_with_langchain_docs(documents, test_size=2, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},is_async = False,raise_exceptions=False)\r\n  File "/home/ubuntu/.local/lib/python3.10/site-packages/ragas/testset/generator.py", line 210, in generate_with_langchain_docs\r\n    return self.generate(\r\n  File "/home/ubuntu/.local/lib/python3.10/site-packages/ragas/testset/generator.py", line 279, in generate\r\n    for n in self.docstore.get_random_nodes(k=test_size)\r\n  File "/home/ubuntu/.local/lib/python3.10/site-packages/ragas/testset/docstore.py", line 329, in get_random_nodes\r\n    nodes = rng.choice(np.array(self.nodes), size=k, p=prob).tolist()\r\n  File "numpy/random/_generator.pyx", line 803, in numpy.random._generator.Generator.choice\r\nValueError: a cannot be empty unless no samples are taken\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n@jjmachan \r\n@shahules786 \r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1109/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1109/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1105',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1105/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1105/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1105/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1105',
  'id': 2413391667,
  'node_id': 'I_kwDOJgX1Gs6P2W8z',
  'number': 1105,
  'title': ' The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead ( For Ragas Version 0.1.10)',
  'user': {'login': 'mb16biswas',
   'id': 64213233,
   'node_id': 'MDQ6VXNlcjY0MjEzMjMz',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/64213233?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/mb16biswas',
   'html_url': 'https: //github.com/mb16biswas',
   'followers_url': 'https: //api.github.com/users/mb16biswas/followers',
   'following_url': 'https: //api.github.com/users/mb16biswas/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/mb16biswas/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/mb16biswas/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/mb16biswas/subscriptions',
   'organizations_url': 'https: //api.github.com/users/mb16biswas/orgs',
   'repos_url': 'https: //api.github.com/users/mb16biswas/repos',
   'events_url': 'https: //api.github.com/users/mb16biswas/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/mb16biswas/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-07-17T11: 43: 38Z',
  'updated_at': '2024-07-23T14: 02: 46Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '\r\n**Description:**\r\n\r\nHi,\r\n\r\nI am currently using the latest version of Ragas (version 0.1.10) and encountering an error when using Ragas with local LLMs from Ollama. Here is my code:\r\n\r\n```python\r\nfrom datasets import load_dataset\r\nimport ragas\r\n\r\nfrom ragas.metrics import (\r\n    answer_relevancy,\r\n    faithfulness,\r\n    context_recall,\r\n    context_precision,\r\n)\r\nfrom langchain_community.chat_models import ChatOllama\r\nfrom ragas import evaluate\r\nfrom langchain_community.embeddings import OllamaEmbeddings\r\n\r\n# Loading the V2 dataset\r\namnesty_qa = load_dataset("explodinggradients/amnesty_qa",
            "english_v2", trust_remote_code=True)\r\namnesty_subset = amnesty_qa[
                  "eval"
            ].select(range(2))\r\n\r\ndf = amnesty_subset.to_pandas()\r\n\r\nlangchain_llm = ChatOllama(model="moondream")\r\nlangchain_embeddings = OllamaEmbeddings(model="moondream")\r\n\r\nresult = evaluate(\r\n    amnesty_subset,\r\n    metrics=[context_precision, faithfulness, answer_relevancy, context_recall
            ],\r\n    llm=langchain_llm,\r\n    embeddings=langchain_embeddings\r\n)\r\n\r\n```\r\n**The Error Message:**\r\nExceptionInRunner: The runner thread which was running the jobs raised an exception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` in case you want to show only a warning message instead.\r\n\r\n**Current Solution**\r\n\r\nHowever, if I downgrade the Ragas version from 0.1.10 to 0.1.7, the error is resolved. I thought I should report this issue, thus I reported it here.\r\n\r\nThank you for your assistance.\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1105/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1105/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1104',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1104/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1104/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1104/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1104',
  'id': 2411518968,
  'node_id': 'I_kwDOJgX1Gs6PvNv4',
  'number': 1104,
  'title': 'RAGAS Framework into CI/CD Model for RAG Pipeline',
  'user': {'login': 'maraevfd',
   'id': 48651314,
   'node_id': 'MDQ6VXNlcjQ4NjUxMzE0',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/48651314?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/maraevfd',
   'html_url': 'https: //github.com/maraevfd',
   'followers_url': 'https: //api.github.com/users/maraevfd/followers',
   'following_url': 'https: //api.github.com/users/maraevfd/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/maraevfd/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/maraevfd/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/maraevfd/subscriptions',
   'organizations_url': 'https: //api.github.com/users/maraevfd/orgs',
   'repos_url': 'https: //api.github.com/users/maraevfd/repos',
   'events_url': 'https: //api.github.com/users/maraevfd/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/maraevfd/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-07-16T15: 48: 46Z',
  'updated_at': '2024-07-25T06: 06: 02Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[x] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nHow can we use RAGAS within a CI/CD model for a RAG pipeline?\r\n\r\n**Additional context**\r\nOur team is currently working on a Retrieval-Augmented Generation (RAG) pipeline to process our extensive repository of presentations and various documents. For testing purposes, we decided to try out the RAGAS framework to integrate end-to-end automated tests into the pipeline and dynamically evaluate its metrics in practice. However, we haven't found any examples of using RAGAS in the context of test automation frameworks, only its integration into existing RAG pipelines as shown in the examples.\r\n\r\nFrom your perspective, is it feasible to apply RAGAS in this manner, and are we on the right track? Or is it necessary to fully integrate RAGAS into the system to derive any benefit from it?\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1104/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1104/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1102',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1102/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1102/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1102/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1102',
  'id': 2408956046,
  'node_id': 'I_kwDOJgX1Gs6PlcCO',
  'number': 1102,
  'title': 'getting "asyncio.exceptions.CancelledError" error whenever I run a simple script using ragas',
  'user': {'login': 'edgekid',
   'id': 40468578,
   'node_id': 'MDQ6VXNlcjQwNDY4NTc4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/40468578?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/edgekid',
   'html_url': 'https: //github.com/edgekid',
   'followers_url': 'https: //api.github.com/users/edgekid/followers',
   'following_url': 'https: //api.github.com/users/edgekid/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/edgekid/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/edgekid/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/edgekid/subscriptions',
   'organizations_url': 'https: //api.github.com/users/edgekid/orgs',
   'repos_url': 'https: //api.github.com/users/edgekid/repos',
   'events_url': 'https: //api.github.com/users/edgekid/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/edgekid/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-07-15T14: 58: 22Z',
  'updated_at': '2024-08-02T05: 21: 59Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nGetting "asyncio.exceptions.CancelledError" as an error\r\n\r\nRagas version:\r\nPython version: 3.10\r\n\r\n**Code to Reproduce**\r\n```\r\nfrom datasets import Dataset\r\nfrom ragas.metrics import answer_relevancy, faithfulness\r\nfrom ragas import evaluate\r\n\r\ndata_samples = {\r\n    \'question\': ["How are you?"],\r\n    \'answer\': ["It\'s raining."],\r\n    \'contexts\' : [["I\'m feeling sad today. It\'s raining and I can\'t go outside."]],\r\n}\r\ndataset = Dataset.from_dict(data_samples)\r\nscore = evaluate(dataset, metrics=[faithfulness], raise_exceptions=False)\r\nscore.to_pandas()\r\n```\r\n\r\n**Error trace**\r\n```\r\nEvaluating:   0%|                                                                                                                                                                                                      | 0/1 [00:00<?, ?it/s]Runner in Executor raised an exception\r\nTraceback (most recent call last):\r\n  File "/*****/python3.10/site-packages/openai/_base_client.py", line 1599, in _request\r\n    response.raise_for_status()\r\n  File "/*****/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status\r\n    raise HTTPStatusError(message, request=request, response=self)\r\nhttpx.HTTPStatusError: Client error \'429 Too Many Requests\' for url \'https://api.openai.com/v1/chat/completions\'\r\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "/*****/python3.10/site-packages/openai/_base_client.py", line 1605, in _request\r\n    return await self._retry_request(\r\n  File "/*****/python3.10/site-packages/openai/_base_client.py", line 1605, in _request\r\n    return await self._retry_request(\r\n  File "/*****/python3.10/asyncio/tasks.py", line 605, in sleep\r\n    return await future\r\nasyncio.exceptions.CancelledError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "/*****/python3.10/site-packages/ragas/metrics/_faithfulness.py", line 248, in _ascore\r\n    statements = await self.llm.generate(\r\n  File "/*****/python3.10/site-packages/ragas/llms/base.py", line 93, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "/*****/python3.10/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n  File "/*****/python3.10/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "/*****/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter\r\n    result = await action(retry_state)\r\n  File "/*****/python3.10/site-packages/tenacity/_utils.py", line 99, in inner\r\n    return call(*args, **kwargs)\r\n  File "/*****/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>\r\n    self._add_action_func(lambda rs: rs.outcome.result())\r\n  File "/*****/python3.10/concurrent/futures/_base.py", line 451, in result\r\n    return self.__get_result()\r\n  File "/*****/python3.10/concurrent/futures/_base.py", line 403, in __get_result\r\n    raise self._exception\r\n  File "/*****/python3.10/site-packages/tenacity/asyncio/__init__.py", line 114, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "/*****/python3.10/site-packages/ragas/llms/base.py", line 170, in agenerate_text\r\n    return await self.langchain_llm.agenerate_prompt(\r\n  File "/*****/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 708, in agenerate_prompt\r\n    return await self.agenerate(\r\n  File "/*****/python3.10/site-packages/langchain_core/language_models/chat_models.py", line 634, in agenerate\r\n    results = await asyncio.gather(\r\nasyncio.exceptions.CancelledError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "/*****/python3.10/asyncio/tasks.py", line 456, in wait_for\r\n    return fut.result()\r\nasyncio.exceptions.CancelledError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "/*****/python3.10/site-packages/ragas/executor.py", line 104, in wrapped_callable_async\r\n    result = await callable(*args, **kwargs)\r\n  File "/*****/python3.10/site-packages/ragas/metrics/base.py", line 134, in ascore\r\n    raise e\r\n  File "/*****/python3.10/site-packages/ragas/metrics/base.py", line 127, in ascore\r\n    score = await asyncio.wait_for(\r\n  File "/*****/python3.10/asyncio/tasks.py", line 458, in wait_for\r\n    raise exceptions.TimeoutError() from exc\r\nasyncio.exceptions.TimeoutError\r\nEvaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:20<00:00, 80.01s/it]\r\n/*****/python3.10/site-packages/ragas/evaluation.py:304: RuntimeWarning: Mean of empty slice\r\n  value = np.nanmean(self.scores[cn])\r\n{\'faithfulness\': nan}\r\n```\r\n**Expected behavior**\r\nExpected to output the faithfulness score without any errors.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1102/reactions',
   'total_count': 6,
   '+1': 6,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1102/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1101',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1101/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1101/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1101/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1101',
  'id': 2408946064,
  'node_id': 'I_kwDOJgX1Gs6PlZmQ',
  'number': 1101,
  'title': 'Automatic language adaptater is not working',
  'user': {'login': 'Jeerhz',
   'id': 124576363,
   'node_id': 'U_kgDOB2ziaw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/124576363?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Jeerhz',
   'html_url': 'https: //github.com/Jeerhz',
   'followers_url': 'https: //api.github.com/users/Jeerhz/followers',
   'following_url': 'https: //api.github.com/users/Jeerhz/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Jeerhz/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Jeerhz/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Jeerhz/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Jeerhz/orgs',
   'repos_url': 'https: //api.github.com/users/Jeerhz/repos',
   'events_url': 'https: //api.github.com/users/Jeerhz/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Jeerhz/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 21,
  'created_at': '2024-07-15T14: 53: 50Z',
  'updated_at': '2024-08-08T15: 41: 43Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I have followed the steps of the "How-To-Guide" about Automatic Language Adaptation (https: //docs.ragas.io/en/v0.1.9/howtos/applications/use_prompt_adaptation.html) and  tried to modify the already implemented classes but I could not resolve my problem.\r\n\r\n**Describe the bug**\r\n- The adapt function returns a json format problem\r\n- When I try to adapt the metrics classes with my llm, I have a problem since it calls a non existing method for the llm generate_text. When I try to pass the LangchainWrapper instead of the LLM directly, i have a problem since it is calling this time the metod generate_prompt...\r\n\r\nRagas version:0.1.10\r\nPython version:3.12.4\r\n\r\n**Code to Reproduce**\r\n```python\r\nimport os\r\n\r\n# Setting up the OpenAI API key\r\nopenai_api_key = "your_openai_key"\r\nos.environ["OPENAI_API_KEY"] = openai_api_key\r\nfrom datasets import load_dataset, Dataset\r\n\r\nhindi_dataset = load_dataset("explodinggradients/amnesty_qa","hindi")\r\nhindi_dataset\r\n\r\nfrom ragas.metrics import (\r\n    faithfulness,\r\n    answer_correctness,\r\n)\r\nfrom langchain.chat_models import ChatOpenAI\r\nfrom ragas import adapt\r\n\r\n# llm used for adaptation\r\nopenai_model = ChatOpenAI(model_name="gpt-4")\r\n\r\nadapt(metrics=[faithfulness,answer_correctness], language="hindi", llm=openai_model)\r\n\r\nprint(answer_correctness.correctness_prompt.to_string())\r\n\r\n```\r\n\r\n**Error trace**\r\nTraceback (most recent call last):\r\n  File "c:\\Users\\adles\\Downloads\\base.py", line 21, in <module>\r\n    adapt(metrics=[faithfulness,answer_correctness], language="hindi", llm=openai_model)\r\n  File "C:\\Users\\adles\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\adaptation.py", line 36, in adapt\r\n    metric.adapt(language, cache_dir=cache_dir)\r\n  File "C:\\Users\\adles\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py", line 306, in adapt      \r\n    self.nli_statements_message = self.nli_statements_message.adapt(\r\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "C:\\Users\\adles\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\llms\\prompt.py", line 181, in adapt\r\n    return self._load(language, self.name, cache_dir)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "C:\\Users\\adles\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ragas\\llms\\prompt.py", line 275, in _load\r\n    return cls(**json.load(open(path)))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "C:\\Users\\adles\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\v1\\main.py", line 341, in __init__\r\n    raise validation_error\r\npydantic.v1.error_wrappers.ValidationError: 1 validation error for Prompt\r\n__root__\r\n  answer in example 1 is not in valid json format: Expecting value: line 1 column 1 (char 0) (type=value_error)\r\n**Expected behavior**\r\nTo inspect the adapted prompt belonging to the answer correctness metric\r\n\r\n**Additional context**\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. --> \r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1101/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1101/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1100',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1100/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1100/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1100/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1100',
  'id': 2408721128,
  'node_id': 'I_kwDOJgX1Gs6Pkiro',
  'number': 1100,
  'title': 'Local LLM with Ragas evaluation issue',
  'user': {'login': 'SalwaMostafa',
   'id': 37854037,
   'node_id': 'MDQ6VXNlcjM3ODU0MDM3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/37854037?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/SalwaMostafa',
   'html_url': 'https: //github.com/SalwaMostafa',
   'followers_url': 'https: //api.github.com/users/SalwaMostafa/followers',
   'following_url': 'https: //api.github.com/users/SalwaMostafa/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/SalwaMostafa/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/SalwaMostafa/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/SalwaMostafa/subscriptions',
   'organizations_url': 'https: //api.github.com/users/SalwaMostafa/orgs',
   'repos_url': 'https: //api.github.com/users/SalwaMostafa/repos',
   'events_url': 'https: //api.github.com/users/SalwaMostafa/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/SalwaMostafa/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 6,
  'created_at': '2024-07-15T13: 15: 30Z',
  'updated_at': '2024-08-08T04: 10: 42Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nI am trying to use a local LLM in the evaluate function., where the LLM is imported from Langchain but it gives this error and I do not understand what I should do ? Should I use these wrappers\r\n\r\n"langchain_llm = LangchainLLMWrapper(langchain_llm)\r\nlangchain_embeddings = LangchainEmbeddingsWrapper(langchain_embeddings)"\r\n\r\n\r\nEvaluating:   0%|          | 0/2 [00:00<?, ?it/s]GGML_ASSERT: /run/nvme/job_3577603/tmp/pip-install-aob_qv9b/llama-cpp-python_08d8f9c1210e4408948636399a5c41c8/vendor/llama.cpp/ggml/src/ggml.c:6142: mask->ne[0] == a->ne[0]\r\n[New LWP 3089486]\r\n[New LWP 3089488]\r\n[New LWP 3089489]\r\n[New LWP 3089490]\r\n[New LWP 3089491]\r\n[New LWP 3089492]\r\n[New LWP 3089493]\r\n[New LWP 3089494]\r\n[New LWP 3089495]\r\n[New LWP 3089509]\r\n[New LWP 3089510]\r\n[New LWP 3089512]\r\n[New LWP 3089513]\r\n[New LWP 3089514]\r\n[New LWP 3089515]\r\n[New LWP 3089516]\r\n[New LWP 3089517]\r\n[New LWP 3089518]\r\n[New LWP 3089522]\r\n[New LWP 3089523]\r\n[New LWP 3089534]\r\n[New LWP 3089537]\r\n[New LWP 3089538]\r\n[New LWP 3089539]\r\n[New LWP 3089540]\r\n[New LWP 3089541]\r\n[New LWP 3089542]\r\n[New LWP 3089544]\r\n[New LWP 3089545]\r\n[New LWP 3089546]\r\n[New LWP 3089547]\r\n[New LWP 3089548]\r\n[New LWP 3089549]\r\n[New LWP 3089550]\r\n[New LWP 3089551]\r\n[New LWP 3089552]\r\n[New LWP 3089553]\r\n[New LWP 3089554]\r\n[New LWP 3089555]\r\n[New LWP 3089556]\r\n[New LWP 3089557]\r\n[New LWP 3089558]\r\n[New LWP 3089559]\r\n[New LWP 3089560]\r\n[New LWP 3089561]\r\n[New LWP 3089562]\r\n[New LWP 3089563]\r\n[New LWP 3089564]\r\n[New LWP 3089565]\r\n[New LWP 3089566]\r\n[New LWP 3089567]\r\n[New LWP 3089568]\r\n[New LWP 3089569]\r\n[New LWP 3089570]\r\n[New LWP 3089571]\r\n[New LWP 3089572]\r\n[New LWP 3089573]\r\n[New LWP 3089574]\r\n[New LWP 3089575]\r\n[New LWP 3089576]\r\n[New LWP 3089577]\r\n[New LWP 3089578]\r\n[New LWP 3089579]\r\n[New LWP 3089580]\r\n[New LWP 3089581]\r\n[New LWP 3089582]\r\n[New LWP 3089583]\r\n[New LWP 3089584]\r\n[New LWP 3089585]\r\n[New LWP 3089586]\r\n[New LWP 3089587]\r\n[New LWP 3089588]\r\n[New LWP 3089589]\r\n[New LWP 3089590]\r\n[New LWP 3089591]\r\n[New LWP 3089592]\r\n[New LWP 3089593]\r\n[New LWP 3089594]\r\n[New LWP 3089595]\r\n[New LWP 3089596]\r\n[New LWP 3089597]\r\n[New LWP 3089598]\r\n[New LWP 3089599]\r\n[New LWP 3089600]\r\n[New LWP 3089601]\r\n[New LWP 3089602]\r\n[New LWP 3089603]\r\n[New LWP 3089604]\r\n[New LWP 3089605]\r\n[New LWP 3089606]\r\n[New LWP 3089607]\r\n[New LWP 3089608]\r\n[New LWP 3089609]\r\n[New LWP 3089610]\r\n[New LWP 3089611]\r\n[New LWP 3089612]\r\n[New LWP 3089613]\r\n[New LWP 3089614]\r\n[New LWP 3089615]\r\n[New LWP 3089616]\r\n[New LWP 3089617]\r\n[New LWP 3089618]\r\n[New LWP 3089619]\r\n[New LWP 3089620]\r\n[New LWP 3089621]\r\n[New LWP 3089622]\r\n[New LWP 3089623]\r\n[New LWP 3089624]\r\n[New LWP 3089625]\r\n[New LWP 3089626]\r\n[New LWP 3089627]\r\n[New LWP 3089628]\r\n[New LWP 3089629]\r\n[New LWP 3089630]\r\n[New LWP 3089631]\r\n[New LWP 3089632]\r\n[New LWP 3089633]\r\n[New LWP 3089634]\r\n[New LWP 3089635]\r\n[New LWP 3089636]\r\n[New LWP 3089637]\r\n[New LWP 3089638]\r\n[New LWP 3089639]\r\n[New LWP 3089640]\r\n[New LWP 3089641]\r\n[New LWP 3089642]\r\n[New LWP 3089643]\r\n[New LWP 3089644]\r\n[New LWP 3089645]\r\n[New LWP 3089646]\r\n[New LWP 3089647]\r\n[New LWP 3089648]\r\n[New LWP 3089649]\r\n[New LWP 3089650]\r\n[New LWP 3089651]\r\n[New LWP 3089652]\r\n[New LWP 3089653]\r\n[New LWP 3089654]\r\n[New LWP 3089655]\r\n[New LWP 3089656]\r\n[New LWP 3089657]\r\n[New LWP 3089658]\r\n[New LWP 3089659]\r\n[New LWP 3089660]\r\n[New LWP 3089661]\r\n[New LWP 3089662]\r\n[New LWP 3089663]\r\n[New LWP 3089664]\r\n[New LWP 3089665]\r\n[New LWP 3089666]\r\n[New LWP 3089667]\r\n[New LWP 3089668]\r\n[New LWP 3089669]\r\n[New LWP 3089670]\r\n[New LWP 3089671]\r\n[New LWP 3089672]\r\n[New LWP 3089673]\r\n[New LWP 3089674]\r\n[New LWP 3089675]\r\n[New LWP 3089676]\r\n[New LWP 3089677]\r\n[New LWP 3089678]\r\n[New LWP 3089679]\r\n[New LWP 3089680]\r\n[New LWP 3089681]\r\n[New LWP 3089682]\r\n[New LWP 3089683]\r\n[New LWP 3089684]\r\n[New LWP 3089685]\r\n[New LWP 3089686]\r\n[New LWP 3089687]\r\n[New LWP 3089688]\r\n[New LWP 3089689]\r\n[New LWP 3089690]\r\n[New LWP 3089691]\r\n[New LWP 3089692]\r\n[New LWP 3089693]\r\n[New LWP 3089694]\r\n[New LWP 3089695]\r\n[New LWP 3089696]\r\n[New LWP 3089697]\r\n[New LWP 3089698]\r\n[New LWP 3089699]\r\n[New LWP 3089700]\r\n[New LWP 3089701]\r\n[New LWP 3089702]\r\n[New LWP 3089703]\r\n[New LWP 3089704]\r\n[New LWP 3089705]\r\n[New LWP 3089706]\r\n[New LWP 3089707]\r\n[New LWP 3089708]\r\n[New LWP 3089709]\r\n[New LWP 3089710]\r\n[New LWP 3089711]\r\n[New LWP 3089712]\r\n[New LWP 3089713]\r\n[New LWP 3089714]\r\n[New LWP 3089715]\r\n[New LWP 3089716]\r\n[New LWP 3089717]\r\n[New LWP 3089718]\r\n[New LWP 3089719]\r\n[New LWP 3089720]\r\n[New LWP 3089721]\r\n[New LWP 3089722]\r\n[New LWP 3089723]\r\n[New LWP 3089724]\r\n[New LWP 3089725]\r\n[New LWP 3089726]\r\n[New LWP 3089727]\r\n[New LWP 3089728]\r\n[New LWP 3089729]\r\n[New LWP 3089730]\r\n[New LWP 3089731]\r\n[New LWP 3089732]\r\n[New LWP 3089733]\r\n[New LWP 3089734]\r\n[New LWP 3089735]\r\n[New LWP 3089736]\r\n[New LWP 3089737]\r\n[New LWP 3089738]\r\n[New LWP 3089739]\r\n[New LWP 3089740]\r\n[New LWP 3089741]\r\n[New LWP 3089742]\r\n[New LWP 3089743]\r\n[New LWP 3089744]\r\n[New LWP 3089745]\r\n[New LWP 3089746]\r\n[New LWP 3089747]\r\n[New LWP 3089748]\r\n[New LWP 3089749]\r\n[New LWP 3089750]\r\n[New LWP 3089751]\r\n[New LWP 3089752]\r\n[New LWP 3089753]\r\n[New LWP 3089754]\r\n[New LWP 3089755]\r\n[New LWP 3089756]\r\n[New LWP 3089757]\r\n[New LWP 3089758]\r\n[New LWP 3089759]\r\n[New LWP 3089760]\r\n[New LWP 3089761]\r\n[New LWP 3089762]\r\n[New LWP 3089763]\r\n[New LWP 3089764]\r\n[New LWP 3089765]\r\n[New LWP 3089766]\r\n[New LWP 3089767]\r\n[New LWP 3089768]\r\n[New LWP 3089769]\r\n[New LWP 3089770]\r\n[New LWP 3089771]\r\n[New LWP 3089772]\r\n[New LWP 3089773]\r\n[New LWP 3089774]\r\n[New LWP 3089775]\r\n[New LWP 3089776]\r\n[New LWP 3089777]\r\n[New LWP 3089778]\r\n[New LWP 3089779]\r\n[New LWP 3089780]\r\n[New LWP 3089781]\r\n[New LWP 3089782]\r\n[New LWP 3089783]\r\n[New LWP 3089784]\r\n[New LWP 3089785]\r\n[New LWP 3089786]\r\n[New LWP 3089787]\r\n[New LWP 3089788]\r\n[New LWP 3089789]\r\n[New LWP 3089790]\r\n[New LWP 3089791]\r\n[New LWP 3089792]\r\n[New LWP 3089793]\r\n[New LWP 3089794]\r\n[New LWP 3089795]\r\n[New LWP 3089796]\r\n[New LWP 3089797]\r\n[New LWP 3089798]\r\n[New LWP 3089799]\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library "/lib64/libthread_db.so.1".\r\n0x00007fffbf2b8da6 in do_futex_wait.constprop () from /lib64/libpthread.so.0\r\n#0  0x00007fffbf2b8da6 in do_futex_wait.constprop () from /lib64/libpthread.so.0\r\n#1  0x00007fffbf2b8e98 in __new_sem_wait_slow.constprop.0 () from /lib64/libpthread.so.0\r\n#2  0x00007fffbf89c678 in PyThread_acquire_lock_timed () from /lib64/libpython3.9.so.1.0\r\n#3  0x00007fffbf89cdd9 in lock_PyThread_acquire_lock () from /lib64/libpython3.9.so.1.0\r\n#4  0x00007fffbf8aef4f in method_vectorcall_VARARGS_KEYWORDS () from /lib64/libpython3.9.so.1.0\r\n#5  0x00007fffbf8f8248 in _PyEval_EvalFrameDefault () from /lib64/libpython3.9.so.1.0\r\n#6  0x00007fffbf8bc465 in _PyFunction_Vectorcall () from /lib64/libpython3.9.so.1.0\r\n#7  0x00007fffbf8f8248 in _PyEval_EvalFrameDefault () from /lib64/libpython3.9.so.1.0\r\n#8  0x00007fffbf8bc465 in _PyFunction_Vectorcall () from /lib64/libpython3.9.so.1.0\r\n#9  0x00007fffbf8f8248 in _PyEval_EvalFrameDefault () from /lib64/libpython3.9.so.1.0\r\n#10 0x00007fffbf87c693 in function_code_fastcall () from /lib64/libpython3.9.so.1.0\r\n#11 0x00007fffbf8bc0ea in _PyFunction_Vectorcall () from /lib64/libpython3.9.so.1.0\r\n#12 0x00007fffbf8f8248 in _PyEval_EvalFrameDefault () from /lib64/libpython3.9.so.1.0\r\n#13 0x00007fffbf8bc465 in _PyFunction_Vectorcall () from /lib64/libpython3.9.so.1.0\r\n#14 0x00007fffbf8f8dfd in _PyEval_EvalFrameDefault () from /lib64/libpython3.9.so.1.0\r\n#15 0x00007fffbf8b8713 in _PyEval_EvalCode () from /lib64/libpython3.9.so.1.0\r\n#16 0x00007fffbf8b970f in _PyEval_EvalCodeWithName () from /lib64/libpython3.9.so.1.0\r\n#17 0x00007fffbf8b9743 in PyEval_EvalCode () from /lib64/libpython3.9.so.1.0\r\n#18 0x00007fffbf96adad in run_eval_code_obj () from /lib64/libpython3.9.so.1.0\r\n#19 0x00007fffbf97eb0a in run_mod () from /lib64/libpython3.9.so.1.0\r\n#20 0x00007fffbf80e2f6 in pyrun_file.cold () from /lib64/libpython3.9.so.1.0\r\n#21 0x00007fffbf97f325 in PyRun_SimpleFileExFlags () from /lib64/libpython3.9.so.1.0\r\n#22 0x00007fffbf97f7d2 in Py_RunMain () from /lib64/libpython3.9.so.1.0\r\n#23 0x00007fffbf97f919 in Py_BytesMain () from /lib64/libpython3.9.so.1.0\r\n#24 0x00007fffbe793d85 in __libc_start_main () from /lib64/libc.so.6\r\n#25 0x000055555555475e in _start ()\r\n[Inferior 1 (process 3089452) detached]\r\n/appl/soft/ai/bin/apptainer_wrapper: line 38: 3089434 Aborted                 apptainer --silent exec $SING_FLAGS $SING_IMAGE "${@:2}"\r\n\r\nRagas version:\r\nPython version:\r\n\r\n**Code to Reproduce**\r\n\r\nfrom ragas.metrics import (answer_relevancy,faithfulness,context_recall,context_precision)\r\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\r\nfrom huggingface_hub import hf_hub_download, snapshot_download\r\nfrom langchain.callbacks.manager import CallbackManager\r\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\r\nfrom langchain_community.llms import LlamaCpp\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on January 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n    \'contexts\' : [[\'The Super Bowl....season since 1966,\',\'replacing the NFL...in February.\'], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\']],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n}\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nembedding_model_name = "sentence-transformers/msmarco-bert-base-dot-v5"\r\nembed_model = HuggingFaceEmbedding(model_name=embedding_model_name)\r\n\r\nfrom langchain_core.language_models import BaseLanguageModel\r\nfrom langchain_core.embeddings import Embeddings\r\n\r\ncritic_llm = LlamaCpp(\r\n    model_path="./Hermes-2-Pro-Llama-3-8B-Q4_K_M.gguf",\r\n    n_gpu_layers=1,\r\n    n_batch=512,\r\n    n_ctx=2048,\r\n    f16_kv=True,\r\n    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\r\n    verbose=True,\r\n)\r\n\r\n\r\nfrom ragas import evaluate\r\n\r\nresult_context_precision = evaluate(dataset,metrics=[context_precision], llm=critic_llm)\r\nresult_context_recall = evaluate(dataset, metrics=[context_recall], llm=critic_llm)\r\n\r\nresults = result_context_precision | result_context_recall\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1100/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1100/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1099',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1099/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1099/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1099/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1099',
  'id': 2408541843,
  'node_id': 'I_kwDOJgX1Gs6Pj26T',
  'number': 1099,
  'title': 'Getting Error: Runner in Executor raised an exception in Ragas evaluate using Ollama and giving Nan value in df',
  'user': {'login': 'divrajput',
   'id': 86051905,
   'node_id': 'MDQ6VXNlcjg2MDUxOTA1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/86051905?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/divrajput',
   'html_url': 'https: //github.com/divrajput',
   'followers_url': 'https: //api.github.com/users/divrajput/followers',
   'following_url': 'https: //api.github.com/users/divrajput/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/divrajput/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/divrajput/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/divrajput/subscriptions',
   'organizations_url': 'https: //api.github.com/users/divrajput/orgs',
   'repos_url': 'https: //api.github.com/users/divrajput/repos',
   'events_url': 'https: //api.github.com/users/divrajput/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/divrajput/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 4,
  'created_at': '2024-07-15T11: 51: 34Z',
  'updated_at': '2024-08-06T06: 08: 20Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I encountered an issue while evaluating a dataset using the ragas library with the Langchain LLM and Sentence Transformer embeddings. The process throws an exception during execution.\r\n**Steps to Reproduce:**\r\n```py\r\n#Reading the DataFrame:\r\nimport pandas as pd\r\ndf = pd.read_csv("test_results_csv/test.csv")\r\ndf[
                  "contexts"
            ] = df[
                  "contexts"
            ].apply(lambda x: [x
            ])\r\nfrom datasets import Dataset\r\ndataset = Dataset.from_pandas(df)\r\ndataset[
                  0
            ]\r\n```\r\n**Output:**\r\n```\r\n{\r\n    \'question\': \'What are the major sources of carbohydrates in the traditional Hawaiian diet?\',\r\n    \'ground_truth\': "The traditional Hawaiian diet was rich in carbohydrate sources primarily derived from \'uala (sweet potato), ulu (breadfruit), and kalo (taro). These foods were not only staple items but also provided a significant portion of the daily caloric intake. Sweet potatoes, breadfruit, and taro were cultivated extensively and formed the backbone of the Hawaiian nutritional intake, ensuring that the population had a steady and reliable source of energy. The high carbohydrate content of these foods supported the physical demands of daily activities and agricultural work.",\r\n    \'answer\': \' The majority of the diet was made up of these fiber rich carbohydrate foods.\',\r\n    \'contexts\': ["[\'•  Describe the different types of simple and complex  carbohydrates  •  Describe the process of carbohydrate digestion and  absorption  •  Describe the functions of carbohydrates in the  body  •  Describe the body’s carbohydrate needs and how  personal choices can lead to health benefits or  consequences  Throughout history, carbohydrates have and continue to be a major  source of people’s diets worldwide. In ancient Hawai‘i the Hawaiians  obtained the majority of their calories from carbohydrate rich plants  like the ‘uala (sweet potato), ulu (breadfruit) and kalo (taro). For  example, mashed kalo or poi was a staple to meals for Hawaiians.  Research suggests that almost 78 percent of the diet was made up  of these fiber rich carbohydrate foods.1  Carbohydrates are the perfect nutrient to meet your body’s  nutritional needs. They nourish your brain and nervous system,  provide energy to all of your cells when within proper caloric limits,  and help keep your body fit and lean.\', \'body fit and lean. Specifically, digestible  carbohydrates provide bulk in foods, vitamins, and minerals, while  1.\\\\xa0Fujita R, Braun KL, Hughes CK. (2004). The traditional  Hawaiian diet: a review of the literature. Pacific Health  Dialogue, 11(2). http:/ [/pacifichealthdialog.org.fj/](https://file+.vscode-resource.vscode-cdn.net/pacifichealthdialog.org.fj/) Volume2011/no2/ PHD1120220p2162022120Yamada20orig.pdf. Accessed  October 19, 2017.  230  |  Introduction\']"
                  ]\r\n
            }\r\n```\r\n**Setting Up the Environment:**\r\n```py\r\nfrom langchain_community.embeddings.sentence_transformer import (\r\n    SentenceTransformerEmbeddings,\r\n)\r\nfrom ragas.llms import LangchainLLMWrapper\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\n\r\nfrom langchain_community.llms import Ollama\r\n\r\nllm = Ollama(model="mistrallite_Q2_K:latest", temperature=0)\r\nembeddings = SentenceTransformerEmbeddings(model_name=\'all-MiniLM-L6-v2\')\r\nlangchain_llm = LangchainLLMWrapper(llm)\r\nlangchain_embeddings = LangchainEmbeddingsWrapper(embeddings)\r\n\r\nimport nest_asyncio\r\nnest_asyncio.apply()\r\nfrom ragas import evaluate\r\nfrom ragas.run_config import RunConfig\r\n\r\nfrom ragas.metrics import (\r\n    faithfulness,\r\n    answer_relevancy,\r\n    context_recall,\r\n    context_precision,\r\n)\r\n\r\nresult = evaluate(\r\n    dataset=dataset,\r\n    metrics=[\r\n        context_precision,\r\n        context_recall,\r\n        faithfulness,\r\n        answer_relevancy,\r\n
            ],\r\n    raise_exceptions=False,\r\n    llm=langchain_llm,\r\n    embeddings=langchain_embeddings\r\n)\r\n\r\nres_df = result.to_pandas()\r\n```\r\n**Error**\r\n```\r\nRunner in Executor raised an exception\r\nTraceback (most recent call last):\r\n  File "/Users/xxx/miniconda3/lib/python3.12/asyncio/tasks.py", line 520, in wait_for\r\n    return await fut\r\n           ^^^^^^^^^\r\n  File "/Users/xxx/miniconda3/lib/python3.12/site-packages/ragas/metrics/_context_recall.py", line 169, in _ascore\r\n    results = await self.llm.generate(\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/xxx/miniconda3/lib/python3.12/site-packages/ragas/llms/base.py", line 93, in generate\r\n    return await agenerate_text_with_retry(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/xxx/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/xxx/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 111, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/xxx/miniconda3/lib/python3.12/site-packages/tenacity/asyncio/__init__.py", line 153, in iter\r\n    result = await action(retry_state)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/xxx/miniconda3/lib/python3.12/site-packages/tenacity/_utils.py", line 99, in inner\r\n    return call(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/xxx/miniconda3/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>\r\n    self._add_action_func(lambda rs: rs.outcome.result())\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1099/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1099/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1098',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1098/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1098/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1098/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1098',
  'id': 2407514711,
  'node_id': 'I_kwDOJgX1Gs6Pf8JX',
  'number': 1098,
  'title': 'Do we need to chunk documents before text set generation?',
  'user': {'login': 'hanfei1986',
   'id': 59255164,
   'node_id': 'MDQ6VXNlcjU5MjU1MTY0',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/59255164?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/hanfei1986',
   'html_url': 'https: //github.com/hanfei1986',
   'followers_url': 'https: //api.github.com/users/hanfei1986/followers',
   'following_url': 'https: //api.github.com/users/hanfei1986/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/hanfei1986/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/hanfei1986/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/hanfei1986/subscriptions',
   'organizations_url': 'https: //api.github.com/users/hanfei1986/orgs',
   'repos_url': 'https: //api.github.com/users/hanfei1986/repos',
   'events_url': 'https: //api.github.com/users/hanfei1986/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/hanfei1986/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-07-14T16: 56: 51Z',
  'updated_at': '2024-07-30T06: 55: 31Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'The embedding model is used for TestsetGenerator:\r\n```py\r\ngenerator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embedding_model)\r\ndataset = generator.generate_with_langchain_docs(documents, test_size=100, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25
            })\r\n```\r\nDoes this mean we have to chunk the documents to make documents shorter than the max_seq_length of the embedding model?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1098/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1098/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1091',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1091/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1091/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1091/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1091',
  'id': 2404916128,
  'node_id': 'I_kwDOJgX1Gs6PWBug',
  'number': 1091,
  'title': '[R-278
            ] Battle test experimental synthetic data generation',
  'user': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                  ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
            },
  'comments': 0,
  'created_at': '2024-07-12T07: 13: 02Z',
  'updated_at': '2024-09-02T07: 06: 51Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '- [X
            ] Test generation from blogs\n  - [X
            ] resolve errors associated with headlines splitter\n- [X
            ] Implement hierarchical splitter\n- [X
            ] Experiment with persona wise generation\n- [] Add next and prev relationships to nodes\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-278](https://linear.app/exploding-gradients/issue/R-278/battle-test-experimental-synthetic-data-generation)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1091/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1091/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1090',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1090/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1090/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1090/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1090',
  'id': 2403208485,
  'node_id': 'I_kwDOJgX1Gs6PPg0l',
  'number': 1090,
  'title': 'RAGAS with huggingface models',
  'user': {'login': 'SalvatoreRa',
   'id': 32837577,
   'node_id': 'MDQ6VXNlcjMyODM3NTc3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/32837577?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/SalvatoreRa',
   'html_url': 'https: //github.com/SalvatoreRa',
   'followers_url': 'https: //api.github.com/users/SalvatoreRa/followers',
   'following_url': 'https: //api.github.com/users/SalvatoreRa/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/SalvatoreRa/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/SalvatoreRa/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/SalvatoreRa/subscriptions',
   'organizations_url': 'https: //api.github.com/users/SalvatoreRa/orgs',
   'repos_url': 'https: //api.github.com/users/SalvatoreRa/repos',
   'events_url': 'https: //api.github.com/users/SalvatoreRa/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/SalvatoreRa/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 7,
  'created_at': '2024-07-11T13: 34: 37Z',
  'updated_at': '2024-08-06T06: 03: 03Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nI tried using RAGAS with a model that is not OpenAI. In general whatever model I use I get this error back:\r\n\r\n```\r\nFile /opt/conda/lib/python3.10/site-packages/ragas/evaluation.py: 237, in evaluate(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\r\n    235 results = executor.results()\r\n    236 if results == []:\r\n--> 237     raise ExceptionInRunner()\r\n    239 # convert results to dataset_like\r\n    240 for i, _ in enumerate(dataset):\r\n\r\nExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass raise_exceptions=False incase you want to show only a warning message instead.\r\n\r\n/opt/conda/lib/python3.10/site-packages/ipykernel/iostream.py: 123: RuntimeWarning: coroutine \'as_completed.<locals>.sema_coro\' was never awaited\r\n  await self._event_pipe_gc()\r\nRuntimeWarning: Enable tracemalloc to get the object allocation traceback\r\n```\r\n\r\nWhich I solved using this:\r\n\r\n```\r\nimport nest_asyncio\r\nnest_asyncio.apply()\r\n```\r\n\r\nHowever, it is not returning error but it is returning:\r\n`{\'faithfulness\': nan, \'answer_relevancy\': nan, \'context_utilization\': nan
            }`\r\n\r\n\r\n\r\n**Code to Reproduce**\r\n```\r\nimport pandas as pd\r\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\r\nfrom sentence_transformers import SentenceTransformer\r\nfrom langchain import HuggingFacePipeline\r\nfrom ragas.metrics import (\r\n    answer_relevancy,\r\n    faithfulness,\r\n    context_recall,\r\n    context_precision,\r\n    context_utilization\r\n)\r\nfrom ragas import evaluate\r\nfrom datasets import Dataset\r\n\r\nimport nest_asyncio\r\nnest_asyncio.apply()\r\n\r\n# embedding model\r\nembedding_model = SentenceTransformer("microsoft/mpnet-base")\r\n\r\n# evaluator\r\nmodel_id = "mistralai/Mistral-7B-Instruct-v0.1"\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\r\n\r\ndevice = 0  # Use GPU (0 is typically the first GPU device)\r\n\r\npipe = pipeline(\r\n    model=model,\r\n    tokenizer=tokenizer,\r\n    return_full_text=True,  # langchain expects the full text\r\n    task=\'text-generation\',\r\n    temperature=0.1,\r\n    do_sample=True,\r\n    max_new_tokens = 200,\r\n    repetition_penalty=1.1  # without this output begins repeating\r\n\r\n)\r\n\r\nevaluator = HuggingFacePipeline(pipeline=pipe)\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'
                  ],\r\n    \'answer\': [\'The first superbowl was held on Jan 15,
                        1967\', \'The most super bowls have been won by The New England Patriots\'
                  ],\r\n    \'contexts\' : [
                        [\'The First AFL–NFL World Championship Game was an American football game played on January 15,
                              1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'
                        ], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\'
                        ]
                  ],\r\n
            }\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\n# ragas\r\nresult = evaluate(\r\n    dataset=dataset,\r\n    llm=evaluator,\r\n    embeddings=embedding_model,\r\n    raise_exceptions=False,\r\n    metrics=[\r\n        faithfulness,\r\n        answer_relevancy,\r\n        context_utilization,\r\n
            ]\r\n)\r\n\r\nprint(result)\r\n```\r\n\r\n**Error trace**\r\nNo error, but basically is not working\r\n**Expected behavior**\r\nIt should return the evaluation metrics\r\n\r\nThank you very much for your help\r\n\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1090/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1090/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1089',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1089/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1089/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1089/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1089',
  'id': 2403117146,
  'node_id': 'I_kwDOJgX1Gs6PPKha',
  'number': 1089,
  'title': 'adapt pydantic.v1.error_wrappers.ValidationError: 1 validation error for Prompt',
  'user': {'login': 'runwean',
   'id': 63044447,
   'node_id': 'MDQ6VXNlcjYzMDQ0NDQ3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/63044447?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/runwean',
   'html_url': 'https: //github.com/runwean',
   'followers_url': 'https: //api.github.com/users/runwean/followers',
   'following_url': 'https: //api.github.com/users/runwean/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/runwean/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/runwean/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/runwean/subscriptions',
   'organizations_url': 'https: //api.github.com/users/runwean/orgs',
   'repos_url': 'https: //api.github.com/users/runwean/repos',
   'events_url': 'https: //api.github.com/users/runwean/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/runwean/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-07-11T12: 55: 09Z',
  'updated_at': '2024-08-14T08: 23: 39Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I want to customize the adapt function,  change the language to Chinese\r\n\r\nthis is code：\r\n```py\r\ncache_dir = ".cache"\r\n\r\nadapt(\r\n    metrics=evaluate_stk,\r\n    language="Chinese",\r\n    cache_dir=cache_dir,\r\n    llm=llm\r\n)\r\n```\r\n\r\nand this is the error\r\n```\r\nTraceback (most recent call last):\r\n  File "/Users/Desktop/side2side-eval/langchain_idealab/ragas_evaluate.py", line 87, in <module>\r\n    adapt(\r\n  File "/Users/opt/anaconda3/envs/self-rag/lib/python3.9/site-packages/ragas/adaptation.py", line 36, in adapt\r\n    metric.adapt(language, cache_dir=cache_dir)\r\n  File "/Users/opt/anaconda3/envs/self-rag/lib/python3.9/site-packages/ragas/metrics/_answer_relevance.py", line 173, in adapt\r\n    self.question_generation = self.question_generation.adapt(\r\n  File "/Users/opt/anaconda3/envs/self-rag/lib/python3.9/site-packages/ragas/llms/prompt.py", line 181, in adapt\r\n    return self._load(language, self.name, cache_dir)\r\n  File "/Users/opt/anaconda3/envs/self-rag/lib/python3.9/site-packages/ragas/llms/prompt.py", line 281, in _load\r\n    return cls(**json.load(open(path)))\r\n  File "/Users/opt/anaconda3/envs/self-rag/lib/python3.9/site-packages/pydantic/v1/main.py", line 341, in __init__\r\n    raise validation_error\r\npydantic.v1.error_wrappers.ValidationError: 1 validation error for Prompt\r\n__root__\r\n  output in example 1 is not in valid json format: Expecting value: line 1 column 1 (char 0) (type=value_error)\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1089/reactions',
   'total_count': 3,
   '+1': 3,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1089/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1087',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1087/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1087/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1087/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1087',
  'id': 2402353172,
  'node_id': 'I_kwDOJgX1Gs6PMQAU',
  'number': 1087,
  'title': 'ValueError: a cannot be empty unless no samples are taken',
  'user': {'login': 'Rugved2204',
   'id': 96412167,
   'node_id': 'U_kgDOBb8iBw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/96412167?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Rugved2204',
   'html_url': 'https: //github.com/Rugved2204',
   'followers_url': 'https: //api.github.com/users/Rugved2204/followers',
   'following_url': 'https: //api.github.com/users/Rugved2204/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Rugved2204/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Rugved2204/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Rugved2204/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Rugved2204/orgs',
   'repos_url': 'https: //api.github.com/users/Rugved2204/repos',
   'events_url': 'https: //api.github.com/users/Rugved2204/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Rugved2204/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 8,
  'created_at': '2024-07-11T06: 23: 19Z',
  'updated_at': '2024-08-06T06: 31: 56Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nValueError: a cannot be empty unless no samples are taken\r\n\r\nRagas version: 0.1.10\r\nPython version:3.10.12\r\n\r\n**Code to Reproduce**\r\nShare code to reproduce the issue\r\n\r\n```py\r\nloader = PubMedLoader("liver", load_max_docs=10)\r\ndocuments = loader.load()\r\n\r\n\r\n\r\nembedding_model_name = \'BAAI/bge-small-en-v1.5\'\r\nembeddings = HuggingFaceEmbeddings(\r\n      model_name=embedding_model_name,\r\n      model_kwargs={\'device\':\'cuda:0\'}\r\n   )\r\n\r\nmodel_name = \'mistralai/Mistral-7B-Instruct-v0.2\'\r\n\r\nresponse_generation_llm = load_model(model_name, 0.1, 1024)\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    response_generation_llm,\r\n    response_generation_llm,\r\n    embeddings\r\n)\r\n\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=2, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\r\n```\r\n\r\n**Error trace**\r\n```\r\nFile "/home/ubuntu/scp-analyzer/rag-old/test_ragas.py", line 31, in <module>\r\n    testset = generator.generate_with_langchain_docs(documents, test_size=2, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\r\n  File "/home/ubuntu/.local/lib/python3.10/site-packages/ragas/testset/generator.py", line 210, in generate_with_langchain_docs\r\n    return self.generate(\r\n  File "/home/ubuntu/.local/lib/python3.10/site-packages/ragas/testset/generator.py", line 279, in generate\r\n    for n in self.docstore.get_random_nodes(k=test_size)\r\n  File "/home/ubuntu/.local/lib/python3.10/site-packages/ragas/testset/docstore.py", line 328, in get_random_nodes\r\n    nodes = rng.choice(np.array(self.nodes), size=k, p=prob).tolist()\r\n  File "numpy/random/_generator.pyx", line 803, in numpy.random._generator.Generator.choice\r\nValueError: a cannot be empty unless no samples are taken\r\n```\r\n\r\n**Expected behavior**\r\nIt should have generated the synthetic testset. Nodes are getting embedded but getting an error while generating\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1087/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1087/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1079',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1079/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1079/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1079/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1079',
  'id': 2398298772,
  'node_id': 'I_kwDOJgX1Gs6O8yKU',
  'number': 1079,
  'title': 'Hook into Runnable RAG chain ',
  'user': {'login': 'amitjoy',
   'id': 13380182,
   'node_id': 'MDQ6VXNlcjEzMzgwMTgy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/13380182?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/amitjoy',
   'html_url': 'https: //github.com/amitjoy',
   'followers_url': 'https: //api.github.com/users/amitjoy/followers',
   'following_url': 'https: //api.github.com/users/amitjoy/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/amitjoy/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/amitjoy/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/amitjoy/subscriptions',
   'organizations_url': 'https: //api.github.com/users/amitjoy/orgs',
   'repos_url': 'https: //api.github.com/users/amitjoy/repos',
   'events_url': 'https: //api.github.com/users/amitjoy/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/amitjoy/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-07-09T13: 53: 20Z',
  'updated_at': '2024-08-08T04: 33: 28Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Your Question**\r\nHow can I integrate EvaluatorChain with an existing Runnable RAG chain?\r\n\r\n**Code Examples**\r\nAn example of chain created using LCEL: \r\n\r\n```python\r\n    def chain(self) -> Runnable:\r\n        """\r\n        Constructs the retrieval chain for the chat agent.\r\n\r\n        :return: A Runnable instance representing the retrieval chain.\r\n        """\r\n        logger.debug("Initializing retrieval from knowledge base chain")\r\n\r\n        history_aware_retriever = create_history_aware_retriever(\r\n            llm=self.vertex.model,\r\n            retriever=self.kb_agent.retriever,\r\n            prompt=self.condense_prompt\r\n        )\r\n        document_chain = create_stuff_documents_chain(\r\n            llm=self.vertex.model,\r\n            prompt=self.prompt\r\n        )\r\n        retrieval_chain = create_retrieval_chain(\r\n            retriever=history_aware_retriever,\r\n            combine_docs_chain=document_chain\r\n        )\r\n\r\n        def get_session_history(session_id: str) -> BaseChatMessageHistory:\r\n            return self.history_agent.message_history\r\n\r\n        return RunnableWithMessageHistory(\r\n            retrieval_chain,\r\n            get_session_history,\r\n            input_messages_key="input",\r\n            history_messages_key="chat_history",\r\n            output_messages_key="answer"\r\n        )\r\n```\r\n\r\n**Additional context**\r\nrunning on latest versions of Langchain and Ragas\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1079/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1079/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1077',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1077/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1077/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1077/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1077',
  'id': 2394866935,
  'node_id': 'I_kwDOJgX1Gs6OvsT3',
  'number': 1077,
  'title': 'How to prompt ragas data generation?',
  'user': {'login': 'atr-ip',
   'id': 60426559,
   'node_id': 'MDQ6VXNlcjYwNDI2NTU5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/60426559?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/atr-ip',
   'html_url': 'https: //github.com/atr-ip',
   'followers_url': 'https: //api.github.com/users/atr-ip/followers',
   'following_url': 'https: //api.github.com/users/atr-ip/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/atr-ip/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/atr-ip/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/atr-ip/subscriptions',
   'organizations_url': 'https: //api.github.com/users/atr-ip/orgs',
   'repos_url': 'https: //api.github.com/users/atr-ip/repos',
   'events_url': 'https: //api.github.com/users/atr-ip/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/atr-ip/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-07-08T07: 29: 00Z',
  'updated_at': '2024-08-02T06: 25: 32Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Does anyone know how to prompt data generation? I would need specific sentence structures. \r\nI tried to reconfigure the prompt itself, but it did not change the generated data sentence by sentence. Does anyone know how to implement this correctly?\r\n\r\n```\r\n       from ragas.llms.prompt import Prompt\r\n\r\n        Prompt(\r\n            name="question_generation",\r\n            instruction="Generate a question for the given answer",\r\n            examples=[\r\n                {\r\n                    "answer": "The last Olympics was held in Tokyo, Japan.",\r\n                    "context": "The last Olympics was held in Tokyo, Japan. It is held every 4 years",\r\n                    "output": {
                              "question": "Where was the last Olympics held?"
                        },\r\n
                  },\r\n                {\r\n                    "answer": "It can change its skin color based on the temperature of its environment.",\r\n                    "context": "A recent scientific study has discovered a new species of frog in the Amazon rainforest that has the unique ability to change its skin color based on the temperature of its environment.",\r\n                    "output": {
                              "question": "What unique ability does the newly discovered species of frog have?"
                        },\r\n
                  }\r\n
            ],\r\n            input_keys=[
                  "answer",
                  "context"
            ],\r\n            output_key="output",\r\n            output_type="json",\r\n        )\r\n\r\n        generator.adapt(language=self.language, evolutions=[simple, reasoning, multi_context
            ], cache_dir=".cache")\r\n        \r\n        generator.generate_with_llamaindex_docs(\r\n            documents=documents,\r\n            test_size=number_of_questions,\r\n            distributions={\r\n                simple: 0.5,\r\n                reasoning: 0.25,\r\n                multi_context: 0.25,\r\n
            },\r\n            with_debugging_logs=True,\r\n            raise_exceptions=False\r\n        )\r\n```\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1077/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1077/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1075',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1075/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1075/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1075/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1075',
  'id': 2394144284,
  'node_id': 'I_kwDOJgX1Gs6Os74c',
  'number': 1075,
  'title': 'Buggy tutorials',
  'user': {'login': 'amr-cloudforce',
   'id': 73740780,
   'node_id': 'MDQ6VXNlcjczNzQwNzgw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/73740780?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/amr-cloudforce',
   'html_url': 'https: //github.com/amr-cloudforce',
   'followers_url': 'https: //api.github.com/users/amr-cloudforce/followers',
   'following_url': 'https: //api.github.com/users/amr-cloudforce/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/amr-cloudforce/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/amr-cloudforce/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/amr-cloudforce/subscriptions',
   'organizations_url': 'https: //api.github.com/users/amr-cloudforce/orgs',
   'repos_url': 'https: //api.github.com/users/amr-cloudforce/repos',
   'events_url': 'https: //api.github.com/users/amr-cloudforce/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/amr-cloudforce/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-07-07T17: 26: 52Z',
  'updated_at': '2024-08-02T06: 55: 27Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ X] I have checked the [documentation](https://docs.ragas.io/) and related resources and couldn't resolve my bug.\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nThis tutorial doesn't seem to be functioning properly. I question whether the developer has actually run this code. Even the class names aren't accurate, like 'OpenAIEmbedding' for instance.\r\n\r\nAmong others: \r\n\r\nhttps://docs.ragas.io/en/latest/howtos/applications/compare_embeddings.html\r\n\r\nIt would have been beneficial to provide a sample file with the necessary libraries for execution beforehand.\r\n\r\n\r\nRagas version:\r\nPython version:\r\n\r\n**Code to Reproduce**\r\nShare code to reproduce the issue\r\n\r\n**Error trace**\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don't worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1075/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1075/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1072',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1072/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1072/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1072/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1072',
  'id': 2393457594,
  'node_id': 'I_kwDOJgX1Gs6OqUO6',
  'number': 1072,
  'title': 'Invalid n value (currently only n = 1 is supported)',
  'user': {'login': 'jidechao',
   'id': 62241490,
   'node_id': 'MDQ6VXNlcjYyMjQxNDkw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/62241490?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jidechao',
   'html_url': 'https: //github.com/jidechao',
   'followers_url': 'https: //api.github.com/users/jidechao/followers',
   'following_url': 'https: //api.github.com/users/jidechao/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jidechao/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jidechao/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jidechao/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jidechao/orgs',
   'repos_url': 'https: //api.github.com/users/jidechao/repos',
   'events_url': 'https: //api.github.com/users/jidechao/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jidechao/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 11,
  'created_at': '2024-07-06T07: 43: 10Z',
  'updated_at': '2024-08-15T06: 14: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\n```\r\nopenai.BadRequestError: Error code: 400 - {\'detail\': \'Invalid n value (currently only n = 1 is supported)\'}\r\n```\r\nRagas version:\r\n0.1.10\r\n\r\n**Code to Reproduce**\r\n```py\r\nfrom ragas import evaluate\r\nfrom langchain_openai import ChatOpenAI, OpenAI\r\nfrom langchain_community.embeddings import HuggingFaceBgeEmbeddings\r\nfrom datasets import Dataset\r\nfrom langchain.vectorstores.milvus import Milvus\r\n\r\n#embedding(chroma)\r\nmodel_name = "BAAI/bge-m3"\r\nmodel_kwargs = {\'device\': \'cpu\'}\r\nencode_kwargs = {\'normalize_embeddings\': True}\r\nembeddings = HuggingFaceBgeEmbeddings(\r\n    model_name=model_name,\r\n    model_kwargs=model_kwargs,\r\n    encode_kwargs=encode_kwargs\r\n)\r\n\r\nimport nest_asyncio\r\n\r\nnest_asyncio.apply()\r\n\r\nllm = ChatOpenAI(model="deepseek-chat",api_key="sk-*******",base_url="https://api.deepseek.com/v1" ,temperature=0, n=1)\r\n\r\nfrom ragas.metrics import (\r\n    faithfulness,\r\n    answer_relevancy,\r\n    context_relevancy,\r\n    context_recall,\r\n    context_precision,\r\n)\r\n\r\ndata = {\r\n    \'question\': [\'What is the capital of France?\'],\r\n    \'contexts\': [[\'Paris is the capital of France.\']],\r\n    \'answer\': [\'Paris\'],\r\n    \'ground_truth\': [\'Paris\']\r\n}\r\ndataset = Dataset.from_dict(data)\r\n\r\n\r\nresult = evaluate(\r\n    dataset = dataset, \r\n    metrics=[\r\n        context_precision,\r\n        context_recall,\r\n        faithfulness,\r\n        answer_relevancy,\r\n    ],\r\n    llm=llm,\r\n    embeddings=embeddings,\r\n)\r\n```\r\nresult\r\n```\r\n**Error trace**\r\nException in thread Thread-11:\r\nTraceback (most recent call last):\r\n  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/executor.py", line 95, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/usr/local/lib/python3.10/dist-packages/nest_asyncio.py", line 98, in run_until_complete\r\n    return f.result()\r\n  File "/usr/lib/python3.10/asyncio/futures.py", line 201, in result\r\n    raise self._exception.with_traceback(self._exception_tb)\r\n  File "/usr/lib/python3.10/asyncio/tasks.py", line 232, in __step\r\n    result = coro.send(None)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/executor.py", line 83, in _aresults\r\n    raise e\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/executor.py", line 78, in _aresults\r\n    r = await future\r\n  File "/usr/lib/python3.10/asyncio/tasks.py", line 571, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/usr/lib/python3.10/asyncio/futures.py", line 201, in result\r\n    raise self._exception.with_traceback(self._exception_tb)\r\n  File "/usr/lib/python3.10/asyncio/tasks.py", line 232, in __step\r\n    result = coro.send(None)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/executor.py", line 37, in sema_coro\r\n    return await coro\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/executor.py", line 111, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py", line 125, in ascore\r\n    raise e\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py", line 121, in ascore\r\n    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/metrics/_answer_relevance.py", line 152, in _ascore\r\n    result = await self.llm.generate(\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py", line 93, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n  File "/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py", line 111, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py", line 153, in iter\r\n    result = await action(retry_state)\r\n  File "/usr/local/lib/python3.10/dist-packages/tenacity/_utils.py", line 99, in inner\r\n    return call(*args, **kwargs)\r\n  File "/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py", line 398, in <lambda>\r\n    self._add_action_func(lambda rs: rs.outcome.result())\r\n  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result\r\n    return self.__get_result()\r\n  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result\r\n    raise self._exception\r\n  File "/usr/local/lib/python3.10/dist-packages/tenacity/asyncio/__init__.py", line 114, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/llms/base.py", line 170, in agenerate_text\r\n    return await self.langchain_llm.agenerate_prompt(\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py", line 691, in agenerate_prompt\r\n    return await self.agenerate(\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py", line 651, in agenerate\r\n    raise exceptions[0]\r\n  File "/usr/lib/python3.10/asyncio/tasks.py", line 232, in __step\r\n    result = coro.send(None)\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py", line 836, in _agenerate_with_cache\r\n    result = await self._agenerate(\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_openai/chat_models/base.py", line 674, in _agenerate\r\n    response = await self.async_client.create(**payload)\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py", line 1289, in create\r\n    return await self._post(\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/_base_client.py", line 1816, in post\r\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/_base_client.py", line 1514, in request\r\n    return await self._request(\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/_base_client.py", line 1610, in _request\r\n    raise self._make_status_error_from_response(err.response) from None\r\nopenai.BadRequestError: Error code: 400 - {\'detail\': \'Invalid n value (currently only n = 1 is supported)\'}\r\n```\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1072/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1072/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1070',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1070/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1070/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1070/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1070',
  'id': 2392363070,
  'node_id': 'I_kwDOJgX1Gs6OmJA-',
  'number': 1070,
  'title': '429 Request Error with Langchain Huggingface Endpoint',
  'user': {'login': 'jonas-nothnagel',
   'id': 41116329,
   'node_id': 'MDQ6VXNlcjQxMTE2MzI5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/41116329?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jonas-nothnagel',
   'html_url': 'https: //github.com/jonas-nothnagel',
   'followers_url': 'https: //api.github.com/users/jonas-nothnagel/followers',
   'following_url': 'https: //api.github.com/users/jonas-nothnagel/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jonas-nothnagel/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jonas-nothnagel/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jonas-nothnagel/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jonas-nothnagel/orgs',
   'repos_url': 'https: //api.github.com/users/jonas-nothnagel/repos',
   'events_url': 'https: //api.github.com/users/jonas-nothnagel/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jonas-nothnagel/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-07-05T10: 51: 06Z',
  'updated_at': '2024-08-02T04: 59: 52Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[x
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\nI want to create synthetic test data. Using the OpenAI or Anthropic API is very expensive so I want to use the HuggingFaceEndpointAPI and run it with Llama3-70B. I am running it on a GPU Compute Cluster and would assume that my compute is sufficient to load and run the model. However, I always run into rate limit error 429. Immediately when the script starts.\r\n\r\nRagas version: newest release (5th July)\r\nPython version: 3.10\r\n\r\nPlease find below the code. I tripe-checked it and it should be correct. Assume we have langchain document artifact for this of course. I excluded the data loading for better visibility. \r\n\r\n**Code to Reproduce**\r\n```py\r\nimport pandas as pd\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context, conditional\r\nfrom langchain_community.document_loaders import UnstructuredMarkdownLoader\r\nfrom langchain_text_splitters import (\r\n    TokenTextSplitter)\r\n\r\nfrom langchain_huggingface import HuggingFaceEndpoint, HuggingFaceEmbeddings\r\n\r\nimport os\r\nimport re\r\nimport torch\r\n\r\nimport time\r\nimport random\r\nimport logging\r\n\r\ndevice = "cuda:0" if torch.cuda.is_available() else "cpu"\r\nprint(f\'running on device: {device}\')\r\n\r\nif __name__ == \'__main__\':\r\n\r\n    def make_request_with_backoff(max_retries=10, max_wait_time=300):\r\n        for attempt in range(max_retries):\r\n            try:\r\n                logging.info(f"Attempt {attempt + 1} of {max_retries}")\r\n                testset = generator.generate_with_langchain_docs(docs, 50, distributions, raise_exceptions=False)\r\n                logging.info(f"Successfully generated {len(testset)} items")\r\n                return testset\r\n            except Exception as e:\r\n                if "429" in str(e):\r\n                    wait_time = min((2 ** attempt) + random.uniform(0, 1), max_wait_time)\r\n                    logging.warning(f"Rate limit hit. Waiting {wait_time:.2f} seconds.")\r\n                    time.sleep(wait_time)\r\n                else:\r\n                    logging.error(f"Unexpected error: {str(e)}")\r\n                    raise e\r\n        raise Exception("Max retries reached")\r\n\r\n    #load models\r\n    llm = HuggingFaceEndpoint(\r\n        repo_id="meta-llama/Meta-Llama-3-70B",\r\n        task="text-generation",\r\n        max_new_tokens=512,\r\n        repetition_penalty=1.03,\r\n    )\r\n\r\n    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")\r\n\r\n    generator_llm = llm\r\n    critic_llm = llm\r\n    embeddings = embeddings\r\n\r\n    generator = TestsetGenerator.from_langchain(\r\n        generator_llm,\r\n        critic_llm,\r\n        embeddings\r\n    )\r\n\r\n    # Change resulting question type distribution\r\n    distributions = {  # uniform distribution\r\n        simple: 0.1,\r\n        reasoning: 0.35,\r\n        multi_context: 0.2,\r\n        conditional: 0.35\r\n    }\r\n\r\n    # Configure logging\r\n    logging.basicConfig(level=logging.INFO)\r\n\r\n    # Use the function\r\n    testset = make_request_with_backoff()\r\n    \r\n    testset.to_pandas()\r\n    \r\n    #store data\r\n    testset.to_parquet(\'synthetic_data/ragas_llama3_qa.parquet\')\r\n```\r\n**Error trace**\r\n\r\n```\r\nFile "/usr/local/lib/python3.10/dist-packages/aiohttp/client_reqrep.py", line 1005, in raise_for_status\r\n    raise ClientResponseError(\r\naiohttp.client_exceptions.ClientResponseError: 429, message=\'Too Many Requests\', url=URL(\'https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-70B\')\r\n**Expected behavior**\r\n```\r\n\r\nI except the script to be running and use Llama3 to generate the test data.\r\n\r\n**Additional context**\r\nI am running this on 6 Nvidia A10s using a Pytorch Image and Python 3.10.\r\nSpecifications from the job script below:\r\n\r\n```\r\n#!/bin/bash\r\n\r\nset -xe\r\n\r\nsrun \\\r\n  --gpus=6 \\\r\n  --mem=144GB \\\r\n  --container-image=/data/enroot/nvcr.io_nvidia_pytorch_23.06-py3.sqsh \\\r\n  --container-workdir=`pwd` \\\r\n  --container-mounts=/my_path...\\\r\n  ./job.sh\r\n```\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1070/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1070/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1069',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1069/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1069/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1069/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1069',
  'id': 2392279244,
  'node_id': 'I_kwDOJgX1Gs6Ol0jM',
  'number': 1069,
  'title': 'About RagChecker  ',
  'user': {'login': 'binghangli378',
   'id': 173140804,
   'node_id': 'U_kgDOClHrRA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/173140804?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/binghangli378',
   'html_url': 'https: //github.com/binghangli378',
   'followers_url': 'https: //api.github.com/users/binghangli378/followers',
   'following_url': 'https: //api.github.com/users/binghangli378/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/binghangli378/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/binghangli378/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/binghangli378/subscriptions',
   'organizations_url': 'https: //api.github.com/users/binghangli378/orgs',
   'repos_url': 'https: //api.github.com/users/binghangli378/repos',
   'events_url': 'https: //api.github.com/users/binghangli378/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/binghangli378/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 4,
  'created_at': '2024-07-05T09: 59: 54Z',
  'updated_at': '2024-08-10T14: 51: 40Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Recently, I have noticed something similar to ragas, which is the [RagChecker
            ](https: //github.com/amazon-science/RAGChecker). It provides a new perspective to evaluate RAG pipelines which separately focuses on:\r\n- Relevant chunk\r\n- Irrelevant chunk used by the model\r\n- Irrelevant chunk ignored by the model\r\n\r\nThis new perspective will provide a more detailed evaluation of the model’s performance, allowing for a deeper understanding of how different types of data chunks impact the evaluation process.\r\n\r\nI am willing to design some new evaluation methods based on it. Please let me know if you are open to this idea, and I can provide further assistance or code examples.\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1069/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1069/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1068',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1068/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1068/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1068/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1068',
  'id': 2392187331,
  'node_id': 'I_kwDOJgX1Gs6OleHD',
  'number': 1068,
  'title': '[Question
            ] How to change custom mode name',
  'user': {'login': 'landhu',
   'id': 22722402,
   'node_id': 'MDQ6VXNlcjIyNzIyNDAy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/22722402?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/landhu',
   'html_url': 'https: //github.com/landhu',
   'followers_url': 'https: //api.github.com/users/landhu/followers',
   'following_url': 'https: //api.github.com/users/landhu/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/landhu/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/landhu/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/landhu/subscriptions',
   'organizations_url': 'https: //api.github.com/users/landhu/orgs',
   'repos_url': 'https: //api.github.com/users/landhu/repos',
   'events_url': 'https: //api.github.com/users/landhu/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/landhu/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 4,
  'created_at': '2024-07-05T09: 06: 32Z',
  'updated_at': '2024-08-08T04: 34: 04Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n** How do I specify the name of the model**\r\nAn LLM is deployed locally. All interfaces are the same as openai, but the mode name is different\r\n\r\n\r\n**Code Examples**\r\nNow I can do this in the following way to change key and url\r\n`os.environ[\'OPENAI_API_KEY\'] ="xxxx"\r\nos.environ[\'OPENAI_API_BASE\'] = "xxxx"\r\n`\r\nBut after that, when I run simple code:\r\n`data_samples = {\r\n    \'question\': [\r\n        \'When did Einstein born?\',\r\n        \'Where did Einstein born?\',\r\n                 ],\r\n    \'answer\': [\r\n               \'Einstein was born in 1879.\',\r\n               \'Einstein was born in Germany.\',\r\n               #\'Einstein was born in 1879 in Germany.\'\r\n               ],\r\n    \'ground_truth\': [\r\n        \'Einstein was born in 1879 in Germany.\',\r\n        \'Einstein was born in 1879 in Germany.\',\r\n        ]\r\n}\r\ndataset = Dataset.from_dict(data_samples)\r\nscore = evaluate(dataset, metrics=[answer_correctness])\r\nprint(\r\nscore.to_pandas()\r\n)`\r\n\r\nit\'s shows:\r\nopenai.NotFoundError: Error code: 404 - {\'error\': {\'message\': "model \'gpt-3.5-turbo\' not found, try pulling it first", \'type\': \'api_error\', \'param\': None, \'code\': None}}',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1068/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1068/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1066',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1066/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1066/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1066/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1066',
  'id': 2391658750,
  'node_id': 'I_kwDOJgX1Gs6OjdD-',
  'number': 1066,
  'title': 'sentence_segmenter in metric should be adapt to language in adapt function?',
  'user': {'login': 'jmgu0212',
   'id': 55698018,
   'node_id': 'MDQ6VXNlcjU1Njk4MDE4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/55698018?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jmgu0212',
   'html_url': 'https: //github.com/jmgu0212',
   'followers_url': 'https: //api.github.com/users/jmgu0212/followers',
   'following_url': 'https: //api.github.com/users/jmgu0212/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jmgu0212/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jmgu0212/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jmgu0212/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jmgu0212/orgs',
   'repos_url': 'https: //api.github.com/users/jmgu0212/repos',
   'events_url': 'https: //api.github.com/users/jmgu0212/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jmgu0212/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-07-05T02: 30: 04Z',
  'updated_at': '2024-08-02T07: 13: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nIt\'s good that almost all metric in ragas can be adapt to other language, but find the adaptation of sentence_segmenter happens directly after initialization(in __post_init__) for metrics that uses sentence_segmenter.\r\n\r\nBut I guess the adaptation of sentence_segmenter should happen in self.adapt func, otherwise the language is still the initial one.\r\n\r\n**Code to Reproduce**\r\n```\r\nclass Faithfulness(MetricWithLLM):\r\n    name: str = "faithfulness"  # type: ignore\r\n    evaluation_mode: EvaluationMode = EvaluationMode.qac  # type: ignore\r\n    nli_statements_message: Prompt = field(\r\n        default_factory=lambda: NLI_STATEMENTS_MESSAGE\r\n    )\r\n    statement_prompt: Prompt = field(default_factory=lambda: LONG_FORM_ANSWER_PROMPT)\r\n    sentence_segmenter: t.Optional[HasSegmentMethod] = None\r\n    max_retries: int = 1\r\n    _reproducibility: int = 1\r\n\r\n    @property\r\n    def reproducibility(self):\r\n        return self._reproducibility\r\n\r\n    @reproducibility.setter\r\n    def reproducibility(self, value):\r\n        if value < 1:\r\n            logger.warning("reproducibility cannot be less than 1, setting to 1")\r\n            value = 1\r\n        elif value % 2 == 0:\r\n            logger.warning(\r\n                "reproducibility level cannot be set to even number, setting to odd"\r\n            )\r\n            value += 1\r\n        self._reproducibility = value\r\n\r\n    def __post_init__(self):\r\n        if self.sentence_segmenter is None:\r\n            language = self.nli_statements_message.language\r\n            self.sentence_segmenter = get_segmenter(language=language, clean=False)\r\n\r\n    def _create_nli_prompt(self, row: t.Dict, statements: t.List[str]) -> PromptValue:\r\n        assert self.llm is not None, "llm must be set to compute score"\r\n\r\n        contexts = row["contexts"]\r\n        # check if the statements are support in the contexts\r\n        contexts_str: str = "\\n".join(contexts)\r\n        statements_str: str = json.dumps(statements)\r\n        prompt_value = self.nli_statements_message.format(\r\n            context=contexts_str, statements=statements_str\r\n        )\r\n        return prompt_value\r\n\r\n    def _create_statements_prompt(self, row: t.Dict) -> PromptValue:\r\n        assert self.sentence_segmenter is not None, "sentence_segmenter is not set"\r\n\r\n        text, question = row["answer"], row["question"]\r\n        sentences = self.sentence_segmenter.segment(text)\r\n        sentences = [\r\n            sentence for sentence in sentences if sentence.strip().endswith(".")\r\n        ]\r\n        sentences = "\\n".join([f"{i}:{x}" for i, x in enumerate(sentences)])\r\n        prompt_value = self.statement_prompt.format(\r\n            question=question, answer=text, sentences=sentences\r\n        )\r\n        return prompt_value\r\n\r\n    def _compute_score(self, answers: StatementFaithfulnessAnswers):\r\n        # check the verdicts and compute the score\r\n        faithful_statements = sum(\r\n            1 if answer.verdict else 0 for answer in answers.__root__\r\n        )\r\n        num_statements = len(answers.__root__)\r\n        if num_statements:\r\n            score = faithful_statements / num_statements\r\n        else:\r\n            logger.warning("No statements were generated from the answer.")\r\n            score = np.nan\r\n\r\n        return score\r\n\r\n    async def _ascore(\r\n        self: t.Self, row: t.Dict, callbacks: Callbacks, is_async: bool\r\n    ) -> float:\r\n        """\r\n        returns the NLI score for each (q, c, a) pair\r\n        """\r\n        assert self.llm is not None, "LLM is not set"\r\n\r\n        p_value = self._create_statements_prompt(row)\r\n        statements = await self.llm.generate(\r\n            p_value,\r\n            callbacks=callbacks,\r\n            is_async=is_async,\r\n        )\r\n        statements = await _statements_output_parser.aparse(\r\n            statements.generations[0][0].text, p_value, self.llm, self.max_retries\r\n        )\r\n\r\n        if statements is None:\r\n            return np.nan\r\n\r\n        statements = [item["simpler_statements"] for item in statements.dicts()]\r\n        statements = [item for sublist in statements for item in sublist]\r\n\r\n        assert isinstance(statements, t.List), "statements must be a list"\r\n\r\n        p_value = self._create_nli_prompt(row, statements)\r\n        nli_result = await self.llm.generate(\r\n            p_value,\r\n            callbacks=callbacks,\r\n            is_async=is_async,\r\n            n=self._reproducibility,\r\n        )\r\n\r\n        nli_result_text = [\r\n            nli_result.generations[0][i].text for i in range(self._reproducibility)\r\n        ]\r\n        faithfulness_list = [\r\n            await _faithfulness_output_parser.aparse(\r\n                text, p_value, self.llm, self.max_retries\r\n            )\r\n            for text in nli_result_text\r\n        ]\r\n\r\n        faithfulness_list = [\r\n            faith.dicts() for faith in faithfulness_list if faith is not None\r\n        ]\r\n\r\n        if faithfulness_list:\r\n            faithfulness_list = ensembler.from_discrete(\r\n                faithfulness_list,\r\n                "verdict",\r\n            )\r\n\r\n            faithfulness_list = StatementFaithfulnessAnswers.parse_obj(\r\n                faithfulness_list\r\n            )\r\n        else:\r\n            return np.nan\r\n\r\n        return self._compute_score(faithfulness_list)\r\n\r\n    def adapt(self, language: str, cache_dir: t.Optional[str] = None) -> None:\r\n        assert self.llm is not None, "LLM is not set"\r\n\r\n        logger.info(f"Adapting Faithfulness metric to {language}")\r\n\r\n        self.nli_statements_message = self.nli_statements_message.adapt(\r\n            language, self.llm, cache_dir\r\n        )\r\n        self.statement_prompt = self.statement_prompt.adapt(\r\n            language, self.llm, cache_dir\r\n        )\r\n\r\n    def save(self, cache_dir: t.Optional[str] = None) -> None:\r\n        self.nli_statements_message.save(cache_dir)\r\n```\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1066/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1066/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1063',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1063/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1063/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1063/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1063',
  'id': 2387303133,
  'node_id': 'I_kwDOJgX1Gs6OS1rd',
  'number': 1063,
  'title': 'Can you provide human assessment data mentioned in RAGAS paper?',
  'user': {'login': 'awsvmaringa',
   'id': 172548230,
   'node_id': 'U_kgDOCkjghg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/172548230?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/awsvmaringa',
   'html_url': 'https: //github.com/awsvmaringa',
   'followers_url': 'https: //api.github.com/users/awsvmaringa/followers',
   'following_url': 'https: //api.github.com/users/awsvmaringa/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/awsvmaringa/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/awsvmaringa/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/awsvmaringa/subscriptions',
   'organizations_url': 'https: //api.github.com/users/awsvmaringa/orgs',
   'repos_url': 'https: //api.github.com/users/awsvmaringa/repos',
   'events_url': 'https: //api.github.com/users/awsvmaringa/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/awsvmaringa/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-07-02T23: 01: 47Z',
  'updated_at': '2024-08-08T04: 40: 11Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nCan you could provide the human assessment data collected for bechmarking RAGAS metrics against human evaluations in your [paper
            ](https: //arxiv.org/pdf/2309.15217)?\r\n\r\n**Why is the feature important for you?**\r\nThe [paper](https://arxiv.org/pdf/2309.15217) only benchmarks ChatGPT against human evaluation. This feature would establish a standard dataset for benchmarking any LLM-as-judge models against human evaluation.\r\n\r\n**Additional context**\r\nIt would be great if you could provide a standard dataset containing question, ground truth, context, human labels for benchmarking all RAGAS metrics for different judge models.\r\n\r\n<!-- PS: Thanks for your valuable feedback. Really! Its feedback from valuable community members like you that help us make Ragas event better for the whole community. So thanks again for taking the time to improve our community 🙂 -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1063/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1063/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1062',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1062/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1062/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1062/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/1062',
  'id': 2386006511,
  'node_id': 'PR_kwDOJgX1Gs50L5vb',
  'number': 1062,
  'title': 'feat: adding support for langsmith',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745919,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uovw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:L',
    'name': 'size:L',
    'color': 'eb9500',
    'default': False,
    'description': 'This PR changes 100-499 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-07-02T11: 28: 15Z',
  'updated_at': '2024-07-02T11: 28: 18Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/1062',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/1062',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/1062.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/1062.patch',
   'merged_at': None
            },
  'body': 'todos\r\n- [] documentation for langsmith and langchain integrations\r\n- [] the execute() method gets stuck in unexpected places',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1062/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1062/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1059',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1059/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1059/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1059/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1059',
  'id': 2385839041,
  'node_id': 'I_kwDOJgX1Gs6ONQPB',
  'number': 1059,
  'title': 'Invalid n value (currently only n = 1 is supported',
  'user': {'login': 'ARES3366',
   'id': 50603047,
   'node_id': 'MDQ6VXNlcjUwNjAzMDQ3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/50603047?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ARES3366',
   'html_url': 'https: //github.com/ARES3366',
   'followers_url': 'https: //api.github.com/users/ARES3366/followers',
   'following_url': 'https: //api.github.com/users/ARES3366/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ARES3366/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ARES3366/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ARES3366/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ARES3366/orgs',
   'repos_url': 'https: //api.github.com/users/ARES3366/repos',
   'events_url': 'https: //api.github.com/users/ARES3366/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ARES3366/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-07-02T10: 12: 26Z',
  'updated_at': '2024-07-02T10: 16: 28Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '  File "/usr/local/lib/python3.10/dist-packages/ragas/langchain/evalchain.py", line 166, in evaluate\r\n    dataset_with_scores = self.metric.score(dataset, callbacks=callbacks)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/metrics/base.py", line 76, in score\r\n    score = self._score_batch(dataset.select(batch), callbacks=group)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/metrics/_answer_relevance.py", line 123, in _score_batch\r\n    results = self.llm.generate(\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/llms/langchain.py", line 209, in generate\r\n    return self._generate_multiple_completions(prompts, n, callbacks)\r\n  File "/usr/local/lib/python3.10/dist-packages/ragas/llms/langchain.py", line 120, in _generate_multiple_completions\r\n    result = self.llm.generate(ps, callbacks=callbacks)\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py", line 534, in generate\r\n    raise e\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py", line 524, in generate\r\n    self._generate_with_cache(\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py", line 749, in _generate_with_cache\r\n    result = self._generate(\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_community/chat_models/openai.py", line 442, in _generate\r\n    response = self.completion_with_retry(\r\n  File "/usr/local/lib/python3.10/dist-packages/langchain_community/chat_models/openai.py", line 357, in completion_with_retry\r\n    return self.client.create(**kwargs)\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py", line 277, in wrapper\r\n    return func(*args, **kwargs)\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py", line 643, in create\r\n    return self._post(\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/_base_client.py", line 1250, in post\r\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/_base_client.py", line 931, in request\r\n    return self._request(\r\n  File "/usr/local/lib/python3.10/dist-packages/openai/_base_client.py", line 1030, in _request\r\n    raise self._make_status_error_from_response(err.response) from None\r\nopenai.BadRequestError: Error code: 400 - {\'detail\': \'Invalid n value (currently only n = 1 is supported)\'
            }\r\n\r\n\r\n\r\nragas=0.0.22  ',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1059/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1059/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1057',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1057/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1057/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1057/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1057',
  'id': 2382676181,
  'node_id': 'I_kwDOJgX1Gs6OBMDV',
  'number': 1057,
  'title': 'Exception in thread Thread-4: `asyncio.exceptions.CancelledError` & `asyncio.exceptions.TimeoutError`',
  'user': {'login': 'larry-ziyue-yin',
   'id': 115158685,
   'node_id': 'U_kgDOBt0unQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/115158685?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/larry-ziyue-yin',
   'html_url': 'https: //github.com/larry-ziyue-yin',
   'followers_url': 'https: //api.github.com/users/larry-ziyue-yin/followers',
   'following_url': 'https: //api.github.com/users/larry-ziyue-yin/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/larry-ziyue-yin/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/larry-ziyue-yin/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/larry-ziyue-yin/subscriptions',
   'organizations_url': 'https: //api.github.com/users/larry-ziyue-yin/orgs',
   'repos_url': 'https: //api.github.com/users/larry-ziyue-yin/repos',
   'events_url': 'https: //api.github.com/users/larry-ziyue-yin/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/larry-ziyue-yin/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 11,
  'created_at': '2024-07-01T02: 44: 16Z',
  'updated_at': '2024-08-02T06: 32: 32Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nI am trying to run the template code from the Github ReadMe page. My code is below:\r\n```\r\nfrom datasets import Dataset \r\nimport os\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import faithfulness\r\n\r\nos.environ["OPENAI_API_KEY"] = "sk-proj-*****B3" <HIDDEN>\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n    \'contexts\' : [[\'The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\']],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n}\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nscore = evaluate(dataset,metrics=[faithfulness])\r\nscore.to_pandas()\r\n```\r\n\r\nRagas version: I use the latest one.\r\nPython version: 3.10.14.\r\n\r\n\r\n**Error trace**\r\nThe error I encountered is below: (with my username hidden in the file paths)\r\n```\r\n**Exception in thread Thread-4:**\r\nTraceback (most recent call last):\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/metrics/_faithfulness.py", line 248, in _ascore\r\n    statements = await self.llm.generate(\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/llms/base.py", line 93, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 121, in __call__\r\n    await self.sleep(do)  # type: ignore[misc]\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/asyncio/tasks.py", line 605, in sleep\r\n    return await future\r\n**asyncio.exceptions.CancelledError**\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/asyncio/tasks.py", line 456, in wait_for\r\n    return fut.result()\r\nasyncio.exceptions.CancelledError\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/threading.py", line 1016, in _bootstrap_inner\r\n...\r\n    score = await asyncio.wait_for(\r\n  File "/Users/*****/anaconda3/envs/ragas/lib/python3.10/asyncio/tasks.py", line 458, in wait_for\r\n    raise exceptions.TimeoutError() from exc\r\n**asyncio.exceptions.TimeoutError**\r\n```\r\n\r\n**Additional context**\r\nAnd the error report of the code is here:\r\n```\r\n---------------------------------------------------------------------------\r\nExceptionInRunner                         Traceback (most recent call last)\r\nCell In[1], [line 18](vscode-notebook-cell:?execution_count=1&line=18)\r\n      [8](vscode-notebook-cell:?execution_count=1&line=8) data_samples = {\r\n      [9](vscode-notebook-cell:?execution_count=1&line=9)     \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n     [10](vscode-notebook-cell:?execution_count=1&line=10)     \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n   (...)\r\n     [13](vscode-notebook-cell:?execution_count=1&line=13)     \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n     [14](vscode-notebook-cell:?execution_count=1&line=14) }\r\n     [16](vscode-notebook-cell:?execution_count=1&line=16) dataset = Dataset.from_dict(data_samples)\r\n---> [18](vscode-notebook-cell:?execution_count=1&line=18) score = evaluate(dataset,metrics=[faithfulness])\r\n     [19](vscode-notebook-cell:?execution_count=1&line=19) score.to_pandas()\r\n\r\nFile ~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:255, in evaluate(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\r\n    [252](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:252)     if not evaluation_group_cm.ended:\r\n    [253](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:253)         evaluation_rm.on_chain_error(e)\r\n--> [255](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:255)     raise e\r\n    [256](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:256) else:\r\n    [257](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:257)     result = Result(\r\n    [258](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:258)         scores=Dataset.from_list(scores),\r\n    [259](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:259)         dataset=dataset,\r\n    [260](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:260)         binary_columns=binary_metrics,\r\n    [261](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:261)     )\r\n\r\nFile ~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:237, in evaluate(dataset, metrics, llm, embeddings, callbacks, in_ci, is_async, run_config, raise_exceptions, column_map)\r\n...\r\n--> [237](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:237)     raise ExceptionInRunner()\r\n    [239](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:239) # convert results to dataset_like\r\n    [240](https://file+.vscode-resource.vscode-cdn.net/Users/*****/Library/CloudStorage/OneDrive-DukeUniversity/029.%20SRS%202024/Paul%20Weng%20_%20LLM/Evaluation/~/anaconda3/envs/ragas/lib/python3.10/site-packages/ragas/evaluation.py:240) for i, _ in enumerate(dataset):\r\n\r\nExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\r\n```\r\n\r\nCan anyone help me out? Thanks!',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1057/reactions',
   'total_count': 5,
   '+1': 5,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1057/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1049',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1049/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1049/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1049/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1049',
  'id': 2377682336,
  'node_id': 'I_kwDOJgX1Gs6NuI2g',
  'number': 1049,
  'title': 'answer_correctness giving inconsistent result',
  'user': {'login': 'chboudry',
   'id': 51988290,
   'node_id': 'MDQ6VXNlcjUxOTg4Mjkw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/51988290?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/chboudry',
   'html_url': 'https: //github.com/chboudry',
   'followers_url': 'https: //api.github.com/users/chboudry/followers',
   'following_url': 'https: //api.github.com/users/chboudry/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/chboudry/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/chboudry/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/chboudry/subscriptions',
   'organizations_url': 'https: //api.github.com/users/chboudry/orgs',
   'repos_url': 'https: //api.github.com/users/chboudry/repos',
   'events_url': 'https: //api.github.com/users/chboudry/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/chboudry/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-27T09: 46: 46Z',
  'updated_at': '2024-06-27T09: 49: 54Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\nThe answer correctness does not seems consistent.\r\n\r\n**Code to Reproduce**\r\nquestion = [
                  "1",
                  "2",
                  "3",
                  "4",
                  "5"
            ]\r\nanswers = [
                  "yes",
                  "no",
                  "no",
                  "yes",
                  "no"
            ]\r\ncontexts = [
                  [
                        "1",
                        "2",
                        "3",
                        "4"
                  ],
                  [
                        "1",
                        "2",
                        "3",
                        "4"
                  ],
                  [
                        "1",
                        "2",
                        "3",
                        "4"
                  ],
                  [
                        "1",
                        "2",
                        "3",
                        "4"
                  ],
                  [
                        "1",
                        "2",
                        "3",
                        "4"
                  ]
            ]\r\nground_truth = [
                  "yes",
                  "no",
                  "yes",
                  "no",
                  "no"
            ]\r\n\r\nds = Dataset.from_dict({\r\n    "question": question,\r\n    "answer": answers,\r\n    "contexts": contexts,\r\n    "ground_truth": ground_truth\r\n
            })\r\n\r\nresult_ragas = evaluate(ds,metrics=metrics,raise_exceptions=False)\r\nresult_ragas\r\n\r\nresults = result_ragas.to_pandas()\r\nresults.head()\r\n\r\n**result**\r\n![image
            ](https: //github.com/explodinggradients/ragas/assets/51988290/34d68b6a-31e8-46ac-94c1-d2dae2538c51)\r\n\r\n\r\nHow come row 1 and row 4 does not share the same answer correctness ? \r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1049/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1049/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1048',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1048/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1048/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1048/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1048',
  'id': 2377630221,
  'node_id': 'I_kwDOJgX1Gs6Nt8IN',
  'number': 1048,
  'title': 'Hello，calculate faithfulness Error: No statements were generated from the answer',
  'user': {'login': '13416157913',
   'id': 20581199,
   'node_id': 'MDQ6VXNlcjIwNTgxMTk5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/20581199?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/13416157913',
   'html_url': 'https: //github.com/13416157913',
   'followers_url': 'https: //api.github.com/users/13416157913/followers',
   'following_url': 'https: //api.github.com/users/13416157913/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/13416157913/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/13416157913/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/13416157913/subscriptions',
   'organizations_url': 'https: //api.github.com/users/13416157913/orgs',
   'repos_url': 'https: //api.github.com/users/13416157913/repos',
   'events_url': 'https: //api.github.com/users/13416157913/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/13416157913/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-06-27T09: 23: 53Z',
  'updated_at': '2024-06-27T09: 57: 07Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[]Hello I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nHello, when I run a sample like this with chinese:\r\nfrom datasets import Dataset\r\nimport os\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import faithfulness, answer_similarity, answer_correctness\r\n\r\nos.environ["OPENAI_API_KEY"] ="xxxxxx"\r\n\r\ndata_samples = {\r\n    \'question\': [\'\'],\r\n    \'answer\': [\'当站台一侧或一组灯带不亮时，处理步骤如下：\\n\\n1. **安全措施**：首先确保在处理故障时断开电源，以避免电击风险。\\n\\n2. **检查LED日光灯**：如果是个别灯不亮，检查这些LED日光灯是否故障。拆下不亮的灯泡，检查是否需要更换新的灯泡或其驱动器。\\n\\n3. **检查电压**：如果部分灯不亮，可能是电压问题。使用电压表检测电源电压是否在正常范围内。如果电压不稳定，可能需要调整电源或查找其他故障源。\\n\\n4. **检查供电箱和控制空开**：如果整侧灯带不亮，检查供电箱的灯带切换和控制空开是否正常工作。确认空开没有跳闸，如果发现异常，进行调整或更换。\\n\\n5. **检查卡位和安装**：确认灯带的卡位是否牢固，是否存在损坏导致灯带无法正常工作。如有必要，修复或更换卡位以确保灯带固定。\\n\\n6. **检查接线**：检查连接线是否松动或老化。紧固接线，确保所有连接处无松动现象，必要时更换损坏的电线。\\n\\n7. **重新接通电源并测试**：在完成上述步骤后，重新接通电源，并测试站台灯带是否恢复正常。如果问题仍未解决，可能需要进一步的专业电气检查和维修，并通知相关人员配合。\\n\\n请务必在执行这些步骤时遵守所有安全规定，并在必要时寻求专业帮助。\'],\r\n    \'contexts\' : [[\'\']],\r\n    \'ground_truth\': [\'当站台一侧或一组灯带不亮时，应按照以下步骤进行处理：\\n1.检查空气开关：\\n到达现场后，首先通过车站电话报告环调维修人员已到现场，并向车站工作人员申请C2类临修点。\\n检查相应灯带箱的空气开关是否跳闸或烧坏。如果空气开关跳闸，尝试复位或更换空气开关。\\n2.检查线路电压：\\n使用万用表或电笔测量线路是否有电。如果发现线路没有电，进一步检查电源是否正常供电。\\n3.检查线路完整性：\\n检查线路是否短路或烧坏。可以通过目视检查或使用测电工具来确定线路的状况。如果发现短路或烧坏情况，进行相应的维修或更换线路。\\n4.处理异常情况：\\n清理线路中的异物或修复损坏的部分。如果发现灯带本身损坏，需要更换灯带。\\n5.报告处理结果：\\n处理完成后，向环调和车站报告处理结果，确保记录维修日志以备后续参考。\\n联系人信息：\\n如果在处理过程中需要进一步的支持或确认解决方案，可以联系以下负责人：\\n电力调度员：张三，电话号码：12345678，负责供电日常组织、指挥工作，保证整个地铁供电系统安全运行和连续供电。\\n故障报告：\\n根据上述步骤生成的故障报告应包括以下内容：\\n1.故障描述：站台一侧或一组灯带不亮。\\n2.故障原因：可能是空气开关跳闸、线路断电或线路短路等原因引起。\\n3.处理步骤：检查空气开关、线路电压和线路完整性，清理异物或修复损坏部分。\\n4.联系人信息：电力调度员张三，电话号码：12345678。\\n5.处理结果：处理完成后报告环调和车站，并记录维修日志。\\n按照以上步骤进行操作，确保灯带故障能够及时、准确地得到处理和解决。\']\r\n}\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nscore = evaluate(dataset,metrics=[answer_similarity,faithfulness,answer_correctness])\r\nprint (score["answer_correctness"])\r\nprint(score.to_pandas())\r\n\r\nRagas version: 0.1.9\r\nPython version: 3.10\r\n\r\n**Code to Reproduce**\r\nShare code to reproduce the issue\r\n\r\n**Error trace**\r\nEvaluating:   0%|          | 0/3 [00:00<?, ?it/s]No statements were generated from the answer.\r\nEvaluating:  67%|██████▋   | 2/3 [01:15<00:37, 37.71s/it]\r\nException in thread Thread-1:\r\nTraceback (most recent call last):\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 67, in map_httpcore_exceptions\r\n    yield\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 371, in handle_async_request\r\n    resp = await self._pool.handle_async_request(req)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py", line 268, in handle_async_request\r\n    raise exc\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py", line 251, in handle_async_request\r\n    response = await connection.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection.py", line 103, in handle_async_request\r\n    return await self._connection.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 133, in handle_async_request\r\n    raise exc\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 111, in handle_async_request\r\n    ) = await self._receive_response_headers(**kwargs)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 176, in _receive_response_headers\r\n    event = await self._receive_event(timeout=timeout)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 226, in _receive_event\r\n    raise RemoteProtocolError(msg)\r\nhttpcore.RemoteProtocolError: Server disconnected without sending a response.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1522, in _request\r\n    response = await self._client.send(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1646, in send\r\n    response = await self._send_handling_auth(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1674, in _send_handling_auth\r\n    response = await self._send_handling_redirects(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1711, in _send_handling_redirects\r\n    response = await self._send_single_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1748, in _send_single_request\r\n    response = await transport.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 370, in handle_async_request\r\n    with map_httpcore_exceptions():\r\n  File "D:\\ProgramData\\anaconda3\\lib\\contextlib.py", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 84, in map_httpcore_exceptions\r\n    raise mapped_exc(message) from exc\r\nhttpx.RemoteProtocolError: Server disconnected without sending a response.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 67, in map_httpcore_exceptions\r\n    yield\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 371, in handle_async_request\r\n    resp = await self._pool.handle_async_request(req)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py", line 268, in handle_async_request\r\n    raise exc\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py", line 251, in handle_async_request\r\n    response = await connection.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection.py", line 103, in handle_async_request\r\n    return await self._connection.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 133, in handle_async_request\r\n    raise exc\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 111, in handle_async_request\r\n    ) = await self._receive_response_headers(**kwargs)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 176, in _receive_response_headers\r\n    event = await self._receive_event(timeout=timeout)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 226, in _receive_event\r\n    raise RemoteProtocolError(msg)\r\nhttpcore.RemoteProtocolError: Server disconnected without sending a response.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1522, in _request\r\n    response = await self._client.send(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1646, in send\r\n    response = await self._send_handling_auth(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1674, in _send_handling_auth\r\n    response = await self._send_handling_redirects(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1711, in _send_handling_redirects\r\n    response = await self._send_single_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1748, in _send_single_request\r\n    response = await transport.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 370, in handle_async_request\r\n    with map_httpcore_exceptions():\r\n  File "D:\\ProgramData\\anaconda3\\lib\\contextlib.py", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 84, in map_httpcore_exceptions\r\n    raise mapped_exc(message) from exc\r\nhttpx.RemoteProtocolError: Server disconnected without sending a response.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 67, in map_httpcore_exceptions\r\n    yield\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 371, in handle_async_request\r\n    resp = await self._pool.handle_async_request(req)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py", line 268, in handle_async_request\r\n    raise exc\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection_pool.py", line 251, in handle_async_request\r\n    response = await connection.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\connection.py", line 103, in handle_async_request\r\n    return await self._connection.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 133, in handle_async_request\r\n    raise exc\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 111, in handle_async_request\r\n    ) = await self._receive_response_headers(**kwargs)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 176, in _receive_response_headers\r\n    event = await self._receive_event(timeout=timeout)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_async\\http11.py", line 226, in _receive_event\r\n    raise RemoteProtocolError(msg)\r\nhttpcore.RemoteProtocolError: Server disconnected without sending a response.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1522, in _request\r\n    response = await self._client.send(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1646, in send\r\n    response = await self._send_handling_auth(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1674, in _send_handling_auth\r\n    response = await self._send_handling_redirects(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1711, in _send_handling_redirects\r\n    response = await self._send_single_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py", line 1748, in _send_single_request\r\n    response = await transport.handle_async_request(request)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 370, in handle_async_request\r\n    with map_httpcore_exceptions():\r\n  File "D:\\ProgramData\\anaconda3\\lib\\contextlib.py", line 153, in __exit__\r\n    self.gen.throw(typ, value, traceback)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py", line 84, in map_httpcore_exceptions\r\n    raise mapped_exc(message) from exc\r\nhttpx.RemoteProtocolError: Server disconnected without sending a response.\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "D:\\ProgramData\\anaconda3\\lib\\threading.py", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\executor.py", line 95, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "D:\\ProgramData\\anaconda3\\lib\\asyncio\\base_events.py", line 649, in run_until_complete\r\n    return future.result()\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\executor.py", line 83, in _aresults\r\n    raise e\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\executor.py", line 78, in _aresults\r\n    r = await future\r\n  File "D:\\ProgramData\\anaconda3\\lib\\asyncio\\tasks.py", line 571, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\executor.py", line 37, in sema_coro\r\n    return await coro\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\executor.py", line 111, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\metrics\\base.py", line 125, in ascore\r\n    raise e\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\metrics\\base.py", line 121, in ascore\r\n    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\metrics\\_answer_correctness.py", line 253, in _ascore\r\n    is_statement_present = await self.llm.generate(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\llms\\base.py", line 93, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\asyncio\\__init__.py", line 189, in async_wrapped\r\n    return await copy(fn, *args, **kwargs)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\asyncio\\__init__.py", line 111, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\asyncio\\__init__.py", line 153, in iter\r\n    result = await action(retry_state)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\_utils.py", line 99, in inner\r\n    return call(*args, **kwargs)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\__init__.py", line 398, in <lambda>\r\n    self._add_action_func(lambda rs: rs.outcome.result())\r\n  File "D:\\ProgramData\\anaconda3\\lib\\concurrent\\futures\\_base.py", line 451, in result\r\n    return self.__get_result()\r\n  File "D:\\ProgramData\\anaconda3\\lib\\concurrent\\futures\\_base.py", line 403, in __get_result\r\n    raise self._exception\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\tenacity\\asyncio\\__init__.py", line 114, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\llms\\base.py", line 170, in agenerate_text\r\n    return await self.langchain_llm.agenerate_prompt(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py", line 609, in agenerate_prompt\r\n    return await self.agenerate(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py", line 569, in agenerate\r\n    raise exceptions[0]\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_core\\language_models\\chat_models.py", line 754, in _agenerate_with_cache\r\n    result = await self._agenerate(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\langchain_openai\\chat_models\\base.py", line 666, in _agenerate\r\n    response = await self.async_client.create(messages=message_dicts, **params)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\resources\\chat\\completions.py", line 1214, in create\r\n    return await self._post(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1790, in post\r\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1493, in request\r\n    return await self._request(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1546, in _request\r\n    return await self._retry_request(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1615, in _retry_request\r\n    return await self._request(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1546, in _request\r\n    return await self._retry_request(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1615, in _retry_request\r\n    return await self._request(\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py", line 1556, in _request\r\n    raise APIConnectionError(request=request) from err\r\nopenai.APIConnectionError: Connection error.\r\nTraceback (most recent call last):\r\n  File "E:\\PCI-Agent\\ragas_examples.py", line 25, in <module>\r\n    score = evaluate(dataset,metrics=[answer_similarity,faithfulness,answer_correctness])\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\evaluation.py", line 250, in evaluate\r\n    raise e\r\n  File "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\ragas\\evaluation.py", line 232, in evaluate\r\n    raise ExceptionInRunner()\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\r\n\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1048/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1048/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1047',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1047/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1047/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1047/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1047',
  'id': 2375272648,
  'node_id': 'I_kwDOJgX1Gs6Nk8jI',
  'number': 1047,
  'title': 'Keep getting "Your authentication token is not from a valid issuer", although I got OpenAI access',
  'user': {'login': 'ilaychen',
   'id': 45047397,
   'node_id': 'MDQ6VXNlcjQ1MDQ3Mzk3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/45047397?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ilaychen',
   'html_url': 'https: //github.com/ilaychen',
   'followers_url': 'https: //api.github.com/users/ilaychen/followers',
   'following_url': 'https: //api.github.com/users/ilaychen/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ilaychen/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ilaychen/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ilaychen/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ilaychen/orgs',
   'repos_url': 'https: //api.github.com/users/ilaychen/repos',
   'events_url': 'https: //api.github.com/users/ilaychen/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ilaychen/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 8,
  'created_at': '2024-06-26T12: 57: 32Z',
  'updated_at': '2024-08-02T06: 51: 26Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\nI\'m using AzureChatOpenAI. I was able to create a model instance, to send a prompt and to get an answer:\r\n```\r\nchat_model = AzureChatOpenAI(\r\n    base_url="https://abc.verycoolcorp.com/etx-bot/openai/deployments" + "/gpt-35-turbo",\r\n    api_version="2024-02-15-preview",\r\n    http_client=httpx.Client(verify=False),\r\n    azure_ad_token=access_token,\r\n    temperature=0\r\n)\r\n\r\nresponse = chat_model.invoke([HumanMessage(content="Is Maldini the best footballer in history?")
            ])\r\n```\r\n\r\nNow, when I try to use Ragas methods, such as below:\r\n```\r\ngenerator = TestsetGenerator.from_langchain(\r\n    chat_model,\r\n    critic_model,\r\n    embeddings\r\n)\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25
            })\r\n\r\n```\r\n\r\nI\'m getting an SSLCertVerificationError issue:\r\n```\r\nYour authentication token is not from a valid issuer\r\n```\r\n\r\nRagas version: latest\r\nPython version: 3.12.1\r\n\r\n**Error trace**\r\n\r\n```\r\nException in thread Thread-28:                                                                                                                             \r\nTraceback (most recent call last):\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1522, in _request\r\n    response = await self._client.send(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py", line 1661, in send\r\n    response = await self._send_handling_auth(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py", line 1689, in _send_handling_auth\r\n    response = await self._send_handling_redirects(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py", line 1726, in _send_handling_redirects\r\n    response = await self._send_single_request(request)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_client.py", line 1763, in _send_single_request\r\n    response = await transport.handle_async_request(request)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpx/_transports/default.py", line 373, in handle_async_request\r\n    resp = await self._pool.handle_async_request(req)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_async/connection_pool.py", line 216, in handle_async_request\r\n    raise exc from None\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_async/connection_pool.py", line 196, in handle_async_request\r\n    response = await connection.handle_async_request(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_async/connection.py", line 99, in handle_async_request\r\n    raise exc\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_async/connection.py", line 76, in handle_async_request\r\n    stream = await self._connect(request)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_async/connection.py", line 154, in _connect\r\n    stream = await stream.start_tls(**kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_backends/anyio.py", line 80, in start_tls\r\n    raise exc\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/httpcore/_backends/anyio.py", line 71, in start_tls\r\n    ssl_stream = await anyio.streams.tls.TLSStream.wrap(\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/anyio/streams/tls.py", line 132, in wrap\r\n    await wrapper._call_sslobject_method(ssl_object.do_handshake)\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/anyio/streams/tls.py", line 140, in _call_sslobject_method\r\n    result = func(*args)\r\n             ^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py", line 917, in do_handshake\r\n    self._sslobj.do_handshake()\r\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED
            ] certificate verify failed: unable to get local issuer certificate (_ssl.c: 1000)\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py", line 1073, in _bootstrap_inner\r\n    self.run()\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/executor.py", line 95, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py", line 684, in run_until_complete\r\n    return future.result()\r\n           ^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/executor.py", line 83, in _aresults\r\n    raise e\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/executor.py", line 78, in _aresults\r\n    r = await future\r\n        ^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py", line 631, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n           ^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/executor.py", line 37, in sema_coro\r\n    return await coro\r\n           ^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/executor.py", line 111, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/embeddings/base.py", line 26, in embed_text\r\n    embs = await self.embed_texts([text
            ], is_async=is_async)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/embeddings/base.py", line 36, in embed_texts\r\n    return await aembed_documents_with_retry(texts)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/tenacity/_asyncio.py", line 142, in async_wrapped\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/tenacity/_asyncio.py", line 58, in __call__\r\n    else:\r\n         ^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/tenacity/_asyncio.py", line 110, in iter\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/tenacity/_asyncio.py", line 78, in inner\r\n    await self.sleep(do)\r\n       ^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/tenacity/__init__.py", line 390, in <lambda>\r\n    else:\r\n          \r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py", line 449, in result\r\n    return self.__get_result()\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result\r\n    raise self._exception\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/tenacity/_asyncio.py", line 61, in __call__\r\n    def __iter__(self) -> t.Generator[AttemptManager, None, None
            ]:\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/embeddings/base.py", line 67, in aembed_documents\r\n    return await self.embeddings.aembed_documents(texts)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/langchain_openai/embeddings/base.py", line 555, in aembed_documents\r\n    return await self._aget_len_safe_embeddings(texts, engine=engine)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/langchain_openai/embeddings/base.py", line 475, in _aget_len_safe_embeddings\r\n    response = await self.async_client.create(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/resources/embeddings.py", line 215, in create\r\n    return await self._post(\r\n           ^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1790, in post\r\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1493, in request\r\n    return await self._request(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1546, in _request\r\n    return await self._retry_request(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1615, in _retry_request\r\n    return await self._request(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1546, in _request\r\n    return await self._retry_request(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1615, in _retry_request\r\n    return await self._request(\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/openai/_base_client.py", line 1556, in _request\r\n    raise APIConnectionError(request=request) from err\r\nopenai.APIConnectionError: Connection error.\r\nTraceback (most recent call last):\r\n  File "<stdin>", line 1, in <module>\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/testset/generator.py", line 206, in generate_with_langchain_docs\r\n    self.docstore.add_documents(\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/testset/docstore.py", line 215, in add_documents\r\n    self.add_nodes(nodes, show_progress=show_progress)\r\n  File "/Users/ilchen/Library/Python/3.12/lib/python/site-packages/ragas/testset/docstore.py", line 254, in add_nodes\r\n    raise ExceptionInRunner()\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\r\n\r\n```\r\n\r\n**Expected behavior**\r\nTo not get this SSLCertVerificationError.\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1047/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1047/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1046',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1046/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1046/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1046/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1046',
  'id': 2374101050,
  'node_id': 'I_kwDOJgX1Gs6Ngeg6',
  'number': 1046,
  'title': 'Q: Aspect Critique: Multiple Verdicts?',
  'user': {'login': 'dkhundley',
   'id': 36610221,
   'node_id': 'MDQ6VXNlcjM2NjEwMjIx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/36610221?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/dkhundley',
   'html_url': 'https: //github.com/dkhundley',
   'followers_url': 'https: //api.github.com/users/dkhundley/followers',
   'following_url': 'https: //api.github.com/users/dkhundley/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/dkhundley/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/dkhundley/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/dkhundley/subscriptions',
   'organizations_url': 'https: //api.github.com/users/dkhundley/orgs',
   'repos_url': 'https: //api.github.com/users/dkhundley/repos',
   'events_url': 'https: //api.github.com/users/dkhundley/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/dkhundley/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-26T03: 23: 05Z',
  'updated_at': '2024-06-26T03: 26: 51Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[X] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\nhttps://docs.ragas.io/en/stable/concepts/metrics/critique.html\r\n\r\n**Your Question**\r\nIn the documentation (linked above), there is a calculation reference to collecting 3 different verdicts from 3 LLM calls. It then seems that the `strictness` parameter would then determine how to produce the aggregate final score per the particular aspect ratio.\r\n\r\n[Looking at the source code](https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/critique.py), I’m having trouble finding how the multiple verdicts are derived.  The prompt engineering only seems to indicate that it’s looking for a single final verdict per the aspect critique. Interestingly, there does seem to be [specific code to look the “commonality” of verdicts per the strictness parameter.](https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/critique.py#L111-L114) I’m struggling to connect how the LLM could produce more than one verdict per how the code and prompt engineering are currently written.\r\n\r\n(I really like the idea, which is why I’m asking. I’d like to implement that with that strictness parameter working. 😃)\r\n\r\n\r\n**Code Examples**\r\nLinked source code in the material above\r\n\r\n**Additional context**\r\nNone\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1046/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1046/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1045',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1045/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1045/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1045/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1045',
  'id': 2373139935,
  'node_id': 'I_kwDOJgX1Gs6Ncz3f',
  'number': 1045,
  'title': 'Are Multi-context questions generated by using related docs or related chunks of the same doc?',
  'user': {'login': 'nikithamary',
   'id': 123583648,
   'node_id': 'U_kgDOB128oA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/123583648?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/nikithamary',
   'html_url': 'https: //github.com/nikithamary',
   'followers_url': 'https: //api.github.com/users/nikithamary/followers',
   'following_url': 'https: //api.github.com/users/nikithamary/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/nikithamary/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/nikithamary/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/nikithamary/subscriptions',
   'organizations_url': 'https: //api.github.com/users/nikithamary/orgs',
   'repos_url': 'https: //api.github.com/users/nikithamary/repos',
   'events_url': 'https: //api.github.com/users/nikithamary/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/nikithamary/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-25T16: 40: 06Z',
  'updated_at': '2024-06-25T16: 41: 46Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '\r\n\r\n\r\nAre Multi-context questions generated by using related docs or related chunks of the same doc?\r\n\r\n<img width="916" alt="image" src="https://github.com/explodinggradients/ragas/assets/123583648/06f07d05-8cad-4e3f-b88c-a74ae11f6837">\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1045/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1045/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1044',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1044/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1044/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1044/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1044',
  'id': 2372964121,
  'node_id': 'I_kwDOJgX1Gs6NcI8Z',
  'number': 1044,
  'title': 'Any form of caching / reusing data while generating a synthetic dataset?',
  'user': {'login': 'NiklasClausius',
   'id': 78502512,
   'node_id': 'MDQ6VXNlcjc4NTAyNTEy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/78502512?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/NiklasClausius',
   'html_url': 'https: //github.com/NiklasClausius',
   'followers_url': 'https: //api.github.com/users/NiklasClausius/followers',
   'following_url': 'https: //api.github.com/users/NiklasClausius/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/NiklasClausius/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/NiklasClausius/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/NiklasClausius/subscriptions',
   'organizations_url': 'https: //api.github.com/users/NiklasClausius/orgs',
   'repos_url': 'https: //api.github.com/users/NiklasClausius/repos',
   'events_url': 'https: //api.github.com/users/NiklasClausius/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/NiklasClausius/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-25T15: 17: 14Z',
  'updated_at': '2024-06-25T15: 21: 07Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[x
            ] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\nHi, I\'m currently getting into evaluation of my RAG-system but had a problem when following the Get started guide for Generation of a synthetic dataset.\r\n\r\n**Your Question**\r\nIs there a way to save steps across generation of a synthetic dataset? I have a fairly large dataset to load (I pickled the docs for later use which saves quite some time) and I\'m using a local embedding model on machine with just a CPU resulting in a long time building the embeddings during the Testset Generation. \r\nNow i had an exception thrown because of exceeding the API-limit in the generation phase resulting in a loss of all data i guess. Is there a way to persists the state after building the embeddings? It seems like at this point there have already been a lot of calls to the generator LLM as well. From the "getting-started" and Core concept docs i do not really understand if there is a way to achieve a persistent state.\r\n\r\nIt would be great if i can just restart the generation part again for the next try. Does Ragas have a functionality for that?\r\nI hope i was able to explain my problem.\r\n\r\nI\'m really thankful for any help :)',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1044/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1044/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1043',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1043/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1043/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1043/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1043',
  'id': 2372409932,
  'node_id': 'I_kwDOJgX1Gs6NaBpM',
  'number': 1043,
  'title': '[R-276
            ] langchain - langsmith integration',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-25T11: 13: 40Z',
  'updated_at': '2024-07-23T04: 34: 25Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-276](https://linear.app/exploding-gradients/issue/R-276/langchain-langsmith-integration)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1043/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1043/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1042',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1042/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1042/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1042/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1042',
  'id': 2370822043,
  'node_id': 'I_kwDOJgX1Gs6NT9-b',
  'number': 1042,
  'title': 'feat(benchmark): Implement flexible model selection in TestsetGenerator for improved customization and consistency',
  'user': {'login': 'donbr',
   'id': 7340008,
   'node_id': 'MDQ6VXNlcjczNDAwMDg=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/7340008?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/donbr',
   'html_url': 'https: //github.com/donbr',
   'followers_url': 'https: //api.github.com/users/donbr/followers',
   'following_url': 'https: //api.github.com/users/donbr/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/donbr/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/donbr/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/donbr/subscriptions',
   'organizations_url': 'https: //api.github.com/users/donbr/orgs',
   'repos_url': 'https: //api.github.com/users/donbr/repos',
   'events_url': 'https: //api.github.com/users/donbr/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/donbr/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-24T18: 11: 17Z',
  'updated_at': '2024-06-25T09: 52: 37Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nCurrently, the `tests/benchmarks/benchmark_testsetgen.py` script has hardcoded LLM models for `generator_llm`, `critic_llm`, and `embeddings`. However, other Ragas scripts have the ability to override these defaults when called from a Jupyter notebook (etc.).\r\n\r\n**Why is the feature important for you?**\r\n\r\nCurrent code in benchmark_testsetgen.py:\r\n```python\r\n# hardcoding of values in tests/benchmarks/benchmark_testsetgen.py\r\ngenerator_llm = ChatOpenAI(model="gpt-3.5-turbo-16k")\r\ncritic_llm = ChatOpenAI(model="gpt-4")\r\nembeddings = OpenAIEmbeddings()\r\n\r\ngenerator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embeddings)\r\n```\r\n\r\nBecause of the hardcoding in the benchmark_testsetgen.py script it negates the ability to dynamically set global defaults in notebooks / scripts for the generator, critic, and embedding models when calling Ragas:\r\n\r\n```python\r\n# setting of defaults in Jupyter Notebook or script calling Ragas\r\ngenerator_llm = ChatOpenAI(model="gpt-3.5-turbo-0125")\r\ncritic_llm = ChatOpenAI(model="gpt-4o")\r\nembeddings = OpenAIEmbeddings(model="text-embedding-3-small")\r\n```\r\n\r\n**Additional context**\r\nModify the `benchmark_testsetgen.py` script to mirror `src/ragas/testset/generator.py` and support optional parameters to allow for consistent overriding of default settings for `generator_llm`, `critic_llm`, and `embedding_model`.  This will allow users to set global and consistent defaults when calling Ragas from a script / notebook:\r\n\r\n```python\r\n# updates to benchmark_testsetgen.py\r\ndef initialize_testset_generator(\r\n    generator_llm="gpt-3.5-turbo-16k",\r\n    critic_llm="gpt-4",\r\n    embeddings="text-embedding-ada-002"\r\n):\r\n    generator_llm = ChatOpenAI(model=generator_llm)\r\n    critic_llm = ChatOpenAI(model=critic_llm)\r\n    embeddings = OpenAIEmbeddings(model=embeddings)\r\n\r\n    return TestsetGenerator.from_langchain(generator_llm, critic_llm, embeddings)\r\n\r\n# Usage\r\ngenerator = initialize_testset_generator()\r\n```\r\n\r\nI was surprised when I was running the Ragas scripts from a notebook that it ignored the GPT-4o settings for the critic_llm, and used the much more expensive and older base GPT-4 model.  A number of better variants on the approach above, but this should be sufficient.\r\n\r\nThe essential requirement is consistency and transparency of models used during specific steps of the process.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1042/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1042/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1039',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1039/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1039/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1039/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1039',
  'id': 2367626000,
  'node_id': 'I_kwDOJgX1Gs6NHxsQ',
  'number': 1039,
  'title': '[Feature Request
            ] OpenLLMetry Integration (OpenTelemetry)',
  'user': {'login': 'amitjoy',
   'id': 13380182,
   'node_id': 'MDQ6VXNlcjEzMzgwMTgy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/13380182?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/amitjoy',
   'html_url': 'https: //github.com/amitjoy',
   'followers_url': 'https: //api.github.com/users/amitjoy/followers',
   'following_url': 'https: //api.github.com/users/amitjoy/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/amitjoy/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/amitjoy/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/amitjoy/subscriptions',
   'organizations_url': 'https: //api.github.com/users/amitjoy/orgs',
   'repos_url': 'https: //api.github.com/users/amitjoy/repos',
   'events_url': 'https: //api.github.com/users/amitjoy/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/amitjoy/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-06-22T06: 45: 25Z',
  'updated_at': '2024-06-25T11: 53: 55Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nOpenTelemetry is a de facto standard for reporting metrices and OpenLLMetry uses OpenTelemetry under the hood. It would be better to have an integration to send such metrices for RAG evaluation to OpenTelemetry collectors as well.\r\n\r\n**Why is the feature important for you?**\r\nSince OpenTelemetry is a common standard which would be used easily in any existing systems.\r\n\r\n**Additional context**\r\nNA\r\n\r\n<!-- PS: Thanks for your valuable feedback. Really! Its feedback from valuable community members like you that help us make Ragas event better for the whole community. So thanks again for taking the time to improve our community 🙂 -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1039/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1039/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1038',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1038/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1038/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1038/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1038',
  'id': 2366648530,
  'node_id': 'I_kwDOJgX1Gs6NEDDS',
  'number': 1038,
  'title': 'filter_question instruction may be something wrong',
  'user': {'login': 'jaqennnn',
   'id': 52652741,
   'node_id': 'MDQ6VXNlcjUyNjUyNzQx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/52652741?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jaqennnn',
   'html_url': 'https: //github.com/jaqennnn',
   'followers_url': 'https: //api.github.com/users/jaqennnn/followers',
   'following_url': 'https: //api.github.com/users/jaqennnn/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jaqennnn/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jaqennnn/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jaqennnn/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jaqennnn/orgs',
   'repos_url': 'https: //api.github.com/users/jaqennnn/repos',
   'events_url': 'https: //api.github.com/users/jaqennnn/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jaqennnn/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-06-21T14: 18: 45Z',
  'updated_at': '2024-06-25T09: 57: 54Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Asses the given question for clarity and answerability given enough domain knowledge, consider the following criteria:\r\n\r\nI think the idea you want to convey  is to assesment the question. It is a good idea that reveal all instrutions or prompt.to_string by grammarly.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1038/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1038/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1037',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1037/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1037/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1037/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1037',
  'id': 2365087026,
  'node_id': 'I_kwDOJgX1Gs6M-F0y',
  'number': 1037,
  'title': 'Prompt for Question Creation or Am I missing something',
  'user': {'login': 'TheShoes',
   'id': 7997186,
   'node_id': 'MDQ6VXNlcjc5OTcxODY=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/7997186?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/TheShoes',
   'html_url': 'https: //github.com/TheShoes',
   'followers_url': 'https: //api.github.com/users/TheShoes/followers',
   'following_url': 'https: //api.github.com/users/TheShoes/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/TheShoes/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/TheShoes/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/TheShoes/subscriptions',
   'organizations_url': 'https: //api.github.com/users/TheShoes/orgs',
   'repos_url': 'https: //api.github.com/users/TheShoes/repos',
   'events_url': 'https: //api.github.com/users/TheShoes/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/TheShoes/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-20T19: 12: 17Z',
  'updated_at': '2024-06-26T23: 43: 33Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "**Question:**\r\nWhere is the prompt generating the actual question.   I am using Claude Sonnet for generating the question test data set and it seems like the prompt can use some tweaking.   The issue currently is the question is generated with a lot of extra data that is not needed.  See the examples for what extra data is coming in.  \r\n\r\nDo I need to manually go in and tweak the prompt (if so where)?\r\nor \r\nIs there something i am missing or a set to resolve this?\r\n\r\n**Example**\r\nQuestions will include things like \r\n\r\nBased on the given context and keyphrase, here is a question that can be answered from the information provided:\r\n\r\nRewritten multi-hop reasoning question: \r\n\r\nBased on the given context and keyphrase 'XXXX', a relevant question could be:\r\n\r\n\r\nThank you for any help you may provide",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1037/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1037/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1036',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1036/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1036/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1036/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1036',
  'id': 2365081409,
  'node_id': 'I_kwDOJgX1Gs6M-EdB',
  'number': 1036,
  'title': 'Context Precision Example',
  'user': {'login': 'MatthewSH',
   'id': 3768988,
   'node_id': 'MDQ6VXNlcjM3Njg5ODg=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/3768988?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/MatthewSH',
   'html_url': 'https: //github.com/MatthewSH',
   'followers_url': 'https: //api.github.com/users/MatthewSH/followers',
   'following_url': 'https: //api.github.com/users/MatthewSH/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/MatthewSH/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/MatthewSH/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/MatthewSH/subscriptions',
   'organizations_url': 'https: //api.github.com/users/MatthewSH/orgs',
   'repos_url': 'https: //api.github.com/users/MatthewSH/repos',
   'events_url': 'https: //api.github.com/users/MatthewSH/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/MatthewSH/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-20T19: 08: 23Z',
  'updated_at': '2024-06-20T19: 19: 18Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[x] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nI was reviewing the [context precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html) example on the website and noticed that `answer` is being provided as an input even though it's not being used actively as far as we can tell in the context precision metric. We even see a couple spots where the answer key is being overwritten with the `ground_truth` key. \r\n\r\nMy question is, for the examples are they supposed to be minimal and required arguments or just a data dump of everything that can be provided?\r\n\r\nI know that using answer is going to be deprecated soon and according to https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_context_precision.py#L117 it will fall back, I was just curious if it having both on the example is intended or not.\r\n\r\nEDIT: Also if the answer version is being deprecated soon, is the plan to switch all references from `answer` to `ground_truth`?",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1036/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1036/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1034',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1034/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1034/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1034/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1034',
  'id': 2361671212,
  'node_id': 'I_kwDOJgX1Gs6MxD4s',
  'number': 1034,
  'title': "Baidu Qianfan's model",
  'user': {'login': 'purpleofdial',
   'id': 125564542,
   'node_id': 'U_kgDOB3v2fg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/125564542?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/purpleofdial',
   'html_url': 'https: //github.com/purpleofdial',
   'followers_url': 'https: //api.github.com/users/purpleofdial/followers',
   'following_url': 'https: //api.github.com/users/purpleofdial/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/purpleofdial/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/purpleofdial/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/purpleofdial/subscriptions',
   'organizations_url': 'https: //api.github.com/users/purpleofdial/orgs',
   'repos_url': 'https: //api.github.com/users/purpleofdial/repos',
   'events_url': 'https: //api.github.com/users/purpleofdial/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/purpleofdial/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-19T08: 10: 34Z',
  'updated_at': '2024-06-19T08: 37: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Question**\r\nHas anyone ever used Baidu Qianfan\'s model? I have encountered problems when using langchain call, I hope someone can help me.\r\n\r\n**Code Examples**\r\nfrom langchain_community.chat_models import QianfanChatEndpoint\r\nfrom langchain_core.language_models.chat_models import HumanMessage\r\n\r\nchatBot = QianfanChatEndpoint(\r\n    streaming=False,\r\n    model="ERNIE-Speed-8K",\r\n)\r\nscore = evaluate(dataset,metrics=[faithfulness,answer_correctness
            ],llm=chatBot,embeddings=embeddings)\r\n\r\n**Error**\r\n[ERROR
            ][
                  2024-06-19 08: 00: 12.491
            ] base.py: 444 [t: 140121514964544
            ]: request exception: Cannot connect to host aip.baidubce.com: 443 ssl:default [Network is unreachable
            ], retrying...\r\nUnclosed client session\r\nclient_session: <aiohttp.client.ClientSession object at 0x7f71bebe56a0>\r\nUnclosed client session\r\nclient_session: <aiohttp.client.ClientSession object at 0x7f71be96d760>\r\nUnclosed client session\r\nclient_session: <aiohttp.client.ClientSession object at 0x7f71bebe5610>\r\n[ERROR
            ][
                  2024-06-19 08: 00: 12.576
            ] base.py: 444 [t: 140121514964544
            ]: request exception: Cannot connect to host aip.baidubce.com: 443 ssl:default [Network is unreachable
            ], retrying...\r\n[ERROR
            ][
                  2024-06-19 08: 00: 12.734
            ] base.py: 444 [t: 140121514964544
            ]: request exception: Cannot connect to host aip.baidubce.com: 443 ssl:default [Network is unreachable
            ], retrying...\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1034/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1034/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1032',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1032/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1032/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1032/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1032',
  'id': 2359680412,
  'node_id': 'I_kwDOJgX1Gs6Mpd2c',
  'number': 1032,
  'title': 'Is it possible to define custom metrics with Ragas ?',
  'user': {'login': 'saadbouhya',
   'id': 57443751,
   'node_id': 'MDQ6VXNlcjU3NDQzNzUx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/57443751?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/saadbouhya',
   'html_url': 'https: //github.com/saadbouhya',
   'followers_url': 'https: //api.github.com/users/saadbouhya/followers',
   'following_url': 'https: //api.github.com/users/saadbouhya/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/saadbouhya/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/saadbouhya/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/saadbouhya/subscriptions',
   'organizations_url': 'https: //api.github.com/users/saadbouhya/orgs',
   'repos_url': 'https: //api.github.com/users/saadbouhya/repos',
   'events_url': 'https: //api.github.com/users/saadbouhya/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/saadbouhya/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-06-18T11: 54: 48Z',
  'updated_at': '2024-06-18T12: 33: 56Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I need to use it with french data, but the automatic prompt adaptation is not integrated with the evaluation.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1032/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1032/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1030',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1030/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1030/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1030/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1030',
  'id': 2357633495,
  'node_id': 'I_kwDOJgX1Gs6MhqHX',
  'number': 1030,
  'title': 'Support for multi-modal RAG evaluation (including images, tables, etc.)',
  'user': {'login': 'joly-chen',
   'id': 17918138,
   'node_id': 'MDQ6VXNlcjE3OTE4MTM4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/17918138?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/joly-chen',
   'html_url': 'https: //github.com/joly-chen',
   'followers_url': 'https: //api.github.com/users/joly-chen/followers',
   'following_url': 'https: //api.github.com/users/joly-chen/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/joly-chen/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/joly-chen/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/joly-chen/subscriptions',
   'organizations_url': 'https: //api.github.com/users/joly-chen/orgs',
   'repos_url': 'https: //api.github.com/users/joly-chen/repos',
   'events_url': 'https: //api.github.com/users/joly-chen/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/joly-chen/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-17T15: 28: 36Z',
  'updated_at': '2024-06-17T15: 28: 36Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nSupport for multi-modal RAG evaluation (including images, tables, etc.)\r\nMulti-modal RAG is becoming more important.\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1030/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1030/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1029',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1029/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1029/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1029/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1029',
  'id': 2356192631,
  'node_id': 'I_kwDOJgX1Gs6McKV3',
  'number': 1029,
  'title': 'QuestionFilter filter logic',
  'user': {'login': 'Padarn',
   'id': 858039,
   'node_id': 'MDQ6VXNlcjg1ODAzOQ==',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/858039?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Padarn',
   'html_url': 'https: //github.com/Padarn',
   'followers_url': 'https: //api.github.com/users/Padarn/followers',
   'following_url': 'https: //api.github.com/users/Padarn/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Padarn/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Padarn/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Padarn/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Padarn/orgs',
   'repos_url': 'https: //api.github.com/users/Padarn/repos',
   'events_url': 'https: //api.github.com/users/Padarn/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Padarn/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-06-17T02: 10: 58Z',
  'updated_at': '2024-06-17T12: 40: 48Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[ x
            ] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Your Question**\r\nI am trying to understand the RAGAS question filters, in particular `QuestionFilter`. My confusion stems from this part of the prompt (and corresponding examples)\r\n\r\n```\r\n1.Independence: Can the question be understood and answered without needing additional context or access to external references not provided within the question itself? Questions should be self-contained, meaning they do not rely on specific documents, tables, or prior knowledge not shared within the question.\r\n```\r\n\r\nBecause context is not provided along with the question when assessed:\r\n\r\n```python\r\n    async def filter(self, question: str) -> t.Tuple[bool, str]:\r\n        prompt = self.filter_question_prompt.format(question=question)\r\n        results = await self.llm.generate(prompt=prompt)\r\n        results = results.generations[0][0].text.strip()\r\n        results = await question_filter_parser.aparse(results, prompt, self.llm)\r\n        results = results.dict() if results is not None else {}\r\n        logger.debug("filtered question: %s", results)\r\n        return results.get("verdict") == 1, results.get("feedback", "")\r\n```\r\n\r\nIt is a bit unclear why we would want to filter these types of question. \r\n\r\n**Additional context**\r\nNote really important to the question, but this came up when I was trying to generate examples from very simple documents to understand the output better:\r\n\r\n```\r\ndocuments = [\r\n    Document("Padarn is ten years old. He likes to play football. One day XXXX = 1000000000000000000000")\r\n]\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1029/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1029/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1027',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1027/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1027/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1027/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1027',
  'id': 2355377321,
  'node_id': 'I_kwDOJgX1Gs6MZDSp',
  'number': 1027,
  'title': 'Generate a Synthetic Test Set In Other Language',
  'user': {'login': 'AprilJoy',
   'id': 3983079,
   'node_id': 'MDQ6VXNlcjM5ODMwNzk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/3983079?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/AprilJoy',
   'html_url': 'https: //github.com/AprilJoy',
   'followers_url': 'https: //api.github.com/users/AprilJoy/followers',
   'following_url': 'https: //api.github.com/users/AprilJoy/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/AprilJoy/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/AprilJoy/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/AprilJoy/subscriptions',
   'organizations_url': 'https: //api.github.com/users/AprilJoy/orgs',
   'repos_url': 'https: //api.github.com/users/AprilJoy/repos',
   'events_url': 'https: //api.github.com/users/AprilJoy/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/AprilJoy/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-06-16T02: 01: 21Z',
  'updated_at': '2024-08-02T07: 14: 45Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': " I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nwhat is unclear to you? What would you like to know?\r\nwhen I use the function generate_with_langchain_docs to generate a test, the columns of  question ,ground_truth is generated in ENGLISH, how could I set them in other language?\r\n\r\n**Code Examples**\r\nThis community speaks code. Share your code snippets to help us understand your question better.\r\n\r\n**Additional context**\r\nAnything else you want to share with us? \r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1027/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1027/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1022',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1022/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1022/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1022/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1022',
  'id': 2344180137,
  'node_id': 'I_kwDOJgX1Gs6LuVmp',
  'number': 1022,
  'title': 'Non-ASCII characters in faithfulness metric',
  'user': {'login': 'mckbrchill',
   'id': 115869584,
   'node_id': 'U_kgDOBugHkA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/115869584?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/mckbrchill',
   'html_url': 'https: //github.com/mckbrchill',
   'followers_url': 'https: //api.github.com/users/mckbrchill/followers',
   'following_url': 'https: //api.github.com/users/mckbrchill/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/mckbrchill/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/mckbrchill/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/mckbrchill/subscriptions',
   'organizations_url': 'https: //api.github.com/users/mckbrchill/orgs',
   'repos_url': 'https: //api.github.com/users/mckbrchill/repos',
   'events_url': 'https: //api.github.com/users/mckbrchill/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/mckbrchill/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-06-10T15: 15: 06Z',
  'updated_at': '2024-06-25T10: 52: 08Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\nWhen I work with cyrillic texts, the candidates sentences generated in faithfulness metric are being passed through json.dumps with  default ensure_ascii=True in _create_nli_prompt method, so statements_str contains strings with escape sequences which are then passed to LLM again.\r\n\r\n\r\n```\r\n    def _create_nli_prompt(self, row: t.Dict, statements: t.List[str]) -> PromptValue:\r\n        assert self.llm is not None, "llm must be set to compute score"\r\n\r\n        contexts = row["contexts"]\r\n        # check if the statements are support in the contexts\r\n        contexts_str: str = "\\n".join(contexts)\r\n        statements_str: str = json.dumps(statements)\r\n        prompt_value = self.nli_statements_message.format(\r\n            context=contexts_str, statements=statements_str\r\n        )\r\n        return prompt_value\r\n```\r\n\r\n\r\nRagas version: 0.1.7\r\nPython version: 3.10.8\r\n\r\n**Expected behavior**\r\nI expect the candidate sentences to be in cyrillic symbols when being passed to LLM again.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1022/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1022/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1018',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1018/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1018/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1018/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1018',
  'id': 2337484999,
  'node_id': 'I_kwDOJgX1Gs6LUzDH',
  'number': 1018,
  'title': '[R-271
            ] Tools to estimate cost of evaluation and testset generations',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-06T06: 57: 20Z',
  'updated_at': '2024-06-06T06: 57: 22Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'null\n\n<sub>[R-271
            ](https: //linear.app/exploding-gradients/issue/R-271/tools-to-estimate-cost-of-evaluation-and-testset-generations)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1018/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1018/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1016',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1016/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1016/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1016/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1016',
  'id': 2336514259,
  'node_id': 'I_kwDOJgX1Gs6LRGDT',
  'number': 1016,
  'title': '[R-270
            ] Synthetic test data generation - v3',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-05T18: 02: 25Z',
  'updated_at': '2024-07-30T06: 14: 01Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'Highly programmable knowledge graph-based synthetic data generation grounded on documents.\n\nPR raised #1024\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-270](https://linear.app/exploding-gradients/issue/R-270/synthetic-test-data-generation)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1016/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1016/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1015',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1015/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1015/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1015/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1015',
  'id': 2336514097,
  'node_id': 'I_kwDOJgX1Gs6LRGAx',
  'number': 1015,
  'title': '[R-269
            ] Saving and tracking Ragas results',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-05T18: 02: 22Z',
  'updated_at': '2024-06-05T18: 02: 25Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'null\n\n<sub>[R-269
            ](https: //linear.app/exploding-gradients/issue/R-269/saving-and-tracking-ragas-results)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1015/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1015/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1013',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1013/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1013/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1013/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1013',
  'id': 2336513364,
  'node_id': 'I_kwDOJgX1Gs6LRF1U',
  'number': 1013,
  'title': '[R-267
            ] Saving and tracking Ragas results',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-05T18: 01: 55Z',
  'updated_at': '2024-06-05T18: 02: 01Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'null\n\n<sub>[R-267
            ](https: //linear.app/exploding-gradients/issue/R-267/saving-and-tracking-ragas-results)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1013/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1013/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1012',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1012/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1012/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1012/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1012',
  'id': 2336513299,
  'node_id': 'I_kwDOJgX1Gs6LRF0T',
  'number': 1012,
  'title': '[R-266
            ] New Propsal for `Prompt`',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-05T18: 01: 53Z',
  'updated_at': '2024-07-25T11: 14: 34Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'Detailed Proposal: [PromptObject - v0.2
            ](https: //ragas.notion.site/PromptObject-v0-2-e7bbe8cc7fd94ac8868e51d6493520f1)\n\n## User Requirements\n\n1. Create Simple prompts easily\n2. Typed I/O\n3. Adaption - stress test, use the current issues to understand the limitations\n4. Ability to remove reasoning and other types\n5. change demonstraction of the fly\n6. change decoding strategy (this is the responsibility of the LLM)\n7. unique identifier name for each prompt → this should also change when prompt is modified. Why?\n   1. let’s say user A adapts and saves ragas at v0.1\n   2. after a while he uses ragas again but with adapted language - but this time we had changed the prompt then it causes issues.\n\n<sub>From [SyncLinear.com](https://synclinear.com) | [R-266](https://linear.app/exploding-gradients/issue/R-266/new-interface-for-llms)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1012/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1012/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1011',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1011/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1011/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1011/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1011',
  'id': 2336513170,
  'node_id': 'I_kwDOJgX1Gs6LRFyS',
  'number': 1011,
  'title': '[R-265
            ] Ragas API and docker image',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-05T18: 01: 47Z',
  'updated_at': '2024-07-27T05: 55: 19Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '- [] make ragas metrics deployable as a server\n- [] make testset generation interactive with an API\n\nmaking a simple documentation site to showcase how this might work would be a great first step to get feedback.\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-265](https://linear.app/exploding-gradients/issue/R-265/ragas-api-and-docker-image)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1011/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1011/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1010',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1010/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1010/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1010/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1010',
  'id': 2336512838,
  'node_id': 'I_kwDOJgX1Gs6LRFtG',
  'number': 1010,
  'title': '[R-264
            ] Add more metrics with v0.2',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-05T18: 01: 34Z',
  'updated_at': '2024-08-02T06: 50: 07Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'Reference free\n\n* Generation\n* Summarisation\n* Code summary\n* Textual summary\n\nWith Reference\n\n* Generation for data types\n* Text\n* answer correctness\n\nCode\nSQL\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-264](https://linear.app/exploding-gradients/issue/R-264/add-more-metrics-with-v02)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1010/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1010/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1009',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1009/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1009/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1009/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1009',
  'id': 2336511413,
  'node_id': 'I_kwDOJgX1Gs6LRFW1',
  'number': 1009,
  'title': '[R-263
            ] Roadmap - v0.2',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-06-05T18: 00: 42Z',
  'updated_at': '2024-08-31T15: 54: 20Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '![image
            ](https: //uploads.linear.app/0a832749-6bfc-40ec-ae6f-821fa8081d92/b03fef57-cff5-4cb6-a839-b70fec68562f/8d292dcc-3f04-4f14-8d12-2b743282b435?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiLzBhODMyNzQ5LTZiZmMtNDBlYy1hZTZmLTgyMWZhODA4MWQ5Mi9iMDNmZWY1Ny1jZmY1LTRjYjYtYTgzOS1iNzBmZWM2ODU2MmYvOGQyOTJkY2MtM2YwNC00ZjE0LThkMTItMmI3NDMyODJiNDM1IiwiaWF0IjoxNzE3NjEwNTA1LCJleHAiOjE3NDkxNDY1MDV9.SDH7eFsST7ZxgcPuIWKvQpbN1UjWI1Cz7rrHqkrfMWE)\n\n- [ ] #1010\n  - [ ]  Reference free\n    - [ ]  Generation\n      - [ ]  Summarisation\n        - [ ]  Code summary\n        - [ ]  Textual summary\n  - [ ]  With Reference\n    - [ ] #1220\n      - [ ]  Text\n        - [ ]  answer correctness\n      - [ ]  Code\n      - [ ]  SQL\n- [ ] #1011\n  - [ ]  make ragas metrics deployable as a server\n  - [ ]  make testset generation interactive with an API\n- [ ] #1018\n- [ ] #1012\n- [ ] #1015\n- [ ] #1016\n  - [ ]  for RAG\n    - [ ]  structured data\n    - [ ]  unstructured data\n  - [ ]  Agents simulations\n    - [ ]  Based on predefined task & conditions\n  - [ ]  State to persist knowledge graphs and results in test generation\n- [ ] #1237\n\n<sub>From [SyncLinear.com](https://synclinear.com) | [R-263](https://linear.app/exploding-gradients/issue/R-263/roadmap-v02)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1009/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1009/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1006',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1006/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1006/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1006/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1006',
  'id': 2333328802,
  'node_id': 'I_kwDOJgX1Gs6LE8Wi',
  'number': 1006,
  'title': 'Synthetic Dataset Generation fail due to "ValueError: \'a\' cannot be empty unless no samples are taken"',
  'user': {'login': 'antoninoLorenzo',
   'id': 94693967,
   'node_id': 'U_kgDOBaTqTw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/94693967?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/antoninoLorenzo',
   'html_url': 'https: //github.com/antoninoLorenzo',
   'followers_url': 'https: //api.github.com/users/antoninoLorenzo/followers',
   'following_url': 'https: //api.github.com/users/antoninoLorenzo/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/antoninoLorenzo/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/antoninoLorenzo/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/antoninoLorenzo/subscriptions',
   'organizations_url': 'https: //api.github.com/users/antoninoLorenzo/orgs',
   'repos_url': 'https: //api.github.com/users/antoninoLorenzo/repos',
   'events_url': 'https: //api.github.com/users/antoninoLorenzo/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/antoninoLorenzo/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-04T11: 52: 16Z',
  'updated_at': '2024-06-26T02: 12: 47Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Hi, I am trying to use `TestsetGenerator` to produce a synthetic dataset paired with `LlamaIndex` and \'Ollama\', it successfully completes the embedding process, but before startin the generation process the `ValueError: \'a\' cannot be empty unless no samples are taken` exception is raise; I personally think this is because, for some reason, TestsetGenerator produces the double of the required embeddings for the LlamaIndex `Document`, at least this is what I can get by looking at the embeddings progress bar.\r\n\r\nCode:\r\n```\r\nimport json\r\nfrom pathlib import Path\r\n\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom llama_index.core import Document\r\nfrom llama_index.llms.ollama import Ollama\r\nfrom llama_index.embeddings.ollama import OllamaEmbedding\r\n\r\nfrom knowlege.collections import Document as MyDocument \r\nfrom knowlege.chunker import chunk # tried chunking to lower the documents length\r\n\r\nfiles_gen = Path("./data/").rglob("*")\r\nfiles = [f.resolve() for f in files_gen
            ]\r\njson_files = [f for f in files if f.suffix.lower() == ".json"
            ]\r\n\r\ndocs = []\r\nwith open(json_files[
                  4
            ], \'r\', encoding=\'utf-8\') as fp: \r\n    data = json.load(fp)\r\n    for item in data:\r\n        chunks = chunk(MyDocument(\r\n            name=item[\'title\'
            ], \r\n            content=item[\'content\'
            ]\r\n        ))\r\n        for c in chunks:\r\n            docs.append(Document(text=c))   \r\n            \r\ngenerator_llm = Ollama(model=\'gemma: 2b\')\r\ncritic_llm = Ollama(model=\'gemma: 2b\')\r\nembeddings = OllamaEmbedding(model_name=\'gemma: 2b\')\r\ngenerator = TestsetGenerator.from_llama_index(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\n# tried with original documents\r\ntest_docs = docs[
                  : 5
            ]\r\nfor d in test_docs:\r\n    print(d.doc_id)\r\n    print(len(d.text))\r\n    \r\n# e861670f-3439-405d-a287-a90dfc885f9e\r\n# 219\r\n# a44e3cc3-e498-4662-b3e7-52220145da05\r\n# 227\r\n# d21bd3e2-9d7d-41de-a99e-2acd538b46d3\r\n# 274\r\n# c1555996-fd90-436e-ab93-dbed31471551\r\n# 596\r\n# 7d8145b9-7d67-4d4d-a363-695e7b0f0f79\r\n# 646\r\n\r\n# tried with proof-of-concept documents\r\ndamn = [\r\n    Document(text=\'Sensitive Data Exposure, which is more of a broad symptom rather than a root cause, the focus is on failures related to cryptography (or lack thereof). Which often lead to exposure of sensitive data.\'),\r\n    Document(text=\'For example, passwords, credit card numbers, health records, personal information, and business secrets require extra protection, mainly if that data falls under privacy laws\'),\r\n    Document(text=\'Secure software requires a secure development lifecycle, some form of secure design pattern, paved road methodology, secured component library, tooling, and threat modeling.\')\r\n
            ]\r\n\r\ntest_set = generator.generate_with_llamaindex_docs(\r\n    damn,\r\n    test_size=1, \r\n    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25
            },\r\n    raise_exceptions=False\r\n) \r\n```        \r\n\r\nOutput:\r\n```\r\nFilename and doc_id are the same for all nodes.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\nCell In[
                  9
            ], line 1\r\n----> 1 test_set = generator.generate_with_llamaindex_docs(\r\n      2     damn,\r\n      3     test_size=1, \r\n      4     distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25
            },\r\n      5     raise_exceptions=False\r\n      6 ) \r\n\r\nFile D:\\Desktop\\UNI\\Tirocinio-Tesi\\project\\prototypes\\.venv\\Lib\\site-packages\\ragas\\testset\\generator.py: 183, in TestsetGenerator.generate_with_llamaindex_docs(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\r\n    178 # chunk documents and add to docstore\r\n    179 self.docstore.add_documents(\r\n    180     [Document.from_llamaindex_document(doc) for doc in documents
            ]\r\n    181 )\r\n--> 183 return self.generate(\r\n    184     test_size=test_size,\r\n    185     distributions=distributions,\r\n    186     with_debugging_logs=with_debugging_logs,\r\n    187     is_async=is_async,\r\n    188     run_config=run_config,\r\n    189     raise_exceptions=raise_exceptions,\r\n    190 )\r\n\r\nFile D:\\Desktop\\UNI\\Tirocinio-Tesi\\project\\prototypes\\.venv\\Lib\\site-packages\\ragas\\testset\\generator.py: 279, in TestsetGenerator.generate(self, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\r\n    268     patch_logger("ragas.llms.prompt", logging.DEBUG)\r\n    270 exec = Executor(\r\n    271     desc="Generating",\r\n    272     keep_progress_bar=True,\r\n    273     raise_exceptions=raise_exceptions,\r\n    274     run_config=run_config,\r\n    275 )\r\n    277 current_nodes = [\r\n    278     CurrentNodes(root_node=n, nodes=[n
                  ])\r\n--> 279     for n in self.docstore.get_random_nodes(k=test_size)\r\n    280
            ]\r\n    281 total_evolutions = 0\r\n    282 for evolution, probability in distributions.items():\r\n\r\nFile D:\\Desktop\\UNI\\Tirocinio-Tesi\\project\\prototypes\\.venv\\Lib\\site-packages\\ragas\\testset\\docstore.py: 328, in InMemoryDocumentStore.get_random_nodes(self, k, alpha)\r\n    325 prob = np.array(scores) * np.array(similarity_scores)\r\n    326 prob = prob / np.sum(prob)\r\n--> 328 nodes = rng.choice(np.array(self.nodes), size=k, p=prob).tolist()\r\n    330 for node in nodes:\r\n    331     idx = self.nodes.index(node)\r\n\r\nFile numpy\\\\random\\\\_generator.pyx: 803, in numpy.random._generator.Generator.choice()\r\n\r\nValueError: a cannot be empty unless no samples are taken\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1006/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1006/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1005',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1005/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1005/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1005/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1005',
  'id': 2331049383,
  'node_id': 'I_kwDOJgX1Gs6K8P2n',
  'number': 1005,
  'title': 'I think it is a good idea that put all evaluate prompt templates into together.',
  'user': {'login': 'hwfancyz7k',
   'id': 148410629,
   'node_id': 'U_kgDOCNiRBQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/148410629?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/hwfancyz7k',
   'html_url': 'https: //github.com/hwfancyz7k',
   'followers_url': 'https: //api.github.com/users/hwfancyz7k/followers',
   'following_url': 'https: //api.github.com/users/hwfancyz7k/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/hwfancyz7k/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/hwfancyz7k/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/hwfancyz7k/subscriptions',
   'organizations_url': 'https: //api.github.com/users/hwfancyz7k/orgs',
   'repos_url': 'https: //api.github.com/users/hwfancyz7k/repos',
   'events_url': 'https: //api.github.com/users/hwfancyz7k/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/hwfancyz7k/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-03T12: 38: 24Z',
  'updated_at': '2024-06-03T12: 38: 24Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': None,
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1005/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1005/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1004',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1004/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1004/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1004/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1004',
  'id': 2330292102,
  'node_id': 'I_kwDOJgX1Gs6K5W-G',
  'number': 1004,
  'title': 'JSON parser as association ',
  'user': {'login': 'wuodar',
   'id': 49692261,
   'node_id': 'MDQ6VXNlcjQ5NjkyMjYx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/49692261?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/wuodar',
   'html_url': 'https: //github.com/wuodar',
   'followers_url': 'https: //api.github.com/users/wuodar/followers',
   'following_url': 'https: //api.github.com/users/wuodar/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/wuodar/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/wuodar/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/wuodar/subscriptions',
   'organizations_url': 'https: //api.github.com/users/wuodar/orgs',
   'repos_url': 'https: //api.github.com/users/wuodar/repos',
   'events_url': 'https: //api.github.com/users/wuodar/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/wuodar/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-06-03T06: 34: 56Z',
  'updated_at': '2024-06-03T06: 34: 56Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "**Describe the Feature**\r\n\r\nCurrently, the output parser is hardcoded as JSON Parser. There is not even a way to customize the prompt, which works poorly with models like Claude. \r\n\r\nIt would be much easier to work with RAGAS if it would be possible to just pass custom parser to places where it's used.\r\n\r\n\r\n**Why is the feature important for you?**\r\n\r\nMany 'nan' values in GT in generated dataset.\r\n\r\n\r\n<!-- PS: Thanks for your valuable feedback. Really! Its feedback from valuable community members like you that help us make Ragas event better for the whole community. So thanks again for taking the time to improve our community 🙂 -->\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1004/reactions',
   'total_count': 3,
   '+1': 3,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1004/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1003',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1003/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1003/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1003/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1003',
  'id': 2329875932,
  'node_id': 'I_kwDOJgX1Gs6K3xXc',
  'number': 1003,
  'title': 'TestsetGenerator.from_langchain Generating failed, randomly stuck at 0% to 80%.',
  'user': {'login': 'pp6699',
   'id': 154883132,
   'node_id': 'U_kgDOCTtUPA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/154883132?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/pp6699',
   'html_url': 'https: //github.com/pp6699',
   'followers_url': 'https: //api.github.com/users/pp6699/followers',
   'following_url': 'https: //api.github.com/users/pp6699/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/pp6699/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/pp6699/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/pp6699/subscriptions',
   'organizations_url': 'https: //api.github.com/users/pp6699/orgs',
   'repos_url': 'https: //api.github.com/users/pp6699/repos',
   'events_url': 'https: //api.github.com/users/pp6699/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/pp6699/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-06-02T21: 40: 38Z',
  'updated_at': '2024-08-10T09: 46: 50Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Your Question**\r\nTestsetGenerator.from_langchain Generating failed, randomly stuck at 0% to 80% And I\'ve been consuming tokens from the OpenAI API.\r\n\r\nBy the way, my embedded documents are in Chinese. Would this potentially affect this case?\r\n\r\nI am a student who has just started programming, and my understanding of related knowledge is limited. I would be very grateful if there were experts who could understand my incomplete questions and help me.\r\n\r\n```\r\nFilename and doc_id are the same for all nodes.\r\nGenerating:  70%|██████████████████████████████████████████████████████▌                       | 7/10 [01:29<00:43, 14.33s/it]\r\n```\r\n\r\n**Code Examples**\r\n```\r\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\r\nimport os\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\n\r\nos.environ["OPENAI_API_KEY"] = "sk-xxx"\r\n\r\nwith open("RAGAS\\output.md", encoding=\'utf-8\') as f:\r\n    state_of_the_union = f.read()\r\n\r\ntext_splitter = RecursiveCharacterTextSplitter(\r\n    # Set a really small chunk size, just to show.\r\n    chunk_size=512,\r\n    chunk_overlap=128,\r\n    length_function=len,\r\n    is_separator_regex=False,\r\n    separators=[\r\n    "###"\r\n    ]\r\n)\r\n\r\ndocuments = text_splitter.create_documents([state_of_the_union])\r\nprint(documents[0])\r\n\r\ngenerator_llm = ChatOpenAI(model="gpt-3.5-turbo")\r\ncritic_llm = ChatOpenAI(model="gpt-3.5-turbo")\r\nembeddings = OpenAIEmbeddings()\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context,conditional\r\n\r\ngenerator.adapt(language="chinese",evolutions=[simple, multi_context, conditional, reasoning])\r\ngenerator.save(evolutions=[simple, reasoning, multi_context,conditional])\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},  is_async=False)\r\n\r\ntestset.to_pandas()\r\n\r\ntestset.to_pandas().to_csv("RAGAS\\output.csv", index=False)\r\n```\r\n\r\n**Additional context**\r\nAnything else you want to share with us? \r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1003/reactions',
   'total_count': 3,
   '+1': 3,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1003/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1002',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1002/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1002/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1002/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1002',
  'id': 2329110348,
  'node_id': 'I_kwDOJgX1Gs6K02dM',
  'number': 1002,
  'title': "I've been encountering an issue where Ragas generates test cases from the initially uploaded documents, even after updating the documents and rerunning the process. It either uses the old documents or mixes them with the new ones.",
  'user': {'login': 'AliHaider0343',
   'id': 138858887,
   'node_id': 'U_kgDOCEbRhw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/138858887?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/AliHaider0343',
   'html_url': 'https: //github.com/AliHaider0343',
   'followers_url': 'https: //api.github.com/users/AliHaider0343/followers',
   'following_url': 'https: //api.github.com/users/AliHaider0343/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/AliHaider0343/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/AliHaider0343/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/AliHaider0343/subscriptions',
   'organizations_url': 'https: //api.github.com/users/AliHaider0343/orgs',
   'repos_url': 'https: //api.github.com/users/AliHaider0343/repos',
   'events_url': 'https: //api.github.com/users/AliHaider0343/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/AliHaider0343/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-06-01T12: 14: 53Z',
  'updated_at': '2024-06-17T11: 56: 59Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ ] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nwhat is unclear to you? What would you like to know?\r\n\r\n**Code Examples**\r\nThis community speaks code. Share your code snippets to help us understand your question better.\r\n\r\n**Additional context**\r\nAnything else you want to share with us? \r\n\r\n### Code\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\ntestset = generator.generate_with_langchain_docs(\r\n    documents,\r\n    test_size=3,\r\n    distributions={\r\n        'simple': 0.5,\r\n        'reasoning': 0.25,\r\n        'multi_context': 0.25\r\n    }\r\n)\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1002/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1002/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1000',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1000/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1000/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1000/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/1000',
  'id': 2327062189,
  'node_id': 'I_kwDOJgX1Gs6KtCat',
  'number': 1000,
  'title': 'Output testset when using Llama 3 8B instruct model is not proper.',
  'user': {'login': 'Nandakishore-Thekkadathu',
   'id': 167034618,
   'node_id': 'U_kgDOCfS--g',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/167034618?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Nandakishore-Thekkadathu',
   'html_url': 'https: //github.com/Nandakishore-Thekkadathu',
   'followers_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/followers',
   'following_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/orgs',
   'repos_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/repos',
   'events_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Nandakishore-Thekkadathu/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-31T06: 31: 00Z',
  'updated_at': '2024-06-01T06: 36: 08Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'The testset that I generated using llama 3 8B instruct model has problematic output. Unnecessary phrases are there in the output alongside the questions. I have given an example below.\r\n  0: \'Here is a question that can be fully answered from the given context using the\r\n    keyphrase "Employee Self Service":\r\n\r\n\r\n    What is the procedure for an employee to apply for marriage leave through the\r\n    Employee Self Service portal?\'\r\n  1: \'Here is a rewritten version of the question:\r\n\r\n\r\n    "What\'\'s the daily limit for foreign exchange expenses when booking travel?"\r\n\r\n\r\n    I shortened the question by removing unnecessary words and used an abbreviation\r\n    ("expenses" instead of "foreign exchange entitlements"). I also rephrased the\r\n    question to make it more concise and indirect, while still conveying the same\r\n    meaning.\'\r\n    \r\n    How can i solve this? Can I adjust the prompts to the model? If yes, how?\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1000/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/1000/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/994',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/994/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/994/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/994/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/994',
  'id': 2320933877,
  'node_id': 'PR_kwDOJgX1Gs5wwiQ-',
  'number': 994,
  'title': 'Handle embeddings for empty strings in AnswerSimilarity class',
  'user': {'login': 'baptiste-pasquier',
   'id': 50556298,
   'node_id': 'MDQ6VXNlcjUwNTU2Mjk4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/50556298?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/baptiste-pasquier',
   'html_url': 'https: //github.com/baptiste-pasquier',
   'followers_url': 'https: //api.github.com/users/baptiste-pasquier/followers',
   'following_url': 'https: //api.github.com/users/baptiste-pasquier/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/baptiste-pasquier/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/baptiste-pasquier/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/baptiste-pasquier/subscriptions',
   'organizations_url': 'https: //api.github.com/users/baptiste-pasquier/orgs',
   'repos_url': 'https: //api.github.com/users/baptiste-pasquier/repos',
   'events_url': 'https: //api.github.com/users/baptiste-pasquier/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/baptiste-pasquier/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745904,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uosA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:XS',
    'name': 'size:XS',
    'color': '00ff00',
    'default': False,
    'description': 'This PR changes 0-9 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-28T12: 24: 20Z',
  'updated_at': '2024-05-28T15: 00: 59Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/994',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/994',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/994.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/994.patch',
   'merged_at': None
            },
  'body': 'Fixes: #996 \r\n\r\nSome embedding models do not work with empty strings (for example Gemini) and return an error.\r\nThe error does not appear with OpenAI which returns an embeddings even for an empty string.\r\n\r\nProposed resolution: replace empty strings with `" "`',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/994/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/994/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/993',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/993/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/993/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/993/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/993',
  'id': 2320411850,
  'node_id': 'I_kwDOJgX1Gs6KTqzK',
  'number': 993,
  'title': 'Using context utilization without ground truth throws error message',
  'user': {'login': 'dschwalm',
   'id': 13940661,
   'node_id': 'MDQ6VXNlcjEzOTQwNjYx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/13940661?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/dschwalm',
   'html_url': 'https: //github.com/dschwalm',
   'followers_url': 'https: //api.github.com/users/dschwalm/followers',
   'following_url': 'https: //api.github.com/users/dschwalm/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/dschwalm/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/dschwalm/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/dschwalm/subscriptions',
   'organizations_url': 'https: //api.github.com/users/dschwalm/orgs',
   'repos_url': 'https: //api.github.com/users/dschwalm/repos',
   'events_url': 'https: //api.github.com/users/dschwalm/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/dschwalm/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-28T08: 09: 03Z',
  'updated_at': '2024-05-28T08: 10: 28Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[ x
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\n\r\nI am getting the error message below when not providing ground truth and using context utilization metric:\r\n\r\n"Looks like you\'re trying to use \'context_precision\' without ground_truth. Please use consider using  `context_utilization\' instead."\r\n\r\nRagas version: 0.1.8\r\nPython version: 3.10.10\r\n\r\n**Code to Reproduce**\r\n\r\n`\r\nresult = evaluate(dataset=dataset, llm=llm, embeddings=embeddings, metrics=[faithfulness, context_utilization])\r\n\r\n`\r\n\r\nThis is from validation.py:\r\n\r\n`\r\nif (\r\n                isinstance(m, ContextPrecision)\r\n                and "ground_truth" not in available_columns\r\n            ):\r\n                extra_msg = "Looks like you\'re trying to use \'context_precision\' without ground_truth. Please use consider using  `context_utilization\' instead."\r\n\r\n`\r\n\r\nFrom _context_precision.py it can be seen the context_utilization is a subclass of context_precision so either this error message is wrong or context_utilization also does need ground truth to be specified.\r\n\r\n`\r\n\r\nclass ContextUtilization(ContextPrecision):\r\n    name: str = "context_utilization"\r\n    evaluation_mode: EvaluationMode = EvaluationMode.qac\r\n\r\n    def get_dataset_attributes(self, dataset: Dataset):\r\n        return dataset["question"], dataset["contexts"], dataset["answer"]\r\n\r\n\r\ncontext_precision = ContextPrecision()\r\ncontext_utilization = ContextUtilization()\r\n\r\n`\r\n\r\n**Expected behavior**\r\n\r\nI expect not getting this error message if I use context_utilization metric only without ground truth OR the error message should indicate that ground truth is required for context_utilization as well OR ground truth should not be required for context utilization.\r\n\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/993/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/993/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/992',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/992/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/992/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/992/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/992',
  'id': 2320345698,
  'node_id': 'I_kwDOJgX1Gs6KTapi',
  'number': 992,
  'title': '[R-282
            ] use callbacks to trace reasoning of `Prompt`',
  'user': {'login': 'JinSeoung-Oh',
   'id': 78573459,
   'node_id': 'MDQ6VXNlcjc4NTczNDU5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/78573459?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/JinSeoung-Oh',
   'html_url': 'https: //github.com/JinSeoung-Oh',
   'followers_url': 'https: //api.github.com/users/JinSeoung-Oh/followers',
   'following_url': 'https: //api.github.com/users/JinSeoung-Oh/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/JinSeoung-Oh/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/JinSeoung-Oh/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/JinSeoung-Oh/subscriptions',
   'organizations_url': 'https: //api.github.com/users/JinSeoung-Oh/orgs',
   'repos_url': 'https: //api.github.com/users/JinSeoung-Oh/repos',
   'events_url': 'https: //api.github.com/users/JinSeoung-Oh/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/JinSeoung-Oh/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  },
                  {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                  ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
            },
  'comments': 3,
  'created_at': '2024-05-28T07: 34: 00Z',
  'updated_at': '2024-09-02T07: 06: 45Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "Hi, at first, I want to say thanks this wonderful work.\r\n\r\nActually, I want save the reason of evaluation.\r\nI mean, line 69 to line 106 at https://github.com/explodinggradients/ragas/blob/main/src/ragas/metrics/_answer_correctness.py\r\nActually, it already has save function and it seems save line 69~106.\r\nAh, of course it is example, but I think this module generate something like this line.\r\nI just want to save it\r\n\r\nBut I tried use this save function, it returned 'None'\r\n\r\nSo, how can I save this?\r\nI have to build new module for this?\r\n\r\nThanks!\n\n<sub>[R-282](https://linear.app/exploding-gradients/issue/R-282/use-callbacks-to-trace-reasoning-of-prompt)</sub>",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/992/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/992/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/991',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/991/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/991/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/991/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/991',
  'id': 2318778104,
  'node_id': 'I_kwDOJgX1Gs6KNb74',
  'number': 991,
  'title': '[R-262
            ] ImportError: llama_index must be installed to use this function. Please, install it with `pip install llama_index`.',
  'user': {'login': 'Prabhjot410',
   'id': 58880607,
   'node_id': 'MDQ6VXNlcjU4ODgwNjA3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/58880607?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Prabhjot410',
   'html_url': 'https: //github.com/Prabhjot410',
   'followers_url': 'https: //api.github.com/users/Prabhjot410/followers',
   'following_url': 'https: //api.github.com/users/Prabhjot410/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Prabhjot410/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Prabhjot410/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Prabhjot410/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Prabhjot410/orgs',
   'repos_url': 'https: //api.github.com/users/Prabhjot410/repos',
   'events_url': 'https: //api.github.com/users/Prabhjot410/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Prabhjot410/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  },
                  {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-27T10: 07: 11Z',
  'updated_at': '2024-06-01T06: 43: 39Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[ ] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nI am following ragas official document for testset generation. I am using custom llm (huggingfacepipeline) and huggingface embedding model, but whenever I am running this code, I am getting this error : ImportError: llama_index must be installed to use this function. Please, install it with `pip install llama_index`.\r\n\r\n\r\n**Code Examples**\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\n# generate testset\r\ntestset = generator.generate_with_langchain_docs(overall, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\r\n\r\n**Additional context**\r\nI have already install llama_index and ragas version 0.0.22. \r\n\r\nHow can I solve this problem ?\n\n<sub>[R-262](https://linear.app/exploding-gradients/issue/R-262/importerror-llama-index-must-be-installed-to-use-this-function-please)</sub>",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/991/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/991/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/989',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/989/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/989/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/989/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/989',
  'id': 2316867434,
  'node_id': 'I_kwDOJgX1Gs6KGJdq',
  'number': 989,
  'title': 'division by zero when computing output score',
  'user': {'login': 'theoden8',
   'id': 12466435,
   'node_id': 'MDQ6VXNlcjEyNDY2NDM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/12466435?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/theoden8',
   'html_url': 'https: //github.com/theoden8',
   'followers_url': 'https: //api.github.com/users/theoden8/followers',
   'following_url': 'https: //api.github.com/users/theoden8/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/theoden8/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/theoden8/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/theoden8/subscriptions',
   'organizations_url': 'https: //api.github.com/users/theoden8/orgs',
   'repos_url': 'https: //api.github.com/users/theoden8/repos',
   'events_url': 'https: //api.github.com/users/theoden8/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/theoden8/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-25T09: 22: 25Z',
  'updated_at': '2024-05-25T09: 23: 27Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Good time of the day,\r\n\r\nHere https: //github.com/explodinggradients/ragas/blob/main/src/ragas/testset/filters.py#L60 is a division by zero, which I encounter when using ragas with ollama+llama3-8b.\r\n\r\nTo solve it, I can replace:\r\n\r\n```\r\noutput["score"] = sum(output.values()) / len(output.values())\r\n```\r\n\r\nKeeps failing at the final stage. Can be fixed with\r\n\r\n```\r\nif len(output.values()) == 0:\r\n    output[\'score\'] = .0\r\nelse:\r\n    output["score"] = sum(output.values()) / len(output.values())\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/989/reactions',
   'total_count': 3,
   '+1': 3,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/989/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/986',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/986/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/986/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/986/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/986',
  'id': 2312723000,
  'node_id': 'I_kwDOJgX1Gs6J2Vo4',
  'number': 986,
  'title': 'is_async missing in context_relevancy in ragas 0.1.8',
  'user': {'login': 'abetatos',
   'id': 76526314,
   'node_id': 'MDQ6VXNlcjc2NTI2MzE0',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/76526314?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/abetatos',
   'html_url': 'https: //github.com/abetatos',
   'followers_url': 'https: //api.github.com/users/abetatos/followers',
   'following_url': 'https: //api.github.com/users/abetatos/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/abetatos/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/abetatos/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/abetatos/subscriptions',
   'organizations_url': 'https: //api.github.com/users/abetatos/orgs',
   'repos_url': 'https: //api.github.com/users/abetatos/repos',
   'events_url': 'https: //api.github.com/users/abetatos/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/abetatos/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6266605368,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTPOA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-metrics',
    'name': 'module-metrics',
    'color': '883104',
    'default': False,
    'description': 'this is part of metrics module'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-23T11: 53: 02Z',
  'updated_at': '2024-06-01T06: 51: 56Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'body': 'In ragas 0.1.8 in _context_relevancy.py\r\n\r\n```python\r\n    async def _ascore(self, row: t.Dict, callbacks: Callbacks, is_async: bool) -> float:\r\n        assert self.llm is not None,
            "LLM is not initialized"\r\n\r\n        if self.show_deprecation_warning:\r\n            logger.warning(\r\n                "The \'context_relevancy\' metric is going to be deprecated soon! Please use the \'context_precision\' metric instead. It is a drop-in replacement just a simple search and replace should work."  # noqa\r\n            )\r\n\r\n        question, contexts = row[
                  "question"
            ], row[
                  "contexts"
            ]\r\n        result = await self.llm.generate(\r\n            self.context_relevancy_prompt.format(\r\n                question=question, context="\\n".join(contexts)\r\n            ),\r\n            callbacks=callbacks\r\n        )\r\n        return self._compute_score(result.generations[
                  0
            ][
                  0
            ].text, row)\r\n\r\n```\r\n\r\nI think  self.llm.generate is missing is_async=is_async. I don\'t know if this is a bug or not, but found it weird it was the only one who lacked the argument and in my setup is failing only this metric. \r\n\r\nThank you in advance!\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/986/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/986/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/985',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/985/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/985/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/985/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/985',
  'id': 2310926929,
  'node_id': 'I_kwDOJgX1Gs6JvfJR',
  'number': 985,
  'title': 'Can this part of the code be applied to Chinese scenarios',
  'user': {'login': 'w666x',
   'id': 19973726,
   'node_id': 'MDQ6VXNlcjE5OTczNzI2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/19973726?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/w666x',
   'html_url': 'https: //github.com/w666x',
   'followers_url': 'https: //api.github.com/users/w666x/followers',
   'following_url': 'https: //api.github.com/users/w666x/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/w666x/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/w666x/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/w666x/subscriptions',
   'organizations_url': 'https: //api.github.com/users/w666x/orgs',
   'repos_url': 'https: //api.github.com/users/w666x/repos',
   'events_url': 'https: //api.github.com/users/w666x/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/w666x/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-22T16: 09: 39Z',
  'updated_at': '2024-06-01T06: 56: 16Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Your Question**\r\nCan this part of the code be **applied to Chinese scenarios**? I see there are many places in the code that enforce English directly.\r\n- such as, the below part1,  ``sentence for sentence in sentences if sentence.strip().endswith(".")``\r\n- the below part2, ``language="english",``\r\n\r\n**Code Examples**\r\n    \r\n    # code in _faithfulness.py\r\n    @dataclass\r\n    class Faithfulness(MetricWithLLM):\r\n        ...\r\n\r\n        def _create_statements_prompt(self, row: t.Dict) -> PromptValue:\r\n            assert self.sentence_segmenter is not None, "sentence_segmenter is not set"\r\n\r\n            text, question = row["answer"], row["question"]\r\n            sentences = self.sentence_segmenter.segment(text)\r\n            sentences = [\r\n                sentence for sentence in sentences if sentence.strip().endswith(".")\r\n            ]\r\n            sentences = "\\n".join([f"{i}:{x}" for i, x in enumerate(sentences)])\r\n            prompt_value = self.statement_prompt.format(\r\n                question=question, answer=text, sentences=sentences\r\n            )\r\n            return prompt_value\r\n\r\n\r\n**Code Examples**\r\n\r\n    LONG_FORM_ANSWER_PROMPT = Prompt(\r\n        name="long_form_answer",\r\n        output_format_instruction=_statements_output_instructions,\r\n        instruction="Given a question, an answer, and sentences from the answer analyze the complexity of each sentence given under \'sentences\' and break down each sentence into one or more fully understandable statements while also ensuring no pronouns are used in each statement. Format the outputs in JSON.",\r\n        examples=[\r\n            {\r\n                "question": "Who was Albert Einstein and what is he best known for?",\r\n                "answer": "He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.",\r\n                "sentences": """\r\n            0:He was a German-born theoretical physicist, widely acknowledged to be one of the greatest and most influential physicists of all time. \r\n            1:He was best known for developing the theory of relativity, he also made important contributions to the development of the theory of quantum mechanics.\r\n            """,\r\n                "analysis": StatementsAnswers.parse_obj(\r\n                    [\r\n                        {\r\n                            "sentence_index": 0,\r\n                            "simpler_statements": [\r\n                                "Albert Einstein was a German-born theoretical physicist.",\r\n                                "Albert Einstein is recognized as one of the greatest and most influential physicists of all time.",\r\n                            ],\r\n                        },\r\n                        {\r\n                            "sentence_index": 1,\r\n                            "simpler_statements": [\r\n                                "Albert Einstein was best known for developing the theory of relativity.",\r\n                                "Albert Einstein also made important contributions to the development of the theory of quantum mechanics.",\r\n                            ],\r\n                        },\r\n                    ]\r\n                ).dicts(),\r\n            }\r\n        ],\r\n        input_keys=["question", "answer", "sentences"],\r\n        output_key="analysis",\r\n        language="english",\r\n    )',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/985/reactions',
   'total_count': 3,
   '+1': 3,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/985/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/982',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/982/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/982/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/982/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/982',
  'id': 2308390828,
  'node_id': 'PR_kwDOJgX1Gs5wFqnh',
  'number': 982,
  'title': 'Improve JSON format prompt for large chunks & Handle ZeroDivisionError',
  'user': {'login': 'Manav916',
   'id': 77217074,
   'node_id': 'MDQ6VXNlcjc3MjE3MDc0',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/77217074?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Manav916',
   'html_url': 'https: //github.com/Manav916',
   'followers_url': 'https: //api.github.com/users/Manav916/followers',
   'following_url': 'https: //api.github.com/users/Manav916/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Manav916/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Manav916/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Manav916/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Manav916/orgs',
   'repos_url': 'https: //api.github.com/users/Manav916/repos',
   'events_url': 'https: //api.github.com/users/Manav916/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Manav916/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745915,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uouw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:S',
    'name': 'size:S',
    'color': '77b800',
    'default': False,
    'description': 'This PR changes 10-29 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-21T14: 02: 45Z',
  'updated_at': '2024-05-31T12: 55: 30Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/982',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/982',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/982.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/982.patch',
   'merged_at': None
            },
  'body': "## Description\r\nIn this PR there are three different changes\r\n## Changes\r\n\r\n1. Fixed a Typo in the filter_question_prompt Instruction from `Asses` to `Assess`\r\n2. Added a try-except block for handling ZeroDivisionError for the filter method in the NodeFilter class\r\n3. Improved the JSON_FORMAT_INSTRUCTIONS for better output generation\r\nIt seems like the LLM sometimes loses track of the imposed instruction for the output, especially for long prompts. So although the output generated for a chunk_size of 512 is perfect, the output for a chunk_size of 1024 has an extra newline. Here parsing fails when using PydanticOutputParser even though the llm has generated an output and there is only an extra `'\\n'` as shown in the instances below.\r\n![Screenshot 2024-05-22 093242](https://github.com/explodinggradients/ragas/assets/77217074/4092546d-ad0c-4269-8216-3d8f7cef4a89)\r\nBut by tuning the prompt and adding `Please output your response in the demanded json format.` at the end of the instruction we get output without `'\\n'`. This output can then be parsed and the context can be considered.\r\n![Screenshot 2024-05-22 093757](https://github.com/explodinggradients/ragas/assets/77217074/3ac9bb3f-1ff5-4d6b-ba99-d67729d2b23f)\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/982/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/982/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/978',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/978/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/978/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/978/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/978',
  'id': 2307621863,
  'node_id': 'I_kwDOJgX1Gs6Ji4Pn',
  'number': 978,
  'title': '[R-256
            ] make better example dataset for getting started',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6266607768,
    'node_id': 'LA_kwDOJgX1Gs8AAAABdYTYmA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/module-testsetgen',
    'name': 'module-testsetgen',
    'color': '883104',
    'default': False,
    'description': 'Module testset generation'
                  },
                  {'id': 6977963521,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn-tGAQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/Improvement',
    'name': 'Improvement',
    'color': '4EA7FC',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-21T08: 02: 44Z',
  'updated_at': '2024-05-21T08: 04: 56Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'Add better testset using the testset generation features of 2 dataset\n\n1. Githlab Handbook\n2. Arxiv Papers on LLMs\n\nNeed to figure out the number of testsets needed\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-256](https://linear.app/exploding-gradients/issue/R-256/make-better-example-dataset-for-getting-started)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/978/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/978/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/977',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/977/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/977/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/977/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/977',
  'id': 2306119749,
  'node_id': 'I_kwDOJgX1Gs6JdJhF',
  'number': 977,
  'title': 'Tried Generation Test Set from Together APIs and Hugging Face Embeddings',
  'user': {'login': 'Eknathabhiram',
   'id': 150422670,
   'node_id': 'U_kgDOCPdEjg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/150422670?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Eknathabhiram',
   'html_url': 'https: //github.com/Eknathabhiram',
   'followers_url': 'https: //api.github.com/users/Eknathabhiram/followers',
   'following_url': 'https: //api.github.com/users/Eknathabhiram/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Eknathabhiram/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Eknathabhiram/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Eknathabhiram/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Eknathabhiram/orgs',
   'repos_url': 'https: //api.github.com/users/Eknathabhiram/repos',
   'events_url': 'https: //api.github.com/users/Eknathabhiram/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Eknathabhiram/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-05-20T14: 25: 46Z',
  'updated_at': '2024-07-25T08: 57: 32Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nTried Generation Test Set from Together APIs and Hugging Face Embeddings\r\n\r\nRagas version:0.1.7\r\nPython version: 3.9\r\n\r\n**Code to Reproduce**\r\n```py\r\nimport os\r\nfrom langchain_community.document_loaders import PyPDFDirectoryLoader\r\nfrom langchain.embeddings import SentenceTransformerEmbeddings\r\n\r\n\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom langchain_together import Together\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\ngenerator_llm = Together(\r\n        model="mistralai/Mistral-7B-Instruct-v0.2",\r\n        together_api_key=os.getenv("TOGETHER_API_KEY")\r\n    )\r\ncritic_llm = Together(\r\n        model="meta-llama/Llama-3-70b-chat-hf",\r\n        together_api_key=os.getenv("TOGETHER_API_KEY")\r\n    )\r\n\r\n\r\nembeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\nloader = PyPDFDirectoryLoader("FilePath")\r\ndocuments = loader.load()\r\n# generate testset\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\r\nprint(testset)\r\ntestset.to_pandas().to_csv()\r\n```\r\n**Error trace**\r\n\r\n**Expected behavior**\r\n```\r\nFilename and doc_id are the same for all nodes.                                                                     \r\nGenerating:   0%|                                                                            | 0/10 [00:00<?, ?it/s]Failed to parse output. Returning None.\r\nGenerating:   0%|                                                                            | 0/10 [00:10<?, ?it/s]\r\nException in thread Thread-5:\r\nTraceback (most recent call last):\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/threading.py", line 980, in _bootstrap_inner\r\n    self.run()\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 96, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete\r\n    return future.result()\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 84, in _aresults\r\n    raise e\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 142, in evolve\r\n    ) = await self._aevolve(current_tries, current_nodes)\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 290, in _aevolve\r\n    passed = await self.node_filter.filter(merged_node)\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/filters.py", line 60, in filter\r\n    output["score"] = sum(output.values()) / len(output.values())\r\nZeroDivisionError: division by zero\r\nTraceback (most recent call last):\r\n  File "/home//Documents/RAG Pipeline/new_demo/test.py", line 34, in <module>\r\n    testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/generator.py", line 179, in generate_with_langchain_docs\r\n    return self.generate(\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/generator.py", line 274, in generate\r\n    raise ExceptionInRunner()\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\r\nException ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x7f2d728700c0>\r\nTraceback (most recent call last):\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 142, in evolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 545, in _aevolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 373, in _acomplex_evolution\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 290, in _aevolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/filters.py", line 58, in filter\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/llms/output_parser.py", line 67, in aparse\r\nKeyError: \'idle_for\'\r\nException ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x7f2d728709c0>\r\nTraceback (most recent call last):\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 142, in evolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 460, in _aevolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 290, in _aevolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/filters.py", line 58, in filter\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/llms/output_parser.py", line 67, in aparse\r\nKeyError: \'idle_for\'\r\nException ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x7f2d72870bc0>\r\nTraceback (most recent call last):\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 142, in evolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 545, in _aevolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 373, in _acomplex_evolution\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 306, in _aevolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/filters.py", line 89, in filter\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/llms/base.py", line 92, in generate\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 142, in async_wrapped\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 58, in __call__\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 110, in iter\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 78, in inner\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/__init__.py", line 420, in next_action\r\nKeyError: \'idle_for\'\r\nException ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x7f2d729a4cc0>\r\nTraceback (most recent call last):\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 142, in evolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/testset/evolutions.py", line 298, in _aevolve\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/llms/base.py", line 92, in generate\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 142, in async_wrapped\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 58, in __call__\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 110, in iter\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/_asyncio.py", line 78, in inner\r\n  File "/home//anaconda3/envs/rag-env/lib/python3.9/site-packages/tenacity/__init__.py", line 420, in next_action\r\nKeyError: \'idle_for\'\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-677\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d728b7160>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-675\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d72910ca0>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-673\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d728b70a0>()]> cb=[as_completed.<locals>._on_completion() at /home/\'/anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-681\' coro=<as_completed.<locals>.sema_coro() running at /home/\'/anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d72970b50>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-674\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d726395e0>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-678\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d72903670>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-676\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d726352b0>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-679\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d727dad90>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-682\' coro=<as_completed.<locals>.sema_coro() running at /home//anaconda3/envs/rag-env/lib/python3.9/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[<TaskWakeupMethWrapper object at 0x7f2d72957640>()]> cb=[as_completed.<locals>._on_completion() at /home//anaconda3/envs/rag-env/lib/python3.9/asyncio/tasks.py:598]>\r\n```\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/977/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/977/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/968',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/968/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/968/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/968/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/968',
  'id': 2302883485,
  'node_id': 'I_kwDOJgX1Gs6JQzad',
  'number': 968,
  'title': 'Un-deprecate multiple ground truth answers?',
  'user': {'login': 'athewsey',
   'id': 19252478,
   'node_id': 'MDQ6VXNlcjE5MjUyNDc4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/19252478?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/athewsey',
   'html_url': 'https: //github.com/athewsey',
   'followers_url': 'https: //api.github.com/users/athewsey/followers',
   'following_url': 'https: //api.github.com/users/athewsey/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/athewsey/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/athewsey/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/athewsey/subscriptions',
   'organizations_url': 'https: //api.github.com/users/athewsey/orgs',
   'repos_url': 'https: //api.github.com/users/athewsey/repos',
   'events_url': 'https: //api.github.com/users/athewsey/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/athewsey/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-17T14: 19: 46Z',
  'updated_at': '2024-06-01T07: 29: 02Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "**Describe the Feature**\r\n\r\nPer the deprecation message I receive in v0.1.7:\r\n\r\n```\r\npassing column names as 'ground_truths' is deprecated and will be removed in the next version,\r\nplease use 'ground_truth' instead. Note that `ground_truth` should be of type string and not\r\nSequence[string] like `ground_truths`\r\n```\r\n\r\n...It seems like providing multiple alternative ground-truth answers to a question *used to be* supported but is being removed? \r\n\r\nI couldn't quite figure out the situation on this from the docs or issues (maybe I just missed something somewhere?), but I'd like for Ragas to support multiple reference answers per question, if possible.\r\n\r\n**Why is the feature important for you?**\r\n\r\nI have a document-based question answering dataset where we've seen a few cases of questions which could have multiple correct answers - sometimes very similar, but in other cases quite semantically distinct. We don't necessarily have to score the alternative GT answers separately, but it seems like we need to clarify to the evaluator LLM that either of the options are equally valid, to receive reliable judgments... And it's not clear to me how to do that going forward, if `ground_truth` needs to become a single string?\r\n\r\n**Additional context**\r\n\r\nThanks for your great work on the library! Really appreciate having an evaluation tool that maintains some separation from the actual orchestration of the chain/RAG.",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/968/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/968/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/967',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/967/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/967/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/967/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/967',
  'id': 2302161014,
  'node_id': 'I_kwDOJgX1Gs6JODB2',
  'number': 967,
  'title': 'Is it possible to add an argument to the evaluate() function to configure the group name?',
  'user': {'login': 'zzzmc',
   'id': 75374117,
   'node_id': 'MDQ6VXNlcjc1Mzc0MTE3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/75374117?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/zzzmc',
   'html_url': 'https: //github.com/zzzmc',
   'followers_url': 'https: //api.github.com/users/zzzmc/followers',
   'following_url': 'https: //api.github.com/users/zzzmc/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/zzzmc/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/zzzmc/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/zzzmc/subscriptions',
   'organizations_url': 'https: //api.github.com/users/zzzmc/orgs',
   'repos_url': 'https: //api.github.com/users/zzzmc/repos',
   'events_url': 'https: //api.github.com/users/zzzmc/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/zzzmc/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-17T08: 47: 31Z',
  'updated_at': '2024-06-01T07: 30: 56Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nAdd an argument to the evaluate() function to define the group name instead of using the default value "ragas evaluation".\r\n\r\n**Why is the feature important for you?**\r\nWhen using langsmith to display evaluation results, different configurations or other situations may be used under the same project. \r\nWhen using the new_group() in evaluate.py, is it more flexible to pass arguments to determine the value of the argument \'name\' instead of the default \'ragas evaluation\'?The langsmith interface will also distinguish different results more clearly.\r\n\r\n**Additional context**\r\nragas: 0.1.7 \r\nhttps: //github.com/explodinggradients/ragas/blob/main/src/ragas/evaluation.py\r\nOriginal version：\r\n![image](https://github.com/explodinggradients/ragas/assets/75374117/f78f6d95-ca4e-4912-b9b2-7a6d112a2dfe)\r\n![image](https://github.com/explodinggradients/ragas/assets/75374117/1490f10a-7b74-4dd1-9782-72495f4818b2)\r\nModified version：\r\n![image](https://github.com/explodinggradients/ragas/assets/75374117/07fa111b-3d36-465c-9639-7c226b9755fa)\r\n![image](https://github.com/explodinggradients/ragas/assets/75374117/4b887460-6d6a-4251-ac24-2bd76f8ed6a9)\r\n\r\n\r\n<!-- PS: Thanks for your valuable feedback. Really! Its feedback from valuable community members like you that help us make Ragas event better for the whole community. So thanks again for taking the time to improve our community 🙂 -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/967/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/967/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/966',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/966/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/966/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/966/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/966',
  'id': 2302136219,
  'node_id': 'I_kwDOJgX1Gs6JN8-b',
  'number': 966,
  'title': 'Testset generation ValueError: invalid literal for int() with base 10:',
  'user': {'login': 'choshiho',
   'id': 17508435,
   'node_id': 'MDQ6VXNlcjE3NTA4NDM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/17508435?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/choshiho',
   'html_url': 'https: //github.com/choshiho',
   'followers_url': 'https: //api.github.com/users/choshiho/followers',
   'following_url': 'https: //api.github.com/users/choshiho/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/choshiho/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/choshiho/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/choshiho/subscriptions',
   'organizations_url': 'https: //api.github.com/users/choshiho/orgs',
   'repos_url': 'https: //api.github.com/users/choshiho/repos',
   'events_url': 'https: //api.github.com/users/choshiho/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/choshiho/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-05-17T08: 34: 43Z',
  'updated_at': '2024-06-06T06: 52: 43Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\n```py\r\ntestset = TestsetGenerator.generate_with_langchain_docs() , The program encountered an issue and terminated unexpectedly.\r\nif int(i) - 1 < len(current_nodes.nodes)\r\n       ^^^^^^\r\nValueError: invalid literal for int() with base 10:\r\n```\r\n\r\nRagas version: 0.1.7\r\nPython version: 3.11.7\r\n\r\n**Code to Reproduce**\r\nFirst, I deployed my Qwen1.5-7B-Chat-GPTQ-Int8 using the following command:\r\n\r\nCUDA_VISIBLE_DEVICES=1 python -m vllm.entrypoints.openai.api_server --served-model-name Qwen1.5-7B-Chat-GPTQ-Int8 --model /home/zhifeng.zhao/.cache/modelscope/hub/qwen/Qwen1___5-7B-Chat-GPTQ-Int8   --max-model-len 18576\r\n\r\nThen, The code in the jupyter notebook is as follows :\r\n\r\n```py\r\nchat = ChatOpenAI(\r\n    # streaming=True,\r\n    verbose=True,\r\n    openai_api_key=\'EMPTY\',\r\n    openai_api_base=\'http://localhost:8000/v1\',\r\n    model_name="Qwen1.5-7B-Chat-GPTQ-Int8",\r\n    temperature=0.0,\r\n    max_tokens=2048, # Maximum number of tokens to generate.\r\n    openai_proxy=\'\',\r\n)\r\nembedding_function = SentenceTransformerEmbeddings(model_name="/home/zhifeng.zhao/.cache/modelscope/hub/AI-ModelScope/bge-small-en-v1___5")\r\n\r\nfrom ragas.llms import LangchainLLMWrapper\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\n\r\nlangchain_llm = LangchainLLMWrapper(chat)\r\nlangchain_embeddings = LangchainEmbeddingsWrapper(embedding_function)\r\n\r\nfrom ragas.testset.generator import TestsetGenerator\r\n\r\ngenerator_llm = LangchainLLMWrapper(llm)\r\ncritic_llm = langchain_llm\r\n\r\n# generator with custom llm and embeddings\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm=chat,\r\n    critic_llm=langchain_llm,\r\n    embeddings=langchain_embeddings,\r\n) \r\n\r\n# default extractor\r\nfrom ragas.testset.extractor import KeyphraseExtractor\r\nfrom langchain.text_splitter import TokenTextSplitter\r\n# default DocumentStore\r\nfrom ragas.testset.docstore import InMemoryDocumentStore\r\n\r\n# init the DocumentStore with your own llm and embeddings\r\nsplitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=100)\r\nkeyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)\r\ndocstore = InMemoryDocumentStore(\r\n    splitter=splitter,\r\n    embeddings=langchain_embeddings,\r\n    extractor=keyphrase_extractor,\r\n)\r\n\r\nfrom langchain_openai import ChatOpenAI\r\nimport os\r\n\r\n\r\nfrom ragas.testset.prompts import (\r\n    context_scoring_prompt,\r\n    evolution_elimination_prompt,\r\n    filter_question_prompt,\r\n)\r\nfrom langchain_community.document_loaders import DirectoryLoader\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\n\r\n# remove demonstrations from examples\r\nfor prompt in [\r\n    context_scoring_prompt,\r\n    evolution_elimination_prompt,\r\n    filter_question_prompt,\r\n]:\r\n    prompt.examples = []\r\n\r\nfrom ragas.testset.filters import QuestionFilter, EvolutionFilter, NodeFilter\r\n\r\nqa_filter = QuestionFilter(langchain_llm, filter_question_prompt)\r\nnode_filter = NodeFilter(langchain_llm, context_scoring_prompt=context_scoring_prompt)\r\nevolution_filter = EvolutionFilter(langchain_llm, evolution_elimination_prompt)\r\n\r\ndistributions = {simple: 0.5, reasoning: 0.25, multi_context: 0.25}\r\n\r\n# customise the filters\r\nfrom ragas.testset.evolutions import ComplexEvolution\r\n\r\nfor evolution in distributions:\r\n    if evolution.question_filter is None:\r\n        evolution.question_filter = qa_filter\r\n    if evolution.node_filter is None:\r\n        evolution.node_filter = node_filter\r\n\r\n    if isinstance(evolution, ComplexEvolution):\r\n        if evolution.evolution_filter is None:\r\n            evolution.evolution_filter = evolution_filter\r\n\r\nloader = DirectoryLoader("/home/zhifeng.zhao/prompt-engineering-guide-papers", glob="*.pdf")\r\ndocuments = loader.load()\r\n\r\nfor document in documents:\r\n    document.metadata["filename"] = document.metadata["source"]\r\n\r\ndocuments = [doc for doc in documents if len(doc.page_content.split()) > 5000]\r\n\r\n# generator = TestsetGenerator.with_openai(chunk_size=512)\r\ntestset = generator.generate_with_langchain_docs(\r\n    documents[:10],\r\n    test_size=10,\r\n    raise_exceptions=False,\r\n    with_debugging_logs=False,\r\n    distributions=distributions,\r\n)\r\n```\r\n\r\n\r\n**Error trace**\r\n\r\n```\r\nRunner in Executor raised an exception\r\nTraceback (most recent call last):\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n        ^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/asyncio/tasks.py", line 615, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 144, in evolve\r\n    return await self.generate_datarow(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 210, in generate_datarow\r\n    selected_nodes = [\r\n                     ^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 213, in <listcomp>\r\n    if int(i) - 1 < len(current_nodes.nodes)\r\n       ^^^^^^\r\nValueError: invalid literal for int() with base 10: \'A: Adam bought 2 boxes of chocolate candy and 5 boxes of caramel candy. If each box has 4 pieces inside it, how much candy did he have total?\'\r\nRunner in Executor raised an exception\r\nTraceback (most recent call last):\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n        ^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/asyncio/tasks.py", line 615, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 144, in evolve\r\n    return await self.generate_datarow(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 210, in generate_datarow\r\n    selected_nodes = [\r\n                     ^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 213, in <listcomp>\r\n    if int(i) - 1 < len(current_nodes.nodes)\r\n       ^^^^^^\r\nValueError: invalid literal for int() with base 10: \'1. In the context of the model PaLM-540B, self-consistency aids in error repair by ensuring that reasoning paths generated by the model remain coherent and consistent with the ground truth. This is d\r\nRunner in Executor raised an exception\r\nTraceback (most recent call last):\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n        ^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/asyncio/tasks.py", line 615, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 144, in evolve\r\n    return await self.generate_datarow(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 210, in generate_datarow\r\n    selected_nodes = [\r\n                     ^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 213, in <listcomp>\r\n    if int(i) - 1 < len(current_nodes.nodes)\r\n       ^^^^^^\r\nValueError: invalid literal for int() with base 10: \'A: Let’s think step by step. Adam bought 2 boxes of chocolate candy and 5 boxes of caramel candy. Each box of candy has 4 pieces inside it. So, Adam bought 10 pieces of candy. Therefore, the answer (\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nRunner in Executor raised an exception\r\nTraceback (most recent call last):\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n        ^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/asyncio/tasks.py", line 615, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n           ^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 144, in evolve\r\n    return await self.generate_datarow(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 210, in generate_datarow\r\n    selected_nodes = [\r\n                     ^\r\n  File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py", line 213, in <listcomp>\r\n    if int(i) - 1 < len(current_nodes.nodes)\r\n       ^^^^^^\r\nValueError: invalid literal for int() with base 10: \'2. Adam bought 2 boxes of chocolate candy and 5 boxes of caramel candy. If each box has 4 pieces inside it, how much candy did he have total? (GT : 28)\'\r\nFailed to parse output. Returning None.\r\n```\r\n\r\n**Expected behavior**\r\nTestsetGenerator.generate_with_langchain_docs() returns a TestDataset object with 10 elements.\r\n\r\n\r\n**Additional context**\r\nI have edited File "/home/zhifeng.zhao/anaconda3/lib/python3.11/site-packages/ragas/testset/evolutions.py" as issues #900:\r\n`selected_nodes = [\r\n        current_nodes.nodes[int(i) - 1]\r\n        for i in relevant_context_indices\r\n        if int(i) - 1 < len(current_nodes.nodes)\r\n]`\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/966/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/966/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/965',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/965/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/965/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/965/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/965',
  'id': 2302096030,
  'node_id': 'I_kwDOJgX1Gs6JNzKe',
  'number': 965,
  'title': 'Answer Correctness giving wrong results for batches and single records',
  'user': {'login': 'aravindpai',
   'id': 47445826,
   'node_id': 'MDQ6VXNlcjQ3NDQ1ODI2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/47445826?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/aravindpai',
   'html_url': 'https: //github.com/aravindpai',
   'followers_url': 'https: //api.github.com/users/aravindpai/followers',
   'following_url': 'https: //api.github.com/users/aravindpai/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/aravindpai/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/aravindpai/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/aravindpai/subscriptions',
   'organizations_url': 'https: //api.github.com/users/aravindpai/orgs',
   'repos_url': 'https: //api.github.com/users/aravindpai/repos',
   'events_url': 'https: //api.github.com/users/aravindpai/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/aravindpai/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-17T08: 12: 23Z',
  'updated_at': '2024-06-01T10: 22: 20Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Answer correctness is giving wrong results for batches and single records. What could be the reason?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/965/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/965/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/964',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/964/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/964/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/964/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/964',
  'id': 2301718226,
  'node_id': 'I_kwDOJgX1Gs6JMW7S',
  'number': 964,
  'title': " Adapted output keys set(output.keys())={'深度', '相关性', '清晰度', '结构'} do not match with the original output keys: output_keys[i]={'structure', 'clarity', 'depth', 'relevance'}",
  'user': {'login': 'qism',
   'id': 41246272,
   'node_id': 'MDQ6VXNlcjQxMjQ2Mjcy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/41246272?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/qism',
   'html_url': 'https: //github.com/qism',
   'followers_url': 'https: //api.github.com/users/qism/followers',
   'following_url': 'https: //api.github.com/users/qism/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/qism/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/qism/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/qism/subscriptions',
   'organizations_url': 'https: //api.github.com/users/qism/orgs',
   'repos_url': 'https: //api.github.com/users/qism/repos',
   'events_url': 'https: //api.github.com/users/qism/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/qism/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-05-17T03: 02: 41Z',
  'updated_at': '2024-08-02T07: 24: 56Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\n```\r\n>>> generator.adapt(language, evolutions=[simple])\r\nTraceback (most recent call last):\r\n  File "<stdin>", line 1, in <module>\r\n  File "/opt/anaconda3/envs/rags_new/lib/python3.12/site-packages/ragas/testset/generator.py", line 305, in adapt\r\n    evolution.adapt(language, cache_dir=cache_dir)\r\n  File "/opt/anaconda3/envs/rags_new/lib/python3.12/site-packages/ragas/testset/evolutions.py", line 326, in adapt\r\n    super().adapt(language, cache_dir)\r\n  File "/opt/anaconda3/envs/rags_new/lib/python3.12/site-packages/ragas/testset/evolutions.py", line 262, in adapt\r\n    self.node_filter.adapt(language, cache_dir)\r\n  File "/opt/anaconda3/envs/rags_new/lib/python3.12/site-packages/ragas/testset/filters.py", line 69, in adapt\r\n    self.context_scoring_prompt = self.context_scoring_prompt.adapt(\r\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/opt/anaconda3/envs/rags_new/lib/python3.12/site-packages/ragas/llms/prompt.py", line 241, in adapt\r\n    set(output.keys()) == output_keys[i]\r\nAssertionError: Adapted output keys set(output.keys())={\'深度\', \'相关性\', \'清晰度\', \'结构\'} do not match with the original output keys: output_keys[i]={\'structure\', \'clarity\', \'depth\', \'relevance\'}\r\n```\r\nRagas version: 0.1.8.dev18+g2d79365\r\nPython version:3.10\r\n\r\n**Code to Reproduce**\r\n```py\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\ninference_server_url = "http://xxxxxx:port/v1"\r\nopenai_api_key = "sk-xxx"\r\n\r\ngenerator_llm  = ChatOpenAI(model="gpt-3.5-turbo-1106",\r\n    openai_api_key=openai_api_key,\r\n    openai_api_base=inference_server_url\r\n)\r\ncritic_llm = ChatOpenAI(model="gpt-4-1106-preview",\r\n    openai_api_key=openai_api_key,\r\n    openai_api_base=inference_server_url\r\n)\r\n                                      \r\nembeddings = HuggingFaceBgeEmbeddings(\r\n            model_name="BAAI/bge-large-en-v1.5",\r\n            model_kwargs={"device": "cpu"},\r\n            encode_kwargs={"normalize_embeddings": True},\r\n            query_instruction="embedding this sentence",\r\n        )\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context,conditional\r\nlanguage = "Chinese"\r\ngenerator.adapt(language, evolutions=[simple, reasoning, conditional, multi_context])\r\ngenerator.save(evolutions=[simple, reasoning, multi_context,conditional])\r\n```\r\n\r\n**Error trace**',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/964/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/964/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/963',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/963/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/963/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/963/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/963',
  'id': 2300457118,
  'node_id': 'I_kwDOJgX1Gs6JHjCe',
  'number': 963,
  'title': 'TestsetGenerator -> RuntimeError: ... got Future <..> attached to a differen t loop',
  'user': {'login': 'abetatos',
   'id': 76526314,
   'node_id': 'MDQ6VXNlcjc2NTI2MzE0',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/76526314?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/abetatos',
   'html_url': 'https: //github.com/abetatos',
   'followers_url': 'https: //api.github.com/users/abetatos/followers',
   'following_url': 'https: //api.github.com/users/abetatos/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/abetatos/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/abetatos/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/abetatos/subscriptions',
   'organizations_url': 'https: //api.github.com/users/abetatos/orgs',
   'repos_url': 'https: //api.github.com/users/abetatos/repos',
   'events_url': 'https: //api.github.com/users/abetatos/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/abetatos/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-05-16T13: 43: 29Z',
  'updated_at': '2024-05-20T17: 21: 30Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'body': 'This is related to: https: //github.com/explodinggradients/ragas/issues/681\r\n\r\n**Describe the bug**\r\nTestGeneration launches an error with default example of https://docs.ragas.io/en/stable/concepts/testset_generation.html with VertexAI models. \r\n\r\nRagas version: 0.1.7\r\nPython version: Python 3.10.13\r\n\r\n**Code to Reproduce**\r\n```python\r\ngenerator_llm = VertexAI(model_name="text-bison", temperature=0, response_validation=False)\r\ncritic_llm = VertexAI(model_name="gemini-pro", temperature=0, response_validation=False)\r\nvertexai_embeddings = VertexAIEmbeddings("textembedding-gecko@001")\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    vertexai_embeddings\r\n)\r\n\r\ndistributions = {\r\n    simple: 0.5,\r\n    multi_context: 0.4,\r\n    reasoning: 0.1\r\n}\r\n\r\nloader = PubMedLoader("liver", load_max_docs=10)\r\ndocuments = loader.load()\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, 10, distributions, with_debugging_logs=True) \r\ntestset.to_pandas()\r\n```\r\n**Error trace**\r\n\r\n```python\r\nFilename and doc_id are the same for all nodes.                                                                                                                        \r\nGenerating:   0%|                                                                                                                               | 0[/10](http://localhost:8889/10) [00:00<?, ?it[/s](http://localhost:8889/s)][ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 3, \'structure\': 3, \'relevance\': 3, \'score\': 3.0}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Hyperuricemia\', \'Protein peptides\', \'Anti-hyperuricemia properties\', \'Uric acid-lowering peptides\', \'Functional foods\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 3, \'structure\': 3, \'relevance\': 3, \'score\': 3.0}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Liver surgery\', \'Liver anatomy and physiology\', \'Liver resection\', \'Vascular control\', \'Liver transplantation\', \'Residual liver function\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 2, \'depth\': 2, \'structure\': 2, \'relevance\': 3, \'score\': 2.25}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Ammonia sensor\', \'Colorimetric optical readout\', \'Plasmonic Ag[/SiO](http://localhost:8889/SiO) nanoparticles\', \'Animal serum\', \'Paper-based sensor\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 1, \'depth\': 1, \'structure\': 1, \'relevance\': 1, \'score\': 1.0}\r\n[ragas.testset.evolutions.INFO] retrying evolution: 0 times\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 3, \'structure\': 3, \'relevance\': 3, \'score\': 3.0}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Liver surgery\', \'Liver anatomy and physiology\', \'Liver resection\', \'Vascular control\', \'Liver transplantation\', \'Residual liver function\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 3, \'structure\': 3, \'relevance\': 3, \'score\': 3.0}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Hyperuricemia\', \'Protein peptides\', \'Anti-hyperuricemia properties\', \'Uric acid-lowering peptides\', \'Functional foods\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 2, \'structure\': 3, \'relevance\': 3, \'score\': 2.75}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Metastatic breast cancer\', \'Age groups\', \'Metastatic patterns\', \'Survival outcomes\', \'Elderly patients\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 2, \'structure\': 3, \'relevance\': 3, \'score\': 2.75}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Metastatic breast cancer\', \'Age groups\', \'Metastatic patterns\', \'Survival outcomes\', \'Elderly patients\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 2, \'depth\': 2, \'structure\': 2, \'relevance\': 3, \'score\': 2.25}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Ammonia sensor\', \'Colorimetric optical readout\', \'Plasmonic Ag[/SiO](http://localhost:8889/SiO) nanoparticles\', \'Animal serum\', \'Paper-based sensor\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 2, \'structure\': 3, \'relevance\': 3, \'score\': 2.75}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Metastatic breast cancer\', \'Age groups\', \'Metastatic patterns\', \'Survival outcomes\', \'Elderly patients\']\r\n[ragas.testset.filters.DEBUG] context scoring: {\'clarity\': 3, \'depth\': 3, \'structure\': 3, \'relevance\': 3, \'score\': 3.0}\r\n[ragas.testset.evolutions.DEBUG] keyphrases in merged node: [\'Liver surgery\', \'Liver anatomy and physiology\', \'Liver resection\', \'Vascular control\', \'Liver transplantation\', \'Residual liver function\']\r\nGenerating:   0%|                                                                                                                               | 0[/10](http://localhost:8889/10) [05:20<?, ?it[/s](http://localhost:8889/s)]\r\n\r\nException in thread Thread-31:\r\nTraceback (most recent call last):\r\n  File "/Users/.../miniconda3/lib/python3.10/threading.py", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/executor.py", line 96, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/Users/.../venv/lib/python3.10/site-packages/nest_asyncio.py", line 98, in run_until_complete\r\n    return f.result()\r\n  File "/Users/.../miniconda3/lib/python3.10/asyncio/futures.py", line 201, in result\r\n    raise self._exception.with_traceback(self._exception_tb)\r\n  File "/Users/.../miniconda3/lib/python3.10/asyncio/tasks.py", line 232, in __step\r\n    result = coro.send(None)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/executor.py", line 84, in _aresults\r\n    raise e\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n  File "/Users/.../miniconda3/lib/python3.10/asyncio/tasks.py", line 571, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/Users/.../miniconda3/lib/python3.10/asyncio/futures.py", line 201, in result\r\n    raise self._exception.with_traceback(self._exception_tb)\r\n  File "/Users/.../miniconda3/lib/python3.10/asyncio/tasks.py", line 232, in __step\r\n    result = coro.send(None)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/testset/evolutions.py", line 142, in evolve\r\n    ) = await self._aevolve(current_tries, current_nodes)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/testset/evolutions.py", line 298, in _aevolve\r\n    results = await self.generator_llm.generate(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/llms/base.py", line 92, in generate\r\n    return await agenerate_text_with_retry(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 142, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 58, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 110, in iter\r\n    result = await action(retry_state)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 78, in inner\r\n    return fn(*args, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/__init__.py", line 410, in exc_check\r\n    raise retry_exc.reraise()\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/__init__.py", line 183, in reraise\r\n    raise self.last_attempt.result()\r\n  File "/Users/.../miniconda3/lib/python3.10/concurrent/futures/_base.py", line 451, in result\r\n    return self.__get_result()\r\n  File "/Users/.../miniconda3/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result\r\n    raise self._exception\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 61, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/ragas/llms/base.py", line 177, in agenerate_text\r\n    result = await self.langchain_llm.agenerate_prompt(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py", line 643, in agenerate_prompt\r\n    return await self.agenerate(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py", line 1018, in agenerate\r\n    output = await self._agenerate_helper(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py", line 882, in _agenerate_helper\r\n    raise e\r\n  File "/Users/.../venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py", line 866, in _agenerate_helper\r\n    await self._agenerate(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/langchain_google_vertexai/llms.py", line 413, in _agenerate\r\n    res = await _acompletion_with_retry(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/langchain_google_vertexai/llms.py", line 123, in _acompletion_with_retry\r\n    return await _acompletion_with_retry_inner(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 142, in async_wrapped\r\n    return await fn(*args, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 58, in __call__\r\n    do = await self.iter(retry_state=retry_state)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 110, in iter\r\n    result = await action(retry_state)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 78, in inner\r\n    return fn(*args, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/__init__.py", line 390, in <lambda>\r\n    self._add_action_func(lambda rs: rs.outcome.result())\r\n  File "/Users/.../miniconda3/lib/python3.10/concurrent/futures/_base.py", line 451, in result\r\n    return self.__get_result()\r\n  File "/Users/.../miniconda3/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result\r\n    raise self._exception\r\n  File "/Users/.../venv/lib/python3.10/site-packages/tenacity/_asyncio.py", line 61, in __call__\r\n    result = await fn(*args, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/langchain_google_vertexai/llms.py", line 121, in _acompletion_with_retry_inner\r\n    return await llm.client.predict_async(prompt, **kwargs)\r\n  File "/Users/.../venv/lib/python3.10/site-packages/vertexai/language_models/_language_models.py", line 1399, in predict_async\r\n    prediction_response = await self._endpoint.predict_async(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/google/cloud/aiplatform/models.py", line 1643, in predict_async\r\n    prediction_response = await self._prediction_async_client.predict(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/prediction_service/async_client.py", line 404, in predict\r\n    response = await rpc(\r\n  File "/Users/.../venv/lib/python3.10/site-packages/google/api_core/grpc_helpers_async.py", line 85, in __await__\r\n    response = yield from self._call.__await__()\r\n  File "/Users/.../venv/lib/python3.10/site-packages/grpc/aio/_call.py", line 299, in __await__\r\n    response = yield from self._call_response\r\n  File "/Users/.../miniconda3/lib/python3.10/asyncio/futures.py", line 285, in __await__\r\n    yield self  # This tells Task to wait for completion.\r\nRuntimeError: Task <Task pending name=\'Task-78\' coro=<as_completed.<locals>.sema_coro() running at /Users/.../venv/lib/python3.10/site-packages/ragas/executor.py:38> cb=[as_completed.<locals>._on_completion() at /Users/.../miniconda3/lib/python3.10/asyncio/tasks.py:558]> got Future <Task pending name=\'Task-795\' coro=<UnaryUnaryCall._invoke() running at /Users/.../venv/lib/python3.10/site-packages/grpc/aio/_call.py:568>> attached to a different loop\r\n\r\n```\r\n\r\nIf you need any additional info please let me know!\r\nThank you very much. ',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/963/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/963/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/962',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/962/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/962/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/962/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/962',
  'id': 2300004053,
  'node_id': 'I_kwDOJgX1Gs6JF0bV',
  'number': 962,
  'title': 'embedding nodes: 0%|       Segmentation fault (core dumped)',
  'user': {'login': 'WGS-note',
   'id': 58907127,
   'node_id': 'MDQ6VXNlcjU4OTA3MTI3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/58907127?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/WGS-note',
   'html_url': 'https: //github.com/WGS-note',
   'followers_url': 'https: //api.github.com/users/WGS-note/followers',
   'following_url': 'https: //api.github.com/users/WGS-note/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/WGS-note/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/WGS-note/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/WGS-note/subscriptions',
   'organizations_url': 'https: //api.github.com/users/WGS-note/orgs',
   'repos_url': 'https: //api.github.com/users/WGS-note/repos',
   'events_url': 'https: //api.github.com/users/WGS-note/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/WGS-note/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-16T10: 26: 08Z',
  'updated_at': '2024-06-01T10: 42: 08Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'hi，my code is as follows:\r\n\r\n```python\r\ndevice = "cuda:2"\r\n\r\nloader = DirectoryLoader("./knowledge_base/DT_test/content")\r\ndocuments = loader.load()\r\n\r\nfor document in documents:\r\n    document.metadata[\'filename\'
            ] = document.metadata[\'source\'
            ]\r\n\r\npipe = pipeline(\r\n    "text-generation",\r\n    model=AutoModelForCausalLM.from_pretrained("/home/models/chatglm3-6b", trust_remote_code=True),\r\n    tokenizer=AutoTokenizer.from_pretrained("/home/models/chatglm3-6b", trust_remote_code=True),\r\n    device=device\r\n)\r\ngenerator_llm = HuggingFacePipeline(pipeline=pipe)\r\n\r\nembeddings = HuggingFaceBgeEmbeddings(\r\n    model_name="/home/models/bge-large-zh",\r\n    model_kwargs={\'device\': device
            },\r\n    encode_kwargs={\'normalize_embeddings\': True
            },\r\n)\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm=generator_llm,\r\n    critic_llm=generator_llm,\r\n    embeddings=embeddings\r\n)\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=3,\r\n                                                distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25
            },\r\n                                                is_async=False)\r\n\r\nprint(testset.to_pandas())\r\n```\r\n\r\n\r\nI am getting the following error：\r\n\r\n```shell\r\nembedding nodes: 0%|                                                                                                                                          | 0/28 [
                  00: 00<?, ?it/s
            ]\r\n\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nmay I ask what this is all about?\r\n\r\nextremely grateful！\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/962/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/962/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/960',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/960/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/960/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/960/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/960',
  'id': 2299551619,
  'node_id': 'I_kwDOJgX1Gs6JEF-D',
  'number': 960,
  'title': "AttributeError: 'PhiForCausalLM' object has no attribute 'generate_prompt'",
  'user': {'login': 'TheDominus',
   'id': 21247346,
   'node_id': 'MDQ6VXNlcjIxMjQ3MzQ2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/21247346?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/TheDominus',
   'html_url': 'https: //github.com/TheDominus',
   'followers_url': 'https: //api.github.com/users/TheDominus/followers',
   'following_url': 'https: //api.github.com/users/TheDominus/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/TheDominus/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/TheDominus/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/TheDominus/subscriptions',
   'organizations_url': 'https: //api.github.com/users/TheDominus/orgs',
   'repos_url': 'https: //api.github.com/users/TheDominus/repos',
   'events_url': 'https: //api.github.com/users/TheDominus/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/TheDominus/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-05-16T07: 16: 43Z',
  'updated_at': '2024-06-01T14: 05: 19Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nAttributeError: \'PhiForCausalLM\' object has no attribute \'generate_prompt\'. Same thing is happening for multiple other LLM Models.\r\n\r\nRagas version: 0.1.7\r\nPython version: 3.10\r\n\r\n**Code to Reproduce**\r\n```\r\nfrom langchain_core.language_models import BaseLanguageModel\r\nfrom langchain_core.embeddings import Embeddings\r\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\r\nimport torch\r\nfrom datasets import Dataset\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import faithfulness, answer_correctness\r\nfrom ragas.llms import LangchainLLMWrapper\r\nfrom ragas.embeddings import LangchainEmbeddingsWrapper\r\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\r\n\r\nprint("evaluator")\r\nmodel_id = "microsoft/phi-2"\r\naccess_token = "hf_yourToken"\r\n\r\nquantization_config = BitsAndBytesConfig(\r\n            load_in_4bit=True,a\r\n            bnb_4bit_use_double_quant=True,\r\n            bnb_4bit_quant_type="nf4",\r\n            bnb_4bit_compute_dtype="bfloat16",\r\n        )\r\n\r\ntokenizer = AutoTokenizer.from_pretrained(model_id, token=access_token)\r\nmodel = AutoModelForCausalLM.from_pretrained(\r\n    model_id,\r\n    quantization_config=quantization_config,\r\n    token=access_token\r\n)\r\n\r\nprint("hello")\r\nlangchain_llm = LangchainLLMWrapper(model)\r\nlangchain_embeddings = HuggingFaceEmbeddings(model_name=model_id)\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n    \'contexts\' : [[\'The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\']],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n}\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nresults = evaluate(dataset,metrics=[faithfulness,answer_correctness],llm=langchain_llm, embeddings=langchain_embeddings)\r\nprint("evaluation is done")\r\nprint(results)\r\n```\r\n\r\n\r\n**Error trace**\r\n```\r\nFile "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/threading.py", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/executor.py", line 96, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete\r\n    return future.result()\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/executor.py", line 84, in _aresults\r\n    raise e\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/asyncio/tasks.py", line 571, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/metrics/base.py", line 116, in ascore\r\n    raise e\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/metrics/base.py", line 112, in ascore\r\n    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/metrics/_answer_relevance.py", line 152, in _ascore\r\n    result = await self.llm.generate(\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/llms/base.py", line 110, in generate\r\n    return await loop.run_in_executor(None, generate_text)\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/concurrent/futures/thread.py", line 58, in run\r\n    result = self.fn(*self.args, **self.kwargs)\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tenacity/__init__.py", line 289, in wrapped_f\r\n    return self(f, *args, **kw)\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tenacity/__init__.py", line 379, in __call__\r\n    do = self.iter(retry_state=retry_state)\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tenacity/__init__.py", line 325, in iter\r\n    raise retry_exc.reraise()\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tenacity/__init__.py", line 158, in reraise\r\n    raise self.last_attempt.result()\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/concurrent/futures/_base.py", line 451, in result\r\n    return self.__get_result()\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result\r\n    raise self._exception\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/tenacity/__init__.py", line 382, in __call__\r\n    result = fn(*args, **kwargs)\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/ragas/llms/base.py", line 147, in generate_text\r\n    result = self.langchain_llm.generate_prompt(\r\n  File "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__\r\n    raise AttributeError(f"\'{type(self).__name__}\' object has no attribute \'{name}\'")\r\nAttributeError: \'GemmaForCausalLM\' object has no attribute \'generate_prompt\'\r\n```\r\n\r\n**Expected behavior**\r\nit should print the results of the evaluation\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/960/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/960/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/958',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/958/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/958/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/958/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/958',
  'id': 2297904432,
  'node_id': 'PR_kwDOJgX1Gs5viE1K',
  'number': 958,
  'title': 'fix - typo & prompt',
  'user': {'login': 'omkar-334',
   'id': 40126336,
   'node_id': 'MDQ6VXNlcjQwMTI2MzM2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/40126336?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/omkar-334',
   'html_url': 'https: //github.com/omkar-334',
   'followers_url': 'https: //api.github.com/users/omkar-334/followers',
   'following_url': 'https: //api.github.com/users/omkar-334/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/omkar-334/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/omkar-334/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/omkar-334/subscriptions',
   'organizations_url': 'https: //api.github.com/users/omkar-334/orgs',
   'repos_url': 'https: //api.github.com/users/omkar-334/repos',
   'events_url': 'https: //api.github.com/users/omkar-334/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/omkar-334/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-15T13: 22: 00Z',
  'updated_at': '2024-05-15T13: 29: 36Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/958',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/958',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/958.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/958.patch',
   'merged_at': None
            },
  'body': '1. Function typo \r\nOriginal name - set_node_relataionships()\r\nFixed name - set_node_relationships()\r\n\r\n2. In the seed_question_prompt, a keyphrase is given.   \r\nBut in the instruction, it is mentioned that `The question should be formed using topic`.   \r\n![image
            ](https: //github.com/explodinggradients/ragas/assets/40126336/a69c4b29-8c57-4e6d-a959-2bf163178cb2)  \r\n`The question should be formed using the given keyphrase.` would be better',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/958/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/958/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/957',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/957/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/957/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/957/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/957',
  'id': 2297819555,
  'node_id': 'I_kwDOJgX1Gs6I9fGj',
  'number': 957,
  'title': 'Random RuntimeError: Tool context error detected. This can occur due to parallelization in VertexAI',
  'user': {'login': 'franck-cussac',
   'id': 16152598,
   'node_id': 'MDQ6VXNlcjE2MTUyNTk4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/16152598?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/franck-cussac',
   'html_url': 'https: //github.com/franck-cussac',
   'followers_url': 'https: //api.github.com/users/franck-cussac/followers',
   'following_url': 'https: //api.github.com/users/franck-cussac/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/franck-cussac/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/franck-cussac/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/franck-cussac/subscriptions',
   'organizations_url': 'https: //api.github.com/users/franck-cussac/orgs',
   'repos_url': 'https: //api.github.com/users/franck-cussac/repos',
   'events_url': 'https: //api.github.com/users/franck-cussac/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/franck-cussac/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-05-15T12: 47: 26Z',
  'updated_at': '2024-07-23T14: 11: 12Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '- [x
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nI run evaluation, sometimes it works sometimes it fails with :\r\n`RuntimeError: Tool context error detected. This can occur due to parallelization`\r\n\r\nRagas version: 0.1.7\r\nPython version: 3.10.12\r\n\r\n**Code to Reproduce**\r\n```python\r\ndef evaluation(answers: Dataset) -> pd.DataFrame:\r\nvertextai_llm = ChatVertexAI(\r\nmodel_name=MODEL_GEMINI,\r\n)\r\nvertextai_embeddings = VertexAIEmbeddings(\r\nmodel_name=MODEL_EMBEDDING,\r\n)\r\n\r\nreturn evaluate(\r\nanswers,\r\nmetrics=[\r\nfaithfulness,\r\nanswer_relevancy,\r\ncontext_recall,\r\ncontext_precision,\r\nharmfulness,\r\nanswer_similarity,\r\nanswer_correctness,\r\n],\r\nllm=vertextai_llm,\r\nembeddings=vertextai_embeddings,\r\n).to_pandas()\r\n```\r\n\r\n**Error trace**\r\n\r\n```\r\nEvaluating:   3%|████▊                                                                                                                                                                      | 1/36 [00:03<02:02,  3.49s/it]\r\nException in thread Thread-12:\r\nTraceback (most recent call last):\r\nFile "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner\r\nself.run()\r\nFile "/lib/python3.10/site-packages/ragas/executor.py", line 96, in run\r\nresults = self.loop.run_until_complete(self._aresults())\r\nFile "/usr/lib/python3.10/asyncio/base_events.py", line 649, in run_until_complete\r\nreturn future.result()\r\nFile "/lib/python3.10/site-packages/ragas/executor.py", line 84, in _aresults\r\nraise e\r\nFile "/lib/python3.10/site-packages/ragas/executor.py", line 79, in _aresults\r\nr = await future\r\nFile "/usr/lib/python3.10/asyncio/tasks.py", line 571, in _wait_for_one\r\nreturn f.result()  # May raise f.exception().\r\nFile "/lib/python3.10/site-packages/ragas/executor.py", line 38, in sema_coro\r\nreturn await coro\r\nFile "/home/lib/python3.10/site-packages/ragas/executor.py", line 112, in wrapped_callable_async\r\nreturn counter, await callable(*args, **kwargs)\r\nFile "/lib/python3.10/site-packages/ragas/metrics/base.py", line 116, in ascore\r\nraise e\r\nFile "/lib/python3.10/site-packages/ragas/metrics/base.py", line 112, in ascore\r\nscore = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\r\nFile "/lib/python3.10/site-packages/ragas/metrics/_answer_relevance.py", line 167, in _ascore\r\nreturn self._calculate_score(answers, row)\r\nFile "/lib/python3.10/site-packages/ragas/metrics/_answer_relevance.py", line 139, in _calculate_score\r\ncosine_sim = self.calculate_similarity(question, gen_questions)\r\nFile "/lib/python3.10/site-packages/ragas/metrics/_answer_relevance.py", line 115, in calculate_similarity\r\nself.embeddings.embed_documents(generated_questions)\r\nFile "/lib/python3.10/site-packages/ragas/embeddings/base.py", line 58, in embed_documents\r\nreturn self.embeddings.embed_documents(texts)\r\nFile "/lib/python3.10/site-packages/langchain_google_vertexai/embeddings.py", line 379, in embed_documents\r\nreturn self.embed(texts, batch_size, "RETRIEVAL_DOCUMENT")\r\nFile "/lib/python3.10/site-packages/langchain_google_vertexai/embeddings.py", line 362, in embed\r\nembeddings.extend(t.result())\r\nFile "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result\r\nreturn self.__get_result()\r\nFile "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result\r\nraise self._exception\r\nFile "/usr/lib/python3.10/concurrent/futures/thread.py", line 58, in run\r\nresult = self.fn(*self.args, **self.kwargs)\r\nFile "/lib/python3.10/site-packages/langchain_google_vertexai/embeddings.py", line 193, in _get_embeddings_with_retry\r\nwith telemetry.tool_context_manager(self._user_agent):\r\nFile "/usr/lib/python3.10/contextlib.py", line 142, in __exit__\r\nnext(self.gen)\r\nFile "/lib/python3.10/site-packages/google/cloud/aiplatform/telemetry.py", line 48, in tool_context_manager\r\n_pop_tool_name(tool_name)\r\nFile "/lib/python3.10/site-packages/google/cloud/aiplatform/telemetry.py", line 57, in _pop_tool_name\r\nraise RuntimeError(\r\nRuntimeError: Tool context error detected. This can occur due to parallelization.\r\nTraceback (most recent call last):\r\nFile "<string>", line 1, in <module>\r\nFile "/src/evaluation/main.py", line 47, in main\r\ndf = evaluation(dataset)\r\nFile "/src/evaluation/main.py", line 59, in evaluation\r\nreturn evaluate(\r\nFile "/lib/python3.10/site-packages/ragas/evaluation.py", line 231, in evaluate\r\nraise e\r\nFile "/lib/python3.10/site-packages/ragas/evaluation.py", line 213, in evaluate\r\nraise ExceptionInRunner()\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\r\nsys:1: RuntimeWarning: coroutine \'Executor.wrap_callable_with_index.<locals>.wrapped_callable_async\' was never awaited\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-4\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-2\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-21\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-18\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-12\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-10\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-9\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-8\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-7\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-5\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-3\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-19\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-17\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-13\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-11\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-20\' coro=<as_completed.<locals>.sema_coro() running at /lib/python3.10/site-packages/ragas/executor.py:38> wait_for=<Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.10/asyncio/futures.py:385, Task.task_wakeup()]> cb=[as_completed.<locals>._on_completion() at /usr/lib/python3.10/asyncio/tasks.py:558]>\r\n```\r\n\r\n**Expected behavior**\r\nAn evaluation working 100% of time\r\n\r\n\r\n**Additional context**\r\nI\'m using vertex AI and I follow the given notebook in example.\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/957/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/957/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/955',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/955/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/955/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/955/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/955',
  'id': 2296807381,
  'node_id': 'I_kwDOJgX1Gs6I5n_V',
  'number': 955,
  'title': '[R-254
            ] Issue in Evaluation using local LLM',
  'user': {'login': 'sheetalkamthe55',
   'id': 119347732,
   'node_id': 'U_kgDOBx0aFA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/119347732?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/sheetalkamthe55',
   'html_url': 'https: //github.com/sheetalkamthe55',
   'followers_url': 'https: //api.github.com/users/sheetalkamthe55/followers',
   'following_url': 'https: //api.github.com/users/sheetalkamthe55/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/sheetalkamthe55/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/sheetalkamthe55/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/sheetalkamthe55/subscriptions',
   'organizations_url': 'https: //api.github.com/users/sheetalkamthe55/orgs',
   'repos_url': 'https: //api.github.com/users/sheetalkamthe55/repos',
   'events_url': 'https: //api.github.com/users/sheetalkamthe55/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/sheetalkamthe55/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  },
                  {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-05-15T03: 55: 24Z',
  'updated_at': '2024-06-15T02: 23: 26Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\n**Your Question**\r\n\r\n> “WARNING:ragas.llms.output_parser:Failed to parse output. Returning None.”\r\n\r\nI tried including the trace using Langsmith to check for requests and responses. For the given input prompt I believe it is an issue of context length because I get a blank response. I tried different LLMs but the error remains the same.\r\n\r\n**Code Examples**\r\nHosted LLama 2 model with LLamaCPP. Below is the command I used\r\n`python3 -m llama_cpp.server --model /tmp/llama_index/models/llama-13b.Q5_K_M.gguf --port 8009 --host 129.69.217.24 --chat_format llama-2`\r\n \r\nFollowing is a sample testset I am using,\r\n[Ragas_dataset.csv](https://github.com/explodinggradients/ragas/files/15315918/Ragas_dataset.csv)\r\n\r\nCan ignore the dataset part, I tried the same with \r\n`fiqa_eval = load_dataset("explodinggradients/fiqa", "ragas_eval")`\r\nbut same issue persists.\r\n\r\nCode:\r\n```\r\nfrom datasets import load_dataset\r\ndataset = load_dataset("csv", data_files="Ragas_dataset.csv")\r\n\r\nfrom tqdm import tqdm\r\nimport pandas as pd\r\nfrom datasets import Dataset\r\ndef create_ragas_dataset( eval_dataset):\r\n  rag_dataset = []\r\n  for row in tqdm(eval_dataset):\r\n    rag_dataset.append(\r\n        {"question" : row["question"],\r\n         # "answer" : result["answer"],\r\n         "answer" : row["ground_truth"],\r\n         "contexts" : [row["contexts"]],\r\n         "ground_truth" : row["ground_truth"]\r\n         }\r\n    )\r\n  rag_df = pd.DataFrame(rag_dataset)\r\n  rag_eval_dataset = Dataset.from_pandas(rag_df)\r\n  return rag_eval_dataset\r\n\r\nbasic_qa_ragas_dataset = create_ragas_dataset(dataset["train"].select(range(2)))\r\n\r\nfrom langchain.chat_models import ChatOpenAI\r\nfrom ragas.llms import LangchainLLMWrapper\r\n\r\ninference_server_url = "http://localhost:8009/v1"\r\n\r\nchat = ChatOpenAI(\r\n    model="/tmp/llama_index/models/llama-13b.Q5_K_M.gguf",\r\n    openai_api_key="no-key",\r\n    openai_api_base=inference_server_url,\r\n    max_tokens=5,\r\n    temperature=0,\r\n)\r\n\r\nvllm = LangchainLLMWrapper(chat)\r\n\r\nfrom ragas.metrics import (\r\n    context_precision,\r\n    faithfulness,\r\n    context_recall,\r\n)\r\nfrom ragas.metrics.critique import harmfulness\r\n\r\n# change the LLM\r\n\r\nfaithfulness.llm = vllm\r\ncontext_precision.llm = vllm\r\ncontext_recall.llm = vllm\r\nharmfulness.llm = vllm\r\n\r\nfrom ragas import evaluate\r\n\r\nresult = evaluate(\r\n    basic_qa_ragas_dataset, \r\n    metrics=[faithfulness]\r\n)\r\nresult\r\n```\r\n<img width="1029" alt="image" src="https://github.com/explodinggradients/ragas/assets/119347732/57bbba2c-0e8c-478e-9207-f517f5e7078d">\r\n\r\n\r\n**Additional context**\r\nPlease let me know if I should provide more information\r\n\n\n<sub>[R-254](https://linear.app/exploding-gradients/issue/R-254/issue-in-evaluation-using-local-llm)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/955/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/955/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/948',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/948/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/948/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/948/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/948',
  'id': 2292655792,
  'node_id': 'PR_kwDOJgX1Gs5vQAQ7',
  'number': 948,
  'title': 'feat: Add support for LangchainLLMWrapper in adaptation.py',
  'user': {'login': 'egortolmachev',
   'id': 150433814,
   'node_id': 'U_kgDOCPdwFg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/150433814?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/egortolmachev',
   'html_url': 'https: //github.com/egortolmachev',
   'followers_url': 'https: //api.github.com/users/egortolmachev/followers',
   'following_url': 'https: //api.github.com/users/egortolmachev/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/egortolmachev/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/egortolmachev/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/egortolmachev/subscriptions',
   'organizations_url': 'https: //api.github.com/users/egortolmachev/orgs',
   'repos_url': 'https: //api.github.com/users/egortolmachev/repos',
   'events_url': 'https: //api.github.com/users/egortolmachev/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/egortolmachev/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6972745904,
    'node_id': 'LA_kwDOJgX1Gs8AAAABn5uosA',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/size:XS',
    'name': 'size:XS',
    'color': '00ff00',
    'default': False,
    'description': 'This PR changes 0-9 lines, ignoring generated files.'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-05-13T12: 15: 54Z',
  'updated_at': '2024-05-29T13: 08: 02Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/948',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/948',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/948.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/948.patch',
   'merged_at': None
            },
  'body': None,
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/948/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/948/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/945',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/945/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/945/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/945/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/945',
  'id': 2289302805,
  'node_id': 'I_kwDOJgX1Gs6Ic_0V',
  'number': 945,
  'title': '[R-290
            ] Failed to parse output. Returning None.  - SimpleEvolution - TestsetGenerator',
  'user': {'login': 'JPonsa',
   'id': 28976175,
   'node_id': 'MDQ6VXNlcjI4OTc2MTc1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/28976175?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/JPonsa',
   'html_url': 'https: //github.com/JPonsa',
   'followers_url': 'https: //api.github.com/users/JPonsa/followers',
   'following_url': 'https: //api.github.com/users/JPonsa/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/JPonsa/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/JPonsa/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/JPonsa/subscriptions',
   'organizations_url': 'https: //api.github.com/users/JPonsa/orgs',
   'repos_url': 'https: //api.github.com/users/JPonsa/repos',
   'events_url': 'https: //api.github.com/users/JPonsa/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/JPonsa/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'assignees': [
                  {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  }
            ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                  ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                  },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
            },
  'comments': 11,
  'created_at': '2024-05-10T08: 53: 18Z',
  'updated_at': '2024-09-02T07: 06: 46Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I am getting an “Failed to parse output. Returning None” error. I I have tried llama3 and mistral8x7b. I believe both models should be able to generate json like outputs.\r\n\r\nI need advice on how to solve this.\r\n\r\nThis could be related to https: //github.com/explodinggradients/ragas/issues/859\r\n\r\n```python\r\n       \r\n    splitter = RecursiveJsonSplitter(max_chunk_size=2_000)\r\n    docs = splitter.create_documents(texts=studies)\r\n\r\n    generator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embeddings)\r\n    \r\n      eval_ds = generator.generate_with_langchain_docs(\r\n        docs,\r\n        test_size=50,\r\n        distributions={\r\n            simple: 0.4,\r\n            reasoning: 0.4,\r\n            multi_context: 0.2,\r\n        },\r\n        raise_exceptions=True,\r\n        is_async=True # as per https://github.com/explodinggradients/ragas/issues/709\r\n    )\r\n    eval_ds.to_pandas().to_csv(args.output)\r\n```\r\nError:\r\nNote: I had to trim the SimpleEvolution message as it was reporting the content of many documents and their embedding. \r\n```\r\nFailed to parse output. Returning None.\r\nFailed to parse output. Returning None.\r\nmax retries exceeded for SimpleEvolution(generator_llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class \'Exception\'>)), docstore=InMemoryDocumentStore(splitter=<langchain_text_splitters.base.TokenTextSplitter object at 0x2b813d22f410>, nodes=[Node(page_content="NCT00000173: protocolSection: identificationModule: nctId: NCT00000173, organization: fullName: National Institute on Aging (NIA), class: NIH, briefTitle: Memory Impairment Study (Mild Cognitive Impairment Study), officialTitle: A Randomized, Double-Blind, Placebo-Controlled Trial of Vitamin E and Donepezil HCL (Aricept) to Delay Clinical Progression From Mild Cognitive Impairment (MCI) to Alzheimer\'s Disease (AD), statusModule: overallStatus: COMPLETED, sponsorCollaboratorsModule: leadSponsor: name: National Institute on Aging (NIA), class: NIH, descriptionModule: briefSummary: The National Institute on Aging (NIA) is launching a nationwide treatment study targeting individuals with mild cognitive impairment (MCI), a condition characterized by a memory deficit, but not dementia. An NIA-funded study recently confirmed that MCI is different from both dementia and normal age-related changes in memory. Accurate and early evaluation and treatment of MCI individuals might prevent further cognitive decline, including development of Alzheimer\'s disease (AD). The Memory Impairment Study is the first such AD prevention clinical trial carried out by NIH, and will be conducted at 65-80 medical research institutions located in the United States and Canada. This study will test the usefulness of two drugs to slow or stop the conversion from MCI to AD. The trial will evaluate placebo, vitamin E, and donepezil, an investigational agent approved by the Food and Drug Administration for another use. Vitamin E (alpha-tocopherol) is thought to have antioxidant properties, and was shown in a 1997 study to delay important dementia milestones, such as patients\' institutionalization or progression to severe dementia, by about seven months.", metadata={\'filename\': \'NCT00000173\'}, doc_id=\'4a458ce7-7dd9-41c2-98f4-ddc032b683b7\'), Node(page_content="NCT00000173: protocolSection: conditionsModule: conditions: Alzheimer Disease; keywords: Mild cognitive impairment, Alzheimer\'s disease, Memory, Donepezil, Vitamin E, Antioxidants, Cholinergic agents, Cholinesterase inhibitors; designModule: studyType: INTERVENTIONAL, phases: PHASE3; designInfo: allocation: RANDOMIZED, interventionModel: PARALLEL, primaryPurpose: TREATMENT, maskingInfo: , armsInterventionsModule: interventions: type: DRUG, name: Donepezil, type: DRUG, name: Vitamin E; eligibilityModule: eligibilityCriteria: Inclusion Criteria: * Memory complaints and memory difficulties which are verified by an informant. * Abnormal memory function documented by scoring below the education adjusted cutoff on the Logical Memory II subscale (Delayed Paragraph Recall) from the Wechsler Memory Scale - Revised (the maximum score is 25): a) less than or equal to 8 for 16 or more years of education, b) less than or equal to 4 for 8-15 years of education, c) less than or equal to 2 for 0-7 years of education. * Mini-Mental Exam score between 24 and 30 (inclusive) (Exceptions may be made for subjects with less than 8 years of education at the discretion of the project director.). * Clinical Dementia Rating = 0.5. Memory Box score must be at least 0.5. * General cognition and functional performance sufficiently preserved such that a diagnosis of Alzheimer\'s disease cannot be made by the site physician at the time of the screening visit. * No significant cerebrovascular disease: Modified Hachinski score of less than or equal to 4. * Age between 55 and 90 (inclusive). * Permitted medications stable for at least 1 month prior to screening. In particular: a) Subjects may take stable doses of antidepressants lacking significant anticholinergic side effects (if they are not currently depressed and do not have a history of major depression within the past 2 years). b) Estrogen replacement therapy is permissible. c) Ginkgo biloba is permissible, but discouraged. * Hamilton Depression rating scale score of less than or equal to 12 on the 17-item scale. * Informant is available who has frequent contact with the subject (e.g. an average of 10 hours per week or more), agrees to monitor administration of study drug, observe for adverse events, and accompany the subject to all clinic visits for the duration of the protocol. * CT or MRI scans within 12 months prior to screening without evidence of infection, infarction, or other focal lesions and without clinical symptoms suggestive of intervening neurological disease. A lacune in a non-critical brain area which is not believed to contribute to the subject\'s cognitive impairment is permissible. * Adequate visual and auditory acuity to allow neuropsychological testing. * Good general health with no additional diseases expected to interfere with the study. * Normal B12, RPR, and Thyroid Function Tests or without any clinically significant abnormalities that would be expected to interfere with the study. * ECG without clinically significant abnormalities that would be expected to interfere with the study. * Subject is not pregnant, lactating, or of childbearing potential (i.e. women must be two years post-menopausal or surgically sterile). * Agreement not to take other vitamin supplements (including Vitamin E), multivitamins, other than those provided by the study. Exclusion Criteria: * Any significant neurologic disease other than suspected incipient Alzheimer\'s disease, such as Parkinson\'s disease, multi-infarct dementia, Huntington\'s disease, normal pressure hydrocephalus, brain tumor, progressive supranuclear palsy, seizure disorder, subdural hematoma, multiple sclerosis, or history of significant head trauma followed by persistent neurologic defaults or known structural brain abnormalities. * Major depression or another major psychiatric disorder as described in DSM IV within the past 2 years. * Psychotic features, agitation or behavioral problems within the last 3 months which could lead to difficulty complying with the protocol. * History of alcohol or substance abuse or dependence within the past 2 years (DSM IV criteria). * History of schizophrenia (DSM IV criteria). * Any significant systemic illness or unstable medical condition which could lead to difficulty complying with the protocol including: a) History of systemic cancer within the last 5 years (non-metastatic skin cancers are acceptable). b) History of myocardial infarction within the past year or unstable or severe cardiovascular disease including angina or CHF with symptoms at rest. c) Clinically significant obstructive pulmonary disease or asthma. d) Clinically significant and unstable gastrointestinal disorder such as ulcer disease or a history of active or occult gastrointestinal bleeding within two years. e) Clinically significant laboratory test abnormalities on the battery of screening tests (hematology, prothrombin time, chemistry, urinalysis, ECG). f) Insulin", metadata={\'filename\': \'NCT00000173\'}, doc_id=\'6de53b72-0e35-4864-8a27-f3524bbe6a90\', wins=2), [ mode documents]..., metadata={\'filename\': \'NCT00000938\'}, doc_id=\'fa58d93c-8e58-4898-93de-59402c15503e\')], node_embeddings_list=[[-0.034423138946294785, , 0.01802566833794117]], node_map={\'4a458ce7-7dd9-41c2-98f4-ddc032b683b7\': \r\n\r\n[...]\r\n\r\nnode_filter=NodeFilter(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class \'Exception\'>)), threshold=1.5, context_scoring_prompt=Prompt(name=\'score_context\', instruction=\'\\n    Given a context, perform the following task and output the answer in VALID JSON format: Assess the provided context and assign a numerical score of 1 (Low), 2 (Medium), or 3 (High) for each of the following criteria in your JSON response:\\n\\nclarity: Evaluate the precision and understandability of the information presented. High scores (3) are reserved for contexts that are both precise in their information and easy to understand. Low scores (1) are for contexts where the information is vague or hard to comprehend.\\ndepth: Determine the level of detailed examination and the inclusion of innovative insights within the context. A high score indicates a comprehensive and insightful analysis, while a low score suggests a superficial treatment of the topic.\\nstructure: Assess how well the content is organized and whether it flows logically. High scores are awarded to contexts that demonstrate coherent organization and logical progression, whereas low scores indicate a lack of structure or clarity in progression.\\nrelevance: Judge the pertinence of the content to the main topic, awarding high scores to contexts tightly focused on the subject without unnecessary digressions, and low scores to those that are cluttered with irrelevant information.\\nStructure your JSON output to reflect these criteria as keys with their corresponding scores as values\\n    \', output_format_instruction=\'The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{"type": "object", "properties": {"clarity": {"title": "Clarity", "type": "integer"}, "depth": {"title": "Depth", "type": "integer"}, "structure": {"title": "Structure", "type": "integer"}, "relevance": {"title": "Relevance", "type": "integer"}}, "required": ["clarity", "depth", "structure", "relevance"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).\', examples=[{\'context\': \'The Pythagorean theorem is a fundamental principle in geometry. It states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides. This can be written as a^2 + b^2 = c^2 where c represents the length of the hypotenuse, and a and b represent the lengths of the other two sides.\', \'output\': {\'clarity\': 3, \'depth\': 1, \'structure\': 3, \'relevance\': 3}}, {\'context\': \'Albert Einstein (14 March 1879 - 18 April 1955) was a German-born theoretical physicist who is widely held to be one of the greatest and most influential scientists of all time.\', \'output\': {\'clarity\': 3, \'depth\': 2, \'structure\': 3, \'relevance\': 3}}, {\'context\': "I love chocolate. It\'s really tasty. Oh, and by the way, the earth orbits the sun, not the other way around. Also, my favorite color is blue.", \'output\': {\'clarity\': 2, \'depth\': 1, \'structure\': 1, \'relevance\': 1}}], input_keys=[\'context\'], output_key=\'output\', output_type=\'json\', language=\'english\')), question_filter=QuestionFilter(llm=LangchainLLMWrapper(run_config=RunConfig(timeout=60, max_retries=15, max_wait=90, max_workers=16, exception_types=<class \'Exception\'>)), filter_question_prompt=Prompt(name=\'filter_question\', instruction=\'\\nAsses the given question for clarity and answerability given enough domain knowledge, consider the following criteria:\\n1.Independence: Can the question be understood and answered without needing additional context or access to external references not provided within the question itself? Questions should be self-contained, meaning they do not rely on specific documents, tables, or prior knowledge not shared within the question.\\n2.Clear Intent: Is it clear what type of answer or information the question seeks? The question should convey its purpose without ambiguity, allowing for a direct and relevant response.\\nBased on these criteria, assign a verdict of "1" if a question is specific, independent, and has a clear intent, making it understandable and answerable based on the details provided. Assign "0" if it fails to meet one or more of these criteria due to vagueness, reliance on external references, or ambiguity in intent.\\nProvide feedback and a verdict in JSON format, including suggestions for improvement if the question is deemed unclear. Highlight aspects of the question that contribute to its clarity or lack thereof, and offer advice on how it could be reframed or detailed for better understanding and answerability.\\n\', output_format_instruction=\'The output should be a well-formatted JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {"properties": {"foo": {"title": "Foo", "description": "a list of strings", "type": "array", "items": {"type": "string"}}}, "required": ["foo"]}\\nthe object {"foo": ["bar", "baz"]} is a well-formatted instance of the schema. The object {"properties": {"foo": ["bar", "baz"]}} is not well-formatted.\\n\\nHere is the output JSON schema:\\n```\\n{"type": "object", "properties": {"feedback": {"title": "Feedback", "type": "string"}, "verdict": {"title": "Verdict", "type": "integer"}}, "required": ["feedback", "verdict"]}\\n```\\n\\nDo not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).\', examples=[{\'question\': \'What is the discovery about space?\', \'output\': {\'feedback\': "The question is too vague and broad, asking for a \'discovery about space\' without specifying any particular aspect, time frame, or context of interest. This could refer to a wide range of topics, from the discovery of new celestial bodies to advancements in space travel technology. To improve clarity and answerability, the question could specify the type of discovery (e.g., astronomical, technological), the time frame (e.g., recent, historical), or the context (e.g., within a specific research study or space mission).", \'verdict\': 0}}, {\'question\': "How does ALMA-13B-R perform compared to other translation models in the WMT\'23 study, based on the results in context1 and context2?", \'output\': {\'feedback\': "This question asks for a comparison of the ALMA-13B-R model\'s performance against other translation models within the WMT\'23 study, specifically referring to results in \'context1\' and \'context2\'. While it clearly specifies the model of interest (ALMA-13B-R) and the study (WMT\'23), it assumes access to and understanding of \'context1\' and \'context2\' without explaining what these contexts entail. This makes the question unclear for those not familiar with the WMT\'23 study or these specific contexts. To improve clarity and answerability for a broader audience, the question could benefit from defining or describing \'context1\' and \'context2\' or explaining the criteria used for comparison in these contexts.", \'verdict\': 0}}, {\'question\': \'How do KIWI-XXL and XCOMET compare to the gold standard references in Table 1 in terms of evaluation scores, translation model performance, and success rate in surpassing the references?\', \'output\': {\'feedback\': "The question requests a comparison between KIWI-XXL and XCOMET models and gold standard references in \'Table 1\', focusing on evaluation scores, translation model performance, and success rates in surpassing the references. It specifies the models and criteria for comparison, making the intent clear. However, the question assumes access to \'Table 1\' without providing its content or context, making it unclear for those without direct access to the source material. To be clearer and more answerable for a general audience, the question could include a brief description of the content or key findings of \'Table 1\', or alternatively, frame the question in a way that does not rely on specific, unpublished documents.", \'verdict\': 0}}, {\'question\': \'What is the configuration of UL2 training objective in OpenMoE and why is it a better choice for pre-training?\', \'output\': {\'feedback\': \'The question asks for the configuration of the UL2 training objective within the OpenMoE framework and the rationale behind its suitability for pre-training. It is clear in specifying the topic of interest (UL2 training objective, OpenMoE) and seeks detailed information on both the configuration and the reasons for its effectiveness in pre-training. However, the question might be challenging for those unfamiliar with the specific terminology or the context of OpenMoE and UL2. For broader clarity and answerability, it would be helpful if the question included a brief explanation or context about OpenMoE and the UL2 training objective, or clarified the aspects of pre-training effectiveness it refers to (e.g., efficiency, accuracy, generalization).\', \'verdict\': 1}}, {\'question\': \'What is the detailed configuration of the UL2 training objective in OpenMoE, based on the provided context?\', \'output\': {\'feedback\': "The question seeks detailed information on the UL2 training objective\'s configuration within the OpenMoE framework, mentioning \'the provided context\' without actually including or describing this context within the query. This makes the question unclear for those who do not have access to the unspecified context. For the question to be clear and answerable, it needs to either include the relevant context directly within the question or be framed in a way that does not require external information. Detailing the specific aspects of the configuration of interest (e.g., loss functions, data augmentation techniques) could also help clarify the query.", \'verdict\': 0}}], input_keys=[\'question\'], output_key=\'output\', output_type=\'json\', language=\'english\')), question_answer_prompt=Prompt(name=\'answer_formulate\', instruction="Answer the question using the information from the given context. Output verdict as \'1\' if answer is present \'-1\' if answer is not present in the context.", output_format_instruction=\'\', examples=[{\'context\': \'Climate change is significantly influenced by human activities, notably the emission of greenhouse gases from burning fossil fuels. The increased greenhouse gas concentration in the atmosphere traps more heat, leading to global warming and changes in weather patterns.\', \'question\': \'How do human activities contribute to climate change?\', \'answer\': {\'answer\': \'Human activities contribute to climate change primarily through the emission of greenhouse gases from burning fossil fuels. These emissions increase the concentration of greenhouse gases in the atmosphere, which traps more heat and leads to global warming and altered weather patterns.\', \'verdict\': \'1\'}}, {\'context\': \'The concept of artificial intelligence (AI) has evolved over time, but it fundamentally refers to machines designed to mimic human cognitive functions. AI can learn, reason, perceive, and, in some instances, react like humans, making it pivotal in fields ranging from healthcare to autonomous vehicles.\', \'question\': \'What are the key capabilities of artificial intelligence?\', \'answer\': {\'answer\': \'Artificial intelligence is designed to mimic human cognitive functions, with key capabilities including learning, reasoning, perception, and reacting to the environment in a manner similar to humans. These capabilities make AI pivotal in various fields, including healthcare and autonomous driving.\', \'verdict\': \'1\'}}, {\'context\': \'The novel "Pride and Prejudice" by Jane Austen revolves around the character Elizabeth Bennet and her family. The story is set in the 19th century in rural England and deals with issues of marriage, morality, and misconceptions.\', \'question\': "What year was \'Pride and Prejudice\' published?", \'answer\': {\'answer\': \'The answer to given question is not present in context\', \'verdict\': \'-1\'}}], input_keys=[\'context\', \'question\'], output_key=\'answer\', output_type=\'json\', language=\'english\'), find_relevant_context_prompt=Prompt(name=\'find_relevant_context\', instruction=\'Given a question and set of contexts, find the most relevant contexts to answer the question.\', output_format_instruction=\'\', examples=[{\'question\': \'What is the capital of France?\', \'contexts\': [\'1. France is a country in Western Europe. It has several cities, including Paris, Lyon, and Marseille. Paris is not only known for its cultural landmarks like the Eiffel Tower and the Louvre Museum but also as the administrative center.\', \'2. The capital of France is Paris. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.\', \'3. Paris is the capital of France. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.\'], \'output\': {\'relevant_contexts\': [1, 2]}}, {\'question\': \'How does caffeine affect the body and what are its common sources?\', \'contexts\': [\'1. Caffeine is a central nervous system stimulant. It can temporarily ward off drowsiness and restore alertness. It primarily affects the brain, where it alters the function of neurotransmitters.\', \'2. Regular physical activity is essential for maintaining good health. It can help control weight, combat health conditions, boost energy, and promote better sleep.\', \'3. Common sources of caffeine include coffee, tea, cola, and energy drinks. These beverages are consumed worldwide and are known for providing a quick boost of energy.\'], \'output\': {\'relevant_contexts\': [1, 2]}}], input_keys=[\'question\', \'contexts\'], output_key=\'output\', output_type=\'json\', language=\'english\'), rewrite_invalid_question_prompt=Prompt(name=\'rewrite_question\', instruction=\'Given a context, question and feedback, rewrite the question to improve its clarity and answerability based on the feedback provided.\', output_format_instruction=\'\', examples=[{\'context\': "The Eiffel Tower was constructed using iron and was originally intended as a temporary exhibit for the 1889 World\'s Fair held in Paris. Despite its initial temporary purpose, the Eiffel Tower quickly became a symbol of Parisian ingenuity and an iconic landmark of the city, attracting millions of visitors each year. The tower\'s design, created by Gustave Eiffel, was initially met with criticism from some French artists and intellectuals, but it has since been celebrated as a masterpiece of structural engineering and architectural design.", \'question\': \'Who created the design for the Tower?\', \'feedback\': "The question asks about the creator of the design for \'the Tower\', but it does not specify which tower it refers to. There are many towers worldwide, and without specifying the exact tower, the question is unclear and unanswerable. To improve the question, it should include the name or a clear description of the specific tower in question.", \'output\': \'Who created the design for the Eiffel Tower?\'}, {\'context\': "\'Exploring Zero-Shot Learning in Neural Networks\' was published by Smith and Lee in 2021, focusing on the application of zero-shot learning techniques in artificial intelligence.", \'question\': \'What datasets were used for the zero-shot evaluations in this study?\', \'feedback\': "The question asks about the datasets used for zero-shot evaluations in \'this study\', without specifying or providing any details about the study in question. This makes the question unclear for those who do not have access to or knowledge of the specific study. To improve clarity and answerability, the question should specify the study it refers to, or provide enough context about the study for the question to be understood and answered independently.", \'output\': \'What datasets were used for the zero-shot evaluations Exploring Zero-Shot Learning in Neural Networks paper?\'}], input_keys=[\'context\', \'question\', \'feedback\'], output_key=\'output\', output_type=\'str\', language=\'english\'), max_tries=5, is_async=True, seed_question_prompt=Prompt(name=\'seed_question\', instruction=\'Generate a question that can be fully answered from given context. The question should be formed using topic\', output_format_instruction=\'\', examples=[{\'context\': \'Photosynthesis in plants involves converting light energy into chemical energy, using chlorophyll and other pigments to absorb light. This process is crucial for plant growth and the production of oxygen.\', \'keyphrase\': \'Photosynthesis\', \'question\': \'What is the role of photosynthesis in plant growth?\'}, {\'context\': \'The Industrial Revolution, starting in the 18th century, marked a major turning point in history as it led to the development of factories and urbanization.\', \'keyphrase\': \'Industrial Revolution\', \'question\': \'How did the Industrial Revolution mark a major turning point in history?\'}, {\'context\': \'The process of evaporation plays a crucial role in the water cycle, converting water from liquid to vapor and allowing it to rise into the atmosphere.\', \'keyphrase\': \'Evaporation\', \'question\': \'Why is evaporation important in the water cycle?\'}], input_keys=[\'context\', \'keyphrase\'], output_key=\'question\', output_type=\'str\', language=\'english\'))\r\n\r\n```\n\n<sub>[R-290](https://linear.app/exploding-gradients/issue/R-290/failed-to-parse-output-returning-none-simpleevolution-testsetgenerator)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/945/reactions',
   'total_count': 4,
   '+1': 4,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/945/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/939',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/939/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/939/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/939/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/939',
  'id': 2282844276,
  'node_id': 'PR_kwDOJgX1Gs5uvaD3',
  'number': 939,
  'title': 'set temperature to 0.01 for better llm compatibility',
  'user': {'login': '0Falli0',
   'id': 71875892,
   'node_id': 'MDQ6VXNlcjcxODc1ODky',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/71875892?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/0Falli0',
   'html_url': 'https: //github.com/0Falli0',
   'followers_url': 'https: //api.github.com/users/0Falli0/followers',
   'following_url': 'https: //api.github.com/users/0Falli0/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/0Falli0/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/0Falli0/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/0Falli0/subscriptions',
   'organizations_url': 'https: //api.github.com/users/0Falli0/orgs',
   'repos_url': 'https: //api.github.com/users/0Falli0/repos',
   'events_url': 'https: //api.github.com/users/0Falli0/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/0Falli0/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-07T10: 14: 13Z',
  'updated_at': '2024-05-07T10: 14: 13Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/939',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/939',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/939.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/939.patch',
   'merged_at': None
            },
  'body': '#938\r\n\r\nChange Temperature from 1e-8 to 0.01 for better llm Compatibility.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/939/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/939/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/938',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/938/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/938/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/938/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/938',
  'id': 2282840803,
  'node_id': 'I_kwDOJgX1Gs6IEWLj',
  'number': 938,
  'title': 'RAGAS compatibility with mistral models',
  'user': {'login': '0Falli0',
   'id': 71875892,
   'node_id': 'MDQ6VXNlcjcxODc1ODky',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/71875892?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/0Falli0',
   'html_url': 'https: //github.com/0Falli0',
   'followers_url': 'https: //api.github.com/users/0Falli0/followers',
   'following_url': 'https: //api.github.com/users/0Falli0/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/0Falli0/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/0Falli0/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/0Falli0/subscriptions',
   'organizations_url': 'https: //api.github.com/users/0Falli0/orgs',
   'repos_url': 'https: //api.github.com/users/0Falli0/repos',
   'events_url': 'https: //api.github.com/users/0Falli0/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/0Falli0/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  },
                  {'id': 6963995062,
    'node_id': 'LA_kwDOJgX1Gs8AAAABnxYhtg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/stale',
    'name': 'stale',
    'color': 'dadada',
    'default': False,
    'description': 'Issue has not had recent activity or appears to be solved. Stale issues will be automatically closed'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-07T10: 13: 11Z',
  'updated_at': '2024-06-07T16: 02: 52Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "- I have checked the [documentation](https://docs.ragas.io/) and related resources and couldn't resolve my bug.\r\n\r\nWithin the base-model file there is a configuration which sets the model temperature to *1e-8*.\r\nThis Temperature does not work for Mistral Models.\r\n\r\nDue to this setting the Models are unable to produce any results.\r\n\r\nWhen replacing the temperature with 0.01 the models seem to work flawlessly.",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/938/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/938/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/936',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/936/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/936/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/936/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/936',
  'id': 2281286148,
  'node_id': 'PR_kwDOJgX1Gs5uqJXo',
  'number': 936,
  'title': 'Extended llm support (e.g. Llama 3, M8x22b) and synthetic test generation',
  'user': {'login': 'ciekawy',
   'id': 2847952,
   'node_id': 'MDQ6VXNlcjI4NDc5NTI=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/2847952?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ciekawy',
   'html_url': 'https: //github.com/ciekawy',
   'followers_url': 'https: //api.github.com/users/ciekawy/followers',
   'following_url': 'https: //api.github.com/users/ciekawy/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ciekawy/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ciekawy/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ciekawy/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ciekawy/orgs',
   'repos_url': 'https: //api.github.com/users/ciekawy/repos',
   'events_url': 'https: //api.github.com/users/ciekawy/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ciekawy/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-06T16: 38: 15Z',
  'updated_at': '2024-05-08T13: 17: 23Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/936',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/936',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/936.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/936.patch',
   'merged_at': None
            },
  'body': '# Enhancements for new opensource models with focus on Llama 3 70b instruct\r\n\r\nThis is a draft PR - it introduces several improvements to RAGAs to enhance its compatibility with Llama 3 70b and improve the quality of generated outputs, especially for synthetic data generation.\r\n\r\n## Prompt Adjustments\r\n\r\n- Modified prompts in `prompt.py` and `prompts.py` to increase the quality of generated outputs, which is particularly important for synthetic data generation.\r\n- The updated prompts aim to provide clearer instructions and more relevant examples to guide the language model in generating higher-quality outputs.\r\n\r\n## Support for Non-Typical LangChain LLM Configurations\r\n\r\n- Added support for LLM configurations that require additional parameters and dynamic calculations when invoking LLM generation.\r\n- Specifically, the Together.ai Llama 3 70b instruct model requires extra parameters, including dynamically calculated values in a callback.\r\n- Introduced a new `LLMConfig` class to encapsulate the custom configuration options.\r\n- Implemented a `together_prompt_callback` function to handle the dynamic prompt generation for the Together.ai Llama 3 70b instruct model.\r\n\r\n### Example Configuration\r\n\r\n```python\r\ndef together_prompt_callback(\r\n    prompt: PromptValue\r\n) -> t.Tuple[t.List[PromptValue
                  ], t.Dict[str, t.Any
                  ]
            ]:\r\n    empty_prompt = StringPromptValue(text=\'\')\r\n    prompt_str = prompt.prompt_str\r\n    messages = [
                  {
                        "content": prompt_str,
                        "role": "user"
                  }
            ]\r\n    return [empty_prompt
            ],
            {
                  "messages": messages
            }\r\n\r\ntogether_llama3instruct_config = LLMConfig(\r\n    stop=[
                  "<|eot_id|>"
            ],\r\n    prompt_callback=together_prompt_callback,\r\n    type="chat",\r\n    prompt_format_string="<human>: {prompt}\\n<bot>:",\r\n    request_type="language-model-inference",\r\n)',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/936/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/936/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/935',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/935/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/935/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/935/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/935',
  'id': 2279293222,
  'node_id': 'PR_kwDOJgX1Gs5ujliO',
  'number': 935,
  'title': 'Add `py.typed` file so mypy knows to use types',
  'user': {'login': 'linjer',
   'id': 1149070,
   'node_id': 'MDQ6VXNlcjExNDkwNzA=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/1149070?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/linjer',
   'html_url': 'https: //github.com/linjer',
   'followers_url': 'https: //api.github.com/users/linjer/followers',
   'following_url': 'https: //api.github.com/users/linjer/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/linjer/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/linjer/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/linjer/subscriptions',
   'organizations_url': 'https: //api.github.com/users/linjer/orgs',
   'repos_url': 'https: //api.github.com/users/linjer/repos',
   'events_url': 'https: //api.github.com/users/linjer/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/linjer/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-05-05T02: 44: 15Z',
  'updated_at': '2024-05-05T02: 44: 15Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/935',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/935',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/935.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/935.patch',
   'merged_at': None
            },
  'body': 'This adds a `py.typed` file so mypy uses types (PEP 561 compatibility).\n\nSee https: //mypy.readthedocs.io/en/stable/installed_packages.html#creating-pep-561-compatible-packages\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/935/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/935/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/927',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/927/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/927/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/927/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/927',
  'id': 2272761395,
  'node_id': 'I_kwDOJgX1Gs6Hd5Yz',
  'number': 927,
  'title': 'Get Started section for "Generate a Synthetic Test Set" is broken',
  'user': {'login': 'ckrapu-nv',
   'id': 163057301,
   'node_id': 'U_kgDOCbgOlQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/163057301?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ckrapu-nv',
   'html_url': 'https: //github.com/ckrapu-nv',
   'followers_url': 'https: //api.github.com/users/ckrapu-nv/followers',
   'following_url': 'https: //api.github.com/users/ckrapu-nv/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ckrapu-nv/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ckrapu-nv/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ckrapu-nv/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ckrapu-nv/orgs',
   'repos_url': 'https: //api.github.com/users/ckrapu-nv/repos',
   'events_url': 'https: //api.github.com/users/ckrapu-nv/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ckrapu-nv/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-05-01T01: 30: 00Z',
  'updated_at': '2024-06-17T06: 00: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[x
            ] I have checked the [documentation
            ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\nThe [get started section on synthetic data generation](https://docs.ragas.io/en/stable/getstarted/testset_generation.html#get-started-testset-generation) is broken. For loading a very basic single file test case, the code hangs.\r\n\r\n\r\n\r\nRagas version: 0.1.7\r\nPython version: 3.12.2 \r\nOS: MacOS Sonoma\r\n\r\n**Code to Reproduce**\r\n```\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\nfrom langchain.document_loaders import DirectoryLoader\r\nfrom ragas.testset.generator import TestsetGenerator\r\nimport os\r\n\r\ndirectory = "../test-directory"\r\nfile_content = """Ted is 37 years old and has a birthmark on his lower thigh. His favorite food is spaghetti with meatballs and his last vacation was to Punta Gorda. He is engaged to be married next year, and enjoys watching the Cincinnati Bengals play in the NFL."""\r\n\r\nif not os.path.exists(directory):\r\n    os.makedirs(directory)\r\n\r\nwith open(os.path.join(directory, "test.txt"),\'w\') as dest:\r\n    dest.write(file_content)\r\n\r\nloader = DirectoryLoader(directory)\r\ndocuments = loader.load()\r\n\r\nprint(documents)\r\n\r\n# generator with openai models\r\ngenerator_llm = ChatOpenAI(model="gpt-3.5-turbo-16k")\r\ncritic_llm = ChatOpenAI(model="gpt-4")\r\nembeddings = OpenAIEmbeddings()\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\n# generate testset\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=2)\r\n```\r\n**Error trace**\r\nWhen interrupted, here is the resulting trace\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nKeyboardInterrupt                         Traceback (most recent call last)\r\nCell In[8], line 32\r\n     25 generator = TestsetGenerator.from_langchain(\r\n     26     generator_llm,\r\n     27     critic_llm,\r\n     28     embeddings\r\n     29 )\r\n     31 # generate testset\r\n---> 32 testset = generator.generate_with_langchain_docs(documents, test_size=2)\r\n\r\nFile ~/salesbot/salesbot-venv/lib/python3.12/site-packages/ragas/testset/generator.py:175, in TestsetGenerator.generate_with_langchain_docs(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\r\n    173 distributions = distributions or {}\r\n    174 # chunk documents and add to docstore\r\n--> 175 self.docstore.add_documents(\r\n    176     [Document.from_langchain_document(doc) for doc in documents]\r\n    177 )\r\n    179 return self.generate(\r\n    180     test_size=test_size,\r\n    181     distributions=distributions,\r\n   (...)\r\n    185     run_config=run_config,\r\n    186 )\r\n\r\nFile ~/salesbot/salesbot-venv/lib/python3.12/site-packages/ragas/testset/docstore.py:215, in InMemoryDocumentStore.add_documents(self, docs, show_progress)\r\n    210 # split documents with self.splitter into smaller nodes\r\n    211 nodes = [\r\n    212     Node.from_langchain_document(d)\r\n    213     for d in self.splitter.transform_documents(docs)\r\n    214 ]\r\n--> 215 self.add_nodes(nodes, show_progress=show_progress)\r\n\r\nFile ~/salesbot/salesbot-venv/lib/python3.12/site-packages/ragas/testset/docstore.py:252, in InMemoryDocumentStore.add_nodes(self, nodes, show_progress)\r\n    245         executor.submit(\r\n    246             self.extractor.extract,\r\n    247             n,\r\n    248             name=f"keyphrase-extraction[{i}]",\r\n    249         )\r\n    250         result_idx += 1\r\n--> 252 results = executor.results()\r\n    253 if not results:\r\n    254     raise ExceptionInRunner()\r\n\r\nFile ~/salesbot/salesbot-venv/lib/python3.12/site-packages/ragas/executor.py:132, in Executor.results(self)\r\n    130 executor_job.start()\r\n    131 try:\r\n--> 132     executor_job.join()\r\n    133 finally:\r\n    134     ...\r\n\r\nFile /opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:1147, in Thread.join(self, timeout)\r\n   1144     raise RuntimeError("cannot join current thread")\r\n   1146 if timeout is None:\r\n-> 1147     self._wait_for_tstate_lock()\r\n   1148 else:\r\n   1149     # the behavior of a negative timeout isn\'t documented, but\r\n   1150     # historically .join(timeout=x) for x<0 has acted as if timeout=0\r\n   1151     self._wait_for_tstate_lock(timeout=max(timeout, 0))\r\n\r\nFile /opt/homebrew/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:1167, in Thread._wait_for_tstate_lock(self, block, timeout)\r\n   1164     return\r\n   1166 try:\r\n-> 1167     if lock.acquire(block, timeout):\r\n   1168         lock.release()\r\n   1169         self._stop()\r\n\r\nKeyboardInterrupt: \r\n```\r\n\r\n**Expected behavior**\r\nProduction of a synthetic test set; code should not hang\r\n\r\n**Additional context**\r\nN/A',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/927/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/927/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/926',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/926/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/926/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/926/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/926',
  'id': 2272590925,
  'node_id': 'I_kwDOJgX1Gs6HdPxN',
  'number': 926,
  'title': 'Init attribute is mutable and shared (not intended?)',
  'user': {'login': 'JunhaoWang',
   'id': 16586487,
   'node_id': 'MDQ6VXNlcjE2NTg2NDg3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/16586487?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/JunhaoWang',
   'html_url': 'https: //github.com/JunhaoWang',
   'followers_url': 'https: //api.github.com/users/JunhaoWang/followers',
   'following_url': 'https: //api.github.com/users/JunhaoWang/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/JunhaoWang/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/JunhaoWang/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/JunhaoWang/subscriptions',
   'organizations_url': 'https: //api.github.com/users/JunhaoWang/orgs',
   'repos_url': 'https: //api.github.com/users/JunhaoWang/repos',
   'events_url': 'https: //api.github.com/users/JunhaoWang/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/JunhaoWang/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-30T22: 34: 34Z',
  'updated_at': '2024-06-10T07: 17: 09Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '```\r\nfrom ragas.testset.filters import EvolutionFilter\r\na = EvolutionFilter(None)\r\nb = EvolutionFilter(None)\r\na.evolution_elimination_prompt.name = "a"\r\nprint(a.evolution_elimination_prompt.name)\r\nprint(b.evolution_elimination_prompt.name)\r\n```\r\nthis prints\r\n```\r\na\r\na\r\n```\r\nnot intended?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/926/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/926/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/923',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/923/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/923/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/923/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/923',
  'id': 2272297944,
  'node_id': 'I_kwDOJgX1Gs6HcIPY',
  'number': 923,
  'title': 'documentation on cosine similarity range is wrong',
  'user': {'login': 'JunhaoWang',
   'id': 16586487,
   'node_id': 'MDQ6VXNlcjE2NTg2NDg3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/16586487?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/JunhaoWang',
   'html_url': 'https: //github.com/JunhaoWang',
   'followers_url': 'https: //api.github.com/users/JunhaoWang/followers',
   'following_url': 'https: //api.github.com/users/JunhaoWang/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/JunhaoWang/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/JunhaoWang/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/JunhaoWang/subscriptions',
   'organizations_url': 'https: //api.github.com/users/JunhaoWang/orgs',
   'repos_url': 'https: //api.github.com/users/JunhaoWang/repos',
   'events_url': 'https: //api.github.com/users/JunhaoWang/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/JunhaoWang/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-30T19: 23: 48Z',
  'updated_at': '2024-05-15T12: 55: 06Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'In [doc
            ](https: //docs.ragas.io/en/latest/concepts/metrics/semantic_similarity.html ), \r\n\r\n> The concept of Answer Semantic Similarity pertains to the assessment of the semantic resemblance between the generated answer and the ground truth. This evaluation is based on the ground truth and the answer, with values falling within the range of 0 to 1.\r\n\r\nThis is wrong since cosine similarity can take on negative values\r\n```\r\na = [1.0]\r\nb = [-1.0]\r\ncosine_sim_a_b = a dot_product b / (a_norm x b_norm) = -1\r\n```',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/923/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/923/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/922',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/922/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/922/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/922/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/922',
  'id': 2271870053,
  'node_id': 'I_kwDOJgX1Gs6Hafxl',
  'number': 922,
  'title': 'value error: probabilities are less than 0',
  'user': {'login': 'theoden8',
   'id': 12466435,
   'node_id': 'MDQ6VXNlcjEyNDY2NDM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/12466435?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/theoden8',
   'html_url': 'https: //github.com/theoden8',
   'followers_url': 'https: //api.github.com/users/theoden8/followers',
   'following_url': 'https: //api.github.com/users/theoden8/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/theoden8/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/theoden8/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/theoden8/subscriptions',
   'organizations_url': 'https: //api.github.com/users/theoden8/orgs',
   'repos_url': 'https: //api.github.com/users/theoden8/repos',
   'events_url': 'https: //api.github.com/users/theoden8/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/theoden8/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-30T15: 46: 52Z',
  'updated_at': '2024-06-10T07: 17: 37Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "https://github.com/explodinggradients/ragas/blob/main/src/ragas/testset/docstore.py#L325 there's a bug here\r\n\r\nIt can be patched by either, setting `prob[prob < 0] = .0` before normalization or by adding `prob += eps`. Here are the min and max values I have:\r\n\r\n```\r\n> prob.min(), prob.max(), prob.sum()\r\n(-2.47917840909896e-05, 0.0005422972470319377, 1.0)\r\n```",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/922/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/922/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/920',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/920/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/920/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/920/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/920',
  'id': 2270939657,
  'node_id': 'I_kwDOJgX1Gs6HW8oJ',
  'number': 920,
  'title': 'I want to know how Testset Generator to create dataset works. Can anyone give like flowchart or anything. I wanna know the high level understanding',
  'user': {'login': 'sfc-gh-akashyap',
   'id': 167956476,
   'node_id': 'U_kgDOCgLP_A',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/167956476?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/sfc-gh-akashyap',
   'html_url': 'https: //github.com/sfc-gh-akashyap',
   'followers_url': 'https: //api.github.com/users/sfc-gh-akashyap/followers',
   'following_url': 'https: //api.github.com/users/sfc-gh-akashyap/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/sfc-gh-akashyap/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/sfc-gh-akashyap/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/sfc-gh-akashyap/subscriptions',
   'organizations_url': 'https: //api.github.com/users/sfc-gh-akashyap/orgs',
   'repos_url': 'https: //api.github.com/users/sfc-gh-akashyap/repos',
   'events_url': 'https: //api.github.com/users/sfc-gh-akashyap/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/sfc-gh-akashyap/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 6,
  'created_at': '2024-04-30T09: 12: 36Z',
  'updated_at': '2024-05-19T11: 10: 18Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "I checked the [documentation](https://docs.ragas.io/en/latest/concepts/testset_generation.html) and related resources and couldn't find an answer to my question.\r\n\r\nI wanna know the high level understanding.\r\nI got to know what is evolution but I wanna know information like how many llm call are happening. How actually the questions are generated \r\n\r\n\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/920/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/920/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/916',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/916/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/916/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/916/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/916',
  'id': 2269838053,
  'node_id': 'I_kwDOJgX1Gs6HSvrl',
  'number': 916,
  'title': '[R-247
            ] Integrations: wandb and wandb tracer',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-04-29T19: 49: 44Z',
  'updated_at': '2024-08-15T04: 45: 10Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': 'todo\n\n- [] How to do Evaluation Driven Development with the wandb stack?\n- [] build out `ragas.integration.wandb` to make that easiest for users\n\n<sub>From [SyncLinear.com
            ](https: //synclinear.com) | [R-247](https://linear.app/exploding-gradients/issue/R-247/integrations-wandb-and-wandb-tracer)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/916/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
            },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/916/timeline',
  'performed_via_github_app': None,
  'state_reason': None
      },
      {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/910',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/910/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/910/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/910/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/910',
  'id': 2264681517,
  'node_id': 'I_kwDOJgX1Gs6G_Ewt',
  'number': 910,
  'title': '[R-227
            ] Add an MLFlow Integration',
  'user': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
            },
  'labels': [
                  {'id': 6872832665,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmacamQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/Feature',
    'name': 'Feature',
    'color': 'BB87FC',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                  }
            ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-04-26T00: 01: 34Z',
  'updated_at': '2024-09-06T04: 48: 56Z',
  'closed_at': None,
  'author_association': 'MEMBER',
  'active_lock_reason': None,
  'body': '\\[work in progress\\
            ] - still flushing out the specifics\n\n* @jjmachan will first build a POC\n\n### Todos\n\n- [] POC\n- [] `ragas.integration` and documentation\n- [] joined blog post?\n\n### Resources\n\n* [https: //mlflow.org/docs/latest/llms/rag/notebooks/mlflow-e2e-evaluation.html](https://mlflow.org/docs/latest/llms/rag/notebooks/mlflow-e2e-evaluation.html?highlight=evaluate)\n\n<sub>From [SyncLinear.com](https://synclinear.com) | [R-227](https://linear.app/exploding-gradients/issue/R-227/add-an-mlflow-integration)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/910/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/910/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/902',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/902/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/902/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/902/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/902',
  'id': 2263940044,
  'node_id': 'PR_kwDOJgX1Gs5tvq0H',
  'number': 902,
  'title': 'Fix grammatical errors in critique definitions',
  'user': {'login': 'LogicalShark',
   'id': 9994650,
   'node_id': 'MDQ6VXNlcjk5OTQ2NTA=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/9994650?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/LogicalShark',
   'html_url': 'https: //github.com/LogicalShark',
   'followers_url': 'https: //api.github.com/users/LogicalShark/followers',
   'following_url': 'https: //api.github.com/users/LogicalShark/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/LogicalShark/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/LogicalShark/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/LogicalShark/subscriptions',
   'organizations_url': 'https: //api.github.com/users/LogicalShark/orgs',
   'repos_url': 'https: //api.github.com/users/LogicalShark/repos',
   'events_url': 'https: //api.github.com/users/LogicalShark/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/LogicalShark/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-25T15: 48: 12Z',
  'updated_at': '2024-04-25T15: 48: 12Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/902',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/902',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/902.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/902.patch',
   'merged_at': None
                  },
  'body': 'Assuming these are not intentional, most of the critique definitions have minor typos. If this was intentional I would suggest adding comments to avoid confusion.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/902/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/902/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/899',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/899/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/899/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/899/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/899',
  'id': 2261860826,
  'node_id': 'I_kwDOJgX1Gs6G0UHa',
  'number': 899,
  'title': '[R-233
                  ] How to generate a testset with VertexAI',
  'user': {'login': 'jaymon0703',
   'id': 4340156,
   'node_id': 'MDQ6VXNlcjQzNDAxNTY=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/4340156?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jaymon0703',
   'html_url': 'https: //github.com/jaymon0703',
   'followers_url': 'https: //api.github.com/users/jaymon0703/followers',
   'following_url': 'https: //api.github.com/users/jaymon0703/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jaymon0703/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jaymon0703/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jaymon0703/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jaymon0703/orgs',
   'repos_url': 'https: //api.github.com/users/jaymon0703/repos',
   'events_url': 'https: //api.github.com/users/jaymon0703/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jaymon0703/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-24T17: 51: 48Z',
  'updated_at': '2024-06-01T11: 40: 20Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Currently getting an error. See https: //github.com/explodinggradients/ragas/issues/735 for more info on the error.\r\n\r\nIf anyone has working code for testset generation using VertexAI i would love to see it. Thanks!\n\n<sub>[R-233](https://linear.app/exploding-gradients/issue/R-233/how-to-generate-a-testset-with-vertexai)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/899/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/899/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/898',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/898/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/898/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/898/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/898',
  'id': 2261637467,
  'node_id': 'I_kwDOJgX1Gs6Gzdlb',
  'number': 898,
  'title': '[R-224
                  ] Ragas integration with Langfuse to trace both llm outputs and scores in the same place',
  'user': {'login': 'databill86',
   'id': 41125230,
   'node_id': 'MDQ6VXNlcjQxMTI1MjMw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/41125230?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/databill86',
   'html_url': 'https: //github.com/databill86',
   'followers_url': 'https: //api.github.com/users/databill86/followers',
   'following_url': 'https: //api.github.com/users/databill86/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/databill86/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/databill86/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/databill86/subscriptions',
   'organizations_url': 'https: //api.github.com/users/databill86/orgs',
   'repos_url': 'https: //api.github.com/users/databill86/repos',
   'events_url': 'https: //api.github.com/users/databill86/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/databill86/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-24T15: 55: 27Z',
  'updated_at': '2024-06-25T11: 12: 40Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[x
                  ] I checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\nI checked and tested the integration of `ragas` with `Langfuse` as demonstrated [here](https://docs.ragas.io/en/latest/howtos/integrations/langfuse.html). Although a lot of the code in that page did not work, I used the `evaluate` function to get the scores, and I logged all the scores in `Langfuse`. \r\n\r\n**My Question: how to customize llm traces with ragas**\r\n\r\nIs there any way we can log the llm generations when evaluating the results using some given `trace_ids` ?\r\nI already have the generations logged into langfuse, but the problem is I want to log these generations into some other corresponding trace_ids I already generated. \r\nIs this possible ? \r\n\r\n**Code Examples**\r\n```\r\n        score = evaluate(\r\n            dataset,\r\n            metrics=[\r\n                context_precision,\r\n                context_recall,\r\n                context_relevancy,\r\n            ],\r\n            llm=llm_ragas,\r\n            embeddings=embedding_model_ragas,\r\n        )\r\n\r\n       # at this point, the traces of all the llm generations done by ragas are already logged into langfuse. \r\n       # is there a way we can log them using some given trace ids ? \r\n        ....\r\n        for k, v in score_row.items():\r\n            try:\r\n                if v not math.isnan(v):\r\n                    langfuse.score(trace_id=trace_id, name=k, value=v)\r\n                else:\r\n                    logger.error(f"Score {k} is None")\r\n            except Exception as e:\r\n                logger.error(f"Error logging score: {e}")\r\n....\r\n\r\n```\r\n\r\nI believe these issues are related: https://github.com/explodinggradients/ragas/issues/896, https://github.com/explodinggradients/ragas/issues/893\r\n\r\n**Additional context**\r\nHere are the requirements used. \r\n\r\nlangfuse==2.26.3 \r\nlitellm==1.35.12\r\nragas==0.1.7\n\n<sub>[R-224](https://linear.app/exploding-gradients/issue/R-224/ragas-integration-with-langfuse-to-trace-both-llm-outputs-and-scores)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/898/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/898/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/896',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/896/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/896/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/896/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/896',
  'id': 2261154640,
  'node_id': 'I_kwDOJgX1Gs6GxntQ',
  'number': 896,
  'title': '[R-272
                  ] keep reasoning as part of the evaluation',
  'user': {'login': 'Yen444',
   'id': 85874150,
   'node_id': 'MDQ6VXNlcjg1ODc0MTUw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/85874150?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Yen444',
   'html_url': 'https: //github.com/Yen444',
   'followers_url': 'https: //api.github.com/users/Yen444/followers',
   'following_url': 'https: //api.github.com/users/Yen444/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Yen444/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Yen444/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Yen444/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Yen444/orgs',
   'repos_url': 'https: //api.github.com/users/Yen444/repos',
   'events_url': 'https: //api.github.com/users/Yen444/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Yen444/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        },
                        {'id': 6872832665,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmacamQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/Feature',
    'name': 'Feature',
    'color': 'BB87FC',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-24T12: 15: 20Z',
  'updated_at': '2024-06-10T07: 23: 28Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Is it possible to go beyond simply viewing the score to also accessing the LLM output?\n\n<sub>[R-272
                  ](https: //linear.app/exploding-gradients/issue/R-272/keep-reasoning-as-part-of-the-evaluation)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/896/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/896/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/895',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/895/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/895/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/895/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/895',
  'id': 2260500509,
  'node_id': 'I_kwDOJgX1Gs6GvIAd',
  'number': 895,
  'title': '[R-258
                  ] Question about official docs of Context Precision.',
  'user': {'login': 'AxelJongoPark',
   'id': 131431642,
   'node_id': 'U_kgDOB9V82g',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/131431642?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/AxelJongoPark',
   'html_url': 'https: //github.com/AxelJongoPark',
   'followers_url': 'https: //api.github.com/users/AxelJongoPark/followers',
   'following_url': 'https: //api.github.com/users/AxelJongoPark/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/AxelJongoPark/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/AxelJongoPark/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/AxelJongoPark/subscriptions',
   'organizations_url': 'https: //api.github.com/users/AxelJongoPark/orgs',
   'repos_url': 'https: //api.github.com/users/AxelJongoPark/repos',
   'events_url': 'https: //api.github.com/users/AxelJongoPark/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/AxelJongoPark/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                        ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
                  },
  'comments': 3,
  'created_at': '2024-04-24T06: 50: 08Z',
  'updated_at': '2024-09-02T07: 06: 50Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "What I understood is that Following case is calculation of Context Precision at K=2.\r\n\r\nFor that case, Last part's denominator must be 2 not 1.\r\n\r\nIs this right?\r\n\r\nIf i didn't understand well, could you explain more about this?? \r\nFollowing is what i'm thinking.\r\n\r\n1. precision at 1\r\nFP at 1 =1, TP at 1 =0 -> precision at 1 = 0\r\n2. precision at 2\r\nFP at 2 =1 , TP at 1 =1 -> precision at 2 = 1/2 =0.5 (since we consider top 2 resulte in context chunk items)\r\n3 finally, we have\r\nContext Precision at K=2 is\r\n(1/2)x(preicision at 1 x indicator at 1 + preicision at 2x indicator at 2) = (1/2)x(0x1+0.5x1)=0.25\r\n\r\nthanks.  \r\n\r\n![ragas_docs](https://github.com/explodinggradients/ragas/assets/131431642/8d2dcfaf-a8de-4b63-a252-ca4cdb3f3a8e)\r\n\n\n<sub>[R-258](https://linear.app/exploding-gradients/issue/R-258/question-about-official-docs-of-context-precision)</sub>",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/895/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/895/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/894',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/894/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/894/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/894/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/894',
  'id': 2259712841,
  'node_id': 'PR_kwDOJgX1Gs5thSqQ',
  'number': 894,
  'title': 'Fix a few typos in the docs',
  'user': {'login': 'amirma',
   'id': 2546225,
   'node_id': 'MDQ6VXNlcjI1NDYyMjU=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/2546225?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/amirma',
   'html_url': 'https: //github.com/amirma',
   'followers_url': 'https: //api.github.com/users/amirma/followers',
   'following_url': 'https: //api.github.com/users/amirma/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/amirma/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/amirma/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/amirma/subscriptions',
   'organizations_url': 'https: //api.github.com/users/amirma/orgs',
   'repos_url': 'https: //api.github.com/users/amirma/repos',
   'events_url': 'https: //api.github.com/users/amirma/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/amirma/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-23T20: 27: 40Z',
  'updated_at': '2024-04-23T22: 37: 38Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/894',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/894',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/894.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/894.patch',
   'merged_at': None
                  },
  'body': None,
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/894/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/894/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/891',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/891/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/891/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/891/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/891',
  'id': 2256488752,
  'node_id': 'PR_kwDOJgX1Gs5tWSes',
  'number': 891,
  'title': 'fix: Adapted output keys do not match with the original output keys',
  'user': {'login': 'FeU-aKlos',
   'id': 28005881,
   'node_id': 'MDQ6VXNlcjI4MDA1ODgx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/28005881?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/FeU-aKlos',
   'html_url': 'https: //github.com/FeU-aKlos',
   'followers_url': 'https: //api.github.com/users/FeU-aKlos/followers',
   'following_url': 'https: //api.github.com/users/FeU-aKlos/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/FeU-aKlos/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/FeU-aKlos/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/FeU-aKlos/subscriptions',
   'organizations_url': 'https: //api.github.com/users/FeU-aKlos/orgs',
   'repos_url': 'https: //api.github.com/users/FeU-aKlos/repos',
   'events_url': 'https: //api.github.com/users/FeU-aKlos/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/FeU-aKlos/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-04-22T13: 03: 09Z',
  'updated_at': '2024-05-16T11: 27: 15Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/891',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/891',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/891.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/891.patch',
   'merged_at': None
                  },
  'body': 'this should fix the error mentioned [here
                  ](https: //github.com/explodinggradients/ragas/issues/774) and [here](https://github.com/explodinggradients/ragas/issues/804) \r\n\r\nthe error is thrown due to an example with an empty list of statements.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/891/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/891/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/890',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/890/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/890/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/890/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/890',
  'id': 2255479193,
  'node_id': 'I_kwDOJgX1Gs6Gb-GZ',
  'number': 890,
  'title': '[R-229
                  ] Automatic language adaptation bugs cleanup',
  'user': {'login': 'rere950303',
   'id': 78265252,
   'node_id': 'MDQ6VXNlcjc4MjY1MjUy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/78265252?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/rere950303',
   'html_url': 'https: //github.com/rere950303',
   'followers_url': 'https: //api.github.com/users/rere950303/followers',
   'following_url': 'https: //api.github.com/users/rere950303/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/rere950303/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/rere950303/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/rere950303/subscriptions',
   'organizations_url': 'https: //api.github.com/users/rere950303/orgs',
   'repos_url': 'https: //api.github.com/users/rere950303/repos',
   'events_url': 'https: //api.github.com/users/rere950303/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/rere950303/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                        ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
                  },
  'comments': 3,
  'created_at': '2024-04-22T03: 04: 05Z',
  'updated_at': '2024-09-02T07: 06: 52Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '- [X
                  ] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\n\n**Describe the bug**\nWhen i try automatic language adaptation for a faithfulness metric, i get `AssertionError: Adapted output key set(output.keys())={\'statements\'} does not match original output key: output_keys[i]=[]` error\n\nRagas version: 0.1.7\nPython version: 3.8.11\n\n**Code to Reproduce**\n\n```python\n    openai_llm = ChatOpenAI(model_name="gpt-4-turbo-2024-04-09")\n    openai_embedding = OpenAIEmbeddings(model="text-embedding-3-large")\n\n    faithfulness = Faithfulness()\n    answer_relevancy = AnswerRelevancy()\n    context_precision = ContextPrecision()\n    context_utilization = ContextUtilization()\n    context_relevancy = ContextRelevancy()\n    context_recall = ContextRecall()\n    answer_similarity = AnswerSimilarity()\n    answer_correctness = AnswerCorrectness()\n    harmfulness = AspectCritique(\n        name="harmfulness",\n        definition="Does the submission causes or has the potential to cause harm to individuals, groups, or society at large?",  # noqa: E501\n        strictness=3\n    )\n    maliciousness = AspectCritique(name="maliciousness", definition="Is the submission intends to harm, deceive, or exploit users?", strictness=3)\n    coherence = AspectCritique(\n        name="coherence",\n        definition="Does the submission presents ideas, information, or arguments in a logical and organized manner?",  # noqa: E501,\n        strictness=3\n    )\n    correctness = AspectCritique(name="correctness", definition="Is the submission factually accurate and free from errors?", strictness=3)\n    conciseness = AspectCritique(\n        name="conciseness",\n        definition="Does the submission conveys information or ideas clearly and efficiently, without unnecessary or redundant details",  # noqa: E501,\n        strictness=3\n    )\n\n    adapt(\n        metrics=[\n            faithfulness, answer_relevancy, context_precision, context_utilization, context_relevancy,\n            context_recall, answer_similarity, answer_correctness, harmfulness, maliciousness,\n            coherence, correctness, conciseness\n        ],\n        language=japanese,\n        llm=openai_llm,\n        cache_dir="./prompt_adaptation_cache"\n    )\n```\n\n**Error trace**\n\n```\nFile ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~/.local/share/virtualenvs/works-openai-bot-bB7UW0C9/lib/python3.8/site-packages/ragas/adaptation.py:36, in adapt(metrics, language, llm, cache_dir)\n     33     metric.llm = llm_wraper\n     35 if hasattr(metric, "adapt"):\n---> 36     metric.adapt(language, cache_dir=cache_dir)\n     37     metric.save(cache_dir=cache_dir)\n     38     metric.llm = metric_llm\n\nFile ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~/.local/share/virtualenvs/works-openai-bot-bB7UW0C9/lib/python3.8/site-packages/ragas/metrics/_faithfulness.py:232, in Faithfulness.adapt(self, language, cache_dir)\n    229 assert self.llm is not None, "LLM is not set"\n    231 logger.info(f"Adapting Faithfulness metric to {language}")\n--> 232 self.long_form_answer_prompt = self.long_form_answer_prompt.adapt(\n    233     language, self.llm, cache_dir\n    234 )\n    235 self.nli_statements_message = self.nli_statements_message.adapt(\n    236     language, self.llm, cache_dir\n    237 )\n\nFile ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~/.local/share/virtualenvs/works-openai-bot-bB7UW0C9/lib/python3.8/site-packages/ragas/llms/prompt.py:240, in Prompt.adapt(self, language, llm, cache_dir)\n    238 output = example_dict[self.output_key]\n    239 if isinstance(output, dict):\n--> 240     assert (\n    241         set(output.keys()) == output_keys[i]\n    242     ), f"Adapted output keys {set(output.keys())=} do not match with the original output keys: {output_keys[i]=}"\n    243 elif isinstance(output, list) and all(\n    244     isinstance(item, dict) for item in output\n    245 ):\n    246     assert all(\n    247         set(item.keys()) in output_keys[i] for item in output\n    248     ), "Adapted output keys do not match with the original output keys"\n\nAssertionError: Adapted output keys set(output.keys())={\'statements\'} do not match with the original output keys: output_keys[i]=[]\n```\n\n**Expected behavior**\nIt should operate normally.\n\n**Additional context** Add any other context about the problem here.Tvgv\n\n<sub>From [SyncLinear.com](https://synclinear.com) | [R-229](https://linear.app/exploding-gradients/issue/R-229/automatic-language-adaptation-bugs-cleanup)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/890/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/890/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/888',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/888/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/888/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/888/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/888',
  'id': 2255095421,
  'node_id': 'I_kwDOJgX1Gs6GagZ9',
  'number': 888,
  'title': '[R-230
                  ] Adapt prompts "in place" also for cached prompts',
  'user': {'login': 'HerrIvan',
   'id': 129194928,
   'node_id': 'U_kgDOB7NbsA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/129194928?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/HerrIvan',
   'html_url': 'https: //github.com/HerrIvan',
   'followers_url': 'https: //api.github.com/users/HerrIvan/followers',
   'following_url': 'https: //api.github.com/users/HerrIvan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/HerrIvan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/HerrIvan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/HerrIvan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/HerrIvan/orgs',
   'repos_url': 'https: //api.github.com/users/HerrIvan/repos',
   'events_url': 'https: //api.github.com/users/HerrIvan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/HerrIvan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-04-21T14: 02: 06Z',
  'updated_at': '2024-08-02T07: 24: 14Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nAdapt Prompts "in place", also in case they are retrieved from the cache.\r\n\r\n**Why is the feature important for you?**\r\nIf you want to generate a testset in a non-english language, the right approach is tofirst adapt all the generation/filtering prompts and then run the generation. \r\nHowever, this works only if you adapt the prompts the first time. In that case, the prompt instances get changed "in place", that means that when the `testset.generate` accesses the prompts, these prompts are the translated ones. However, if the prompts are retrieved from the cache, they are not changed "in place", which means that when TestsetGenerator.generate accesses the prompts, it uses the original ones in English.\r\n\r\n**Additional context**\r\nThis is half a feature request, half a bug, since the behavior of the "adapt" function is not consistent: Prompts in the cache are not modified "in place", while instances of prompts not in the cache are modified.\r\n\r\nSee below in `src/ragas/llms/prompt.py`, when a prompt is "translated/adapted" the translated values are stored in the prompt instance. On top of that, the instance is returned.\r\n\r\n```python\r\n        for i, example in enumerate(grouped_results):\r\n            [...
                  ]\r\n            self.examples[i
                  ] = example_dict\r\n\r\n        self.language = language\r\n\r\n        # TODO:Validate the prompt after adaptation\r\n\r\n        return self\r\n```\r\n\r\nHowever, in the same function, whenever there is a hit in the `cache` the current prompt instance isn\'t modified (ie, nothing is assigned to the `self` var:\r\n\r\n```python\r\n        if os.path.exists(os.path.join(cache_dir, language, f"{self.name}.json")):\r\n            return self._load(language, self.name, cache_dir)\r\n```\r\n\r\n(The function `self._load` is a class method which doesn\'t modify the instance).\r\n\r\nI will open a PR to address this issue.\r\n\n\n<sub>[R-230
                  ](https: //linear.app/exploding-gradients/issue/R-230/adapt-prompts-in-place-also-for-cached-prompts)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/888/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/888/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/885',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/885/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/885/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/885/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/885',
  'id': 2254570652,
  'node_id': 'PR_kwDOJgX1Gs5tP9z8',
  'number': 885,
  'title': 'fix(evaluation): Update evaluation dataset parameters docs',
  'user': {'login': 'zhaozhiming',
   'id': 1436694,
   'node_id': 'MDQ6VXNlcjE0MzY2OTQ=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/1436694?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/zhaozhiming',
   'html_url': 'https: //github.com/zhaozhiming',
   'followers_url': 'https: //api.github.com/users/zhaozhiming/followers',
   'following_url': 'https: //api.github.com/users/zhaozhiming/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/zhaozhiming/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/zhaozhiming/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/zhaozhiming/subscriptions',
   'organizations_url': 'https: //api.github.com/users/zhaozhiming/orgs',
   'repos_url': 'https: //api.github.com/users/zhaozhiming/repos',
   'events_url': 'https: //api.github.com/users/zhaozhiming/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/zhaozhiming/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-04-20T14: 15: 32Z',
  'updated_at': '2024-04-23T01: 38: 21Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/885',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/885',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/885.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/885.patch',
   'merged_at': None
                  },
  'body': 'Hi, I used the evaluation and found the docs of ground_truth parameter should be `list[str
                  ]`. \r\nSee the `validate_column_dtypes` method in [validation.py
                  ](https: //github.com/explodinggradients/ragas/blob/main/src/ragas/validation.py#L43).\r\nThanks.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/885/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/885/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/884',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/884/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/884/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/884/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/884',
  'id': 2254478463,
  'node_id': 'PR_kwDOJgX1Gs5tPsN4',
  'number': 884,
  'title': 'fix: replace assert with ValueError for llm validation',
  'user': {'login': 'iw4p',
   'id': 30632761,
   'node_id': 'MDQ6VXNlcjMwNjMyNzYx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/30632761?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/iw4p',
   'html_url': 'https: //github.com/iw4p',
   'followers_url': 'https: //api.github.com/users/iw4p/followers',
   'following_url': 'https: //api.github.com/users/iw4p/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/iw4p/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/iw4p/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/iw4p/subscriptions',
   'organizations_url': 'https: //api.github.com/users/iw4p/orgs',
   'repos_url': 'https: //api.github.com/users/iw4p/repos',
   'events_url': 'https: //api.github.com/users/iw4p/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/iw4p/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-20T09: 51: 02Z',
  'updated_at': '2024-04-22T22: 55: 28Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/884',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/884',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/884.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/884.patch',
   'merged_at': None
                  },
  'body': 'It\'s absolutely better to use raise ValueError instead of assert. (or maybe someone has a better idea)\r\nIf you agree for the next refactors I can implement this method\r\n```\r\ndef check_llm(self):\r\n    if self.llm is None:\r\n        raise ValueError("LLM must be set before using this method")\r\n```\r\nSo by using this method whenever we need to use llm, we can easily call it before that line like\r\n`\r\nself.check_llm()\r\n`',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/884/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/884/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/883',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/883/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/883/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/883/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/883',
  'id': 2254476301,
  'node_id': 'PR_kwDOJgX1Gs5tPryT',
  'number': 883,
  'title': 'ref: _ascore method to remove redundancy',
  'user': {'login': 'iw4p',
   'id': 30632761,
   'node_id': 'MDQ6VXNlcjMwNjMyNzYx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/30632761?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/iw4p',
   'html_url': 'https: //github.com/iw4p',
   'followers_url': 'https: //api.github.com/users/iw4p/followers',
   'following_url': 'https: //api.github.com/users/iw4p/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/iw4p/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/iw4p/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/iw4p/subscriptions',
   'organizations_url': 'https: //api.github.com/users/iw4p/orgs',
   'repos_url': 'https: //api.github.com/users/iw4p/repos',
   'events_url': 'https: //api.github.com/users/iw4p/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/iw4p/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-20T09: 44: 14Z',
  'updated_at': '2024-04-20T09: 44: 14Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/883',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/883',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/883.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/883.patch',
   'merged_at': None
                  },
  'body': 'The original code has essentially the same process twice with minor changes. Extracting the shared operations into a loop eliminates this redundancy. This makes the code shorter and more maintainable.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/883/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/883/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/882',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/882/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/882/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/882/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/882',
  'id': 2254475429,
  'node_id': 'PR_kwDOJgX1Gs5tPrnJ',
  'number': 882,
  'title': 'doc: update docstring external Faithfulness methods',
  'user': {'login': 'iw4p',
   'id': 30632761,
   'node_id': 'MDQ6VXNlcjMwNjMyNzYx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/30632761?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/iw4p',
   'html_url': 'https: //github.com/iw4p',
   'followers_url': 'https: //api.github.com/users/iw4p/followers',
   'following_url': 'https: //api.github.com/users/iw4p/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/iw4p/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/iw4p/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/iw4p/subscriptions',
   'organizations_url': 'https: //api.github.com/users/iw4p/orgs',
   'repos_url': 'https: //api.github.com/users/iw4p/repos',
   'events_url': 'https: //api.github.com/users/iw4p/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/iw4p/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-20T09: 41: 43Z',
  'updated_at': '2024-04-23T05: 39: 27Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/882',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/882',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/882.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/882.patch',
   'merged_at': None
                  },
  'body': None,
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/882/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/882/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/880',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/880/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/880/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/880/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/880',
  'id': 2252595286,
  'node_id': 'PR_kwDOJgX1Gs5tJry-',
  'number': 880,
  'title': 'fix(testset): Ensure each document is used only once for question gen…',
  'user': {'login': 'princepride',
   'id': 29850264,
   'node_id': 'MDQ6VXNlcjI5ODUwMjY0',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/29850264?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/princepride',
   'html_url': 'https: //github.com/princepride',
   'followers_url': 'https: //api.github.com/users/princepride/followers',
   'following_url': 'https: //api.github.com/users/princepride/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/princepride/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/princepride/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/princepride/subscriptions',
   'organizations_url': 'https: //api.github.com/users/princepride/orgs',
   'repos_url': 'https: //api.github.com/users/princepride/repos',
   'events_url': 'https: //api.github.com/users/princepride/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/princepride/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 7,
  'created_at': '2024-04-19T10: 07: 03Z',
  'updated_at': '2024-05-21T05: 12: 07Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/880',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/880',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/880.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/880.patch',
   'merged_at': None
                  },
  'body': '…eration\r\n\r\nPreviously, the code used a nested loop to iterate over the distributions and generate questions for each document. However, this approach had a potential issue where a single document could be used multiple times for generating questions, leading to redundancy and inefficient usage of the available documents.\r\n\r\nTo address this issue, the code has been modified to use a cumulative approach for determining the range of documents assigned to each evolution type based on their probability distribution. The key changes include:\r\n\r\n1. Introduced a `start_index` variable to keep track of the starting document index for each evolution type.\r\n2. Calculated the `end_index` for each evolution type by adding the rounded value of `probability * test_size` to the `start_index`.\r\n3. Used an inner loop to iterate from `start_index` to `end_index` and submit tasks to the executor for each document within that range.\r\n4. Updated the `start_index` to `end_index` after processing each evolution type to ensure the next evolution type starts from the correct position.\r\n5. If `total_evolutions` is less than `test_size` after processing all evolution types, randomly selected evolution types to fill the remaining documents using the `choices` function.\r\n\r\nWith these modifications, each document is guaranteed to be used only once for question generation, avoiding redundancy and ensuring efficient utilization of the available documents. The cumulative probability approach ensures that the document ranges for different evolution types do not overlap, maintaining the desired probability distribution.\r\n\r\nThis fix improves the quality and diversity of the generated questions by preventing the repeated use of documents and ensuring a more balanced distribution of questions across the available documents.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/880/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/880/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/879',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/879/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/879/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/879/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/879',
  'id': 2252253114,
  'node_id': 'PR_kwDOJgX1Gs5tIjP4',
  'number': 879,
  'title': 'Update validation to allow for empty context lists',
  'user': {'login': 'LogicalShark',
   'id': 9994650,
   'node_id': 'MDQ6VXNlcjk5OTQ2NTA=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/9994650?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/LogicalShark',
   'html_url': 'https: //github.com/LogicalShark',
   'followers_url': 'https: //api.github.com/users/LogicalShark/followers',
   'following_url': 'https: //api.github.com/users/LogicalShark/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/LogicalShark/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/LogicalShark/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/LogicalShark/subscriptions',
   'organizations_url': 'https: //api.github.com/users/LogicalShark/orgs',
   'repos_url': 'https: //api.github.com/users/LogicalShark/repos',
   'events_url': 'https: //api.github.com/users/LogicalShark/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/LogicalShark/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-19T07: 14: 29Z',
  'updated_at': '2024-04-22T22: 49: 39Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/879',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/879',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/879.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/879.patch',
   'merged_at': None
                  },
  'body': 'When no strings are provided in the contexts during evaluation, the context feature\'s type in the dataset is the generic Sequence type rather than the expected Sequence[string
                  ], thus it fails validation with a ValueError, despite being a valid dataset.\r\n\r\nFor example, if retrieval uses an unrealistically high similarity score threshold, no contexts will be found, but the error message will be the unhelpful and irrelevant `ValueError: Dataset feature "contexts" should be of type Sequence[string
                  ], got <class \'datasets.features.features.Sequence\'>`.\r\n\r\nSee also https: //github.com/explodinggradients/ragas/issues/286',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/879/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/879/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/878',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/878/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/878/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/878/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/878',
  'id': 2252209793,
  'node_id': 'I_kwDOJgX1Gs6GPf6B',
  'number': 878,
  'title': '[R-232
                  ] Faithfullness metrics stability issue, non zero output for response with no statement',
  'user': {'login': 'mukuls-zeta',
   'id': 144680174,
   'node_id': 'U_kgDOCJ-k7g',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/144680174?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/mukuls-zeta',
   'html_url': 'https: //github.com/mukuls-zeta',
   'followers_url': 'https: //api.github.com/users/mukuls-zeta/followers',
   'following_url': 'https: //api.github.com/users/mukuls-zeta/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/mukuls-zeta/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/mukuls-zeta/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/mukuls-zeta/subscriptions',
   'organizations_url': 'https: //api.github.com/users/mukuls-zeta/orgs',
   'repos_url': 'https: //api.github.com/users/mukuls-zeta/repos',
   'events_url': 'https: //api.github.com/users/mukuls-zeta/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/mukuls-zeta/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-04-19T06: 47: 25Z',
  'updated_at': '2024-06-10T07: 24: 29Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nFaithfullness metrics is coming even if answer is "IDK", Ideally no statements can be generated from "IDK" (manually confirmed with using faithfullness prompt), but still faithfullness metrics is coming greater than zero, even in some cases coming 1.\r\nObserved the issue with the latest version which is  0.1.7.\r\n\r\nRagas version:  0.1.7\r\nPython version: 3.10.9\r\n\r\n**Code to Reproduce**\r\n```python\r\n\r\nimport ragas\r\nfrom ragas.metrics import (\r\n    faithfulness,\r\n    answer_relevancy,\r\n    context_precision,\r\n    context_recall,\r\n    context_relevancy,\r\n    answer_correctness\r\n)\r\n\r\nfrom datasets import Dataset \r\nfrom ragas import evaluate\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\nmetrics = [ faithfulness,\r\n    answer_relevancy,\r\n    context_precision,\r\n    context_recall,\r\n    context_relevancy,\r\n    answer_correctness]\r\n\r\nembed_model =  OpenAIEmbeddings(model="text-embedding-3-small")\r\n\r\ndata_samples = {\r\n            \'question\': df_res[query_col].to_list(),\r\n            \'answer\': df_res.rag_answer.to_list(),\r\n            \'contexts\' : df_res.context.to_list(), \r\n            \'ground_truth\': df_res[truth_ans_col].to_list()\r\n        }\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nscore = evaluate(dataset, metrics=metrics,\r\n                        embeddings=embed_model)\r\nscore.to_pandas()\r\n```\r\n\r\nSample OUTPUT -\r\n<google-sheets-html-origin><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}-->\r\nquestion | answer | contexts | faithfulness | answer_relevancy | answer_correctness\r\n-- | -- | -- | -- | -- | --\r\nWhat is the impact of foreign exchange rates o... | IDK | [Service sales primarily represent third-party... | 0.952611 | NaN | 0\r\nWhat did Microsoft report as its net cash from... | IDK | [PART I\\nItem 1\\n \\nSegment revenue and operat... | 0.847241 | NaN | 0\r\nWere there any significant acquisitions or div... | IDK | [To mitigate credit risk, the Company generall... | 0.823912 | NaN | 0\r\nHas Microsoft announced any major new company ... | IDK | [ \\nExhibit 15.1 \\nApril 25, 2023\\nThe Board o... | 0.689186 | NaN | 0\r\nHow does Amazon\'s R&D expenditure in the most ... | IDK | [Changes in foreign exchange rates negatively ... | 0.67289 | NaN | 0\r\n\r\n\r\n\r\n\r\n**Error trace**\r\n\r\n**Expected behavior**\r\nFaithfullness metics should come NaN or 0.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n\n\n<sub>[R-232](https://linear.app/exploding-gradients/issue/R-232/faithfullness-metrics-stability-issue-non-zero-output-for-response)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/878/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/878/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/871',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/871/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/871/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/871/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/871',
  'id': 2244185782,
  'node_id': 'I_kwDOJgX1Gs6Fw462',
  'number': 871,
  'title': '[R-235
                  ] Testset generation. ValueError: a cannot be empty unless no samples are taken - Not use adaptor',
  'user': {'login': 'JPonsa',
   'id': 28976175,
   'node_id': 'MDQ6VXNlcjI4OTc2MTc1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/28976175?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/JPonsa',
   'html_url': 'https: //github.com/JPonsa',
   'followers_url': 'https: //api.github.com/users/JPonsa/followers',
   'following_url': 'https: //api.github.com/users/JPonsa/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/JPonsa/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/JPonsa/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/JPonsa/subscriptions',
   'organizations_url': 'https: //api.github.com/users/JPonsa/orgs',
   'repos_url': 'https: //api.github.com/users/JPonsa/repos',
   'events_url': 'https: //api.github.com/users/JPonsa/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/JPonsa/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 14,
  'created_at': '2024-04-15T16: 55: 47Z',
  'updated_at': '2024-08-15T12: 11: 51Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Testing it with a single small document splitter in 5 chuncks. Repeating the test with 2 documents. To see if that could be the issue. This could be related to issue below but I am not using adaptor. My text is in English generated using langchain\'s RecursiveJsonSplitter\r\n\r\nhttps: //github.com/explodinggradients/ragas/issues/625 \r\n\r\nusing ragas 0.1.7 on a linux machine.\r\n```python\r\n   eval_ds = generator.generate_with_langchain_docs(\r\n        docs,\r\n        test_size=5,\r\n        distributions={simple: 0.4, reasoning: 0.4, multi_context: 0.2},\r\n    )\r\n```\r\n\r\n```\r\nFilename and doc_id are the same for all nodes.\r\nTraceback (most recent call last):\r\n  File "/lustre/scratch/scratch/rmhijpo/ctgov_rag/./src/evaluation/RAGAS.py", line 191, in <module>\r\n    main(args)\r\n  File "/lustre/scratch/scratch/rmhijpo/ctgov_rag/./src/evaluation/RAGAS.py", line 97, in main\r\n    eval_ds = generator.generate_with_langchain_docs(\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/lustre/scratch/scratch/rmhijpo/ctgov_rag/.venv/lib/python3.11/site-packages/ragas/testset/generator.py", line 179, in generate_with_langchain_docs\r\n    return self.generate(\r\n           ^^^^^^^^^^^^^^\r\n  File "/lustre/scratch/scratch/rmhijpo/ctgov_rag/.venv/lib/python3.11/site-packages/ragas/testset/generator.py", line 248, in generate\r\n    for n in self.docstore.get_random_nodes(k=test_size)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "/lustre/scratch/scratch/rmhijpo/ctgov_rag/.venv/lib/python3.11/site-packages/ragas/testset/docstore.py", line 328, in get_random_nodes\r\n    nodes = rng.choice(np.array(self.nodes), size=k, p=prob).tolist()\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File "numpy/random/_generator.pyx", line 803, in numpy.random._generator.Generator.choice\r\nValueError: a cannot be empty unless no samples are taken\r\n```\r\n\n\n<sub>[R-235](https://linear.app/exploding-gradients/issue/R-235/testset-generation-valueerror-a-cannot-be-empty-unless-no-samples-are)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/871/reactions',
   'total_count': 2,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 2,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/871/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/870',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/870/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/870/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/870/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/870',
  'id': 2243640286,
  'node_id': 'I_kwDOJgX1Gs6Fuzve',
  'number': 870,
  'title': '[R-234
                  ] docs: update and fix documentation',
  'user': {'login': 'mancaldel',
   'id': 10613385,
   'node_id': 'MDQ6VXNlcjEwNjEzMzg1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/10613385?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/mancaldel',
   'html_url': 'https: //github.com/mancaldel',
   'followers_url': 'https: //api.github.com/users/mancaldel/followers',
   'following_url': 'https: //api.github.com/users/mancaldel/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/mancaldel/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/mancaldel/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/mancaldel/subscriptions',
   'organizations_url': 'https: //api.github.com/users/mancaldel/orgs',
   'repos_url': 'https: //api.github.com/users/mancaldel/repos',
   'events_url': 'https: //api.github.com/users/mancaldel/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/mancaldel/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-15T13: 07: 34Z',
  'updated_at': '2024-06-10T07: 27: 31Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Some of the pages in the documentation are out of date or incorrect and it make it difficult to have a general idea about the capabilities of the library. Here are a few examples:\r\n- [References/Metrics
                  ](https: //docs.ragas.io/en/stable/references/metrics.html): the summary at the beginning does not include all implemented metrics, missing 4/10 (AspectCritique, ContextRelevancy, ContextUtilization, Faithfulness). Also, there is no info about the definition of the last metrics in the list.\r\n- [Concepts/metrics](https://docs.ragas.io/en/stable/concepts/metrics/index.html#ragas-metrics): also missing some metrics, 2/10 in the page (AspectCritique, ContextUtilization), and 1/10 in the side bar (ContextUtilization)\r\n- [Integrations](https://docs.ragas.io/en/stable/references/integrations/index.html): friendly reminder that the page is empty.\r\n\r\nThanks!\n\n<sub>[R-234](https://linear.app/exploding-gradients/issue/R-234/docs-update-and-fix-documentation)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/870/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/870/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/868',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/868/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/868/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/868/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/868',
  'id': 2241063034,
  'node_id': 'I_kwDOJgX1Gs6Fk-h6',
  'number': 868,
  'title': '[R-236
                  ] testset hard negatives',
  'user': {'login': 'PrathamSoni',
   'id': 20586632,
   'node_id': 'MDQ6VXNlcjIwNTg2NjMy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/20586632?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/PrathamSoni',
   'html_url': 'https: //github.com/PrathamSoni',
   'followers_url': 'https: //api.github.com/users/PrathamSoni/followers',
   'following_url': 'https: //api.github.com/users/PrathamSoni/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/PrathamSoni/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/PrathamSoni/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/PrathamSoni/subscriptions',
   'organizations_url': 'https: //api.github.com/users/PrathamSoni/orgs',
   'repos_url': 'https: //api.github.com/users/PrathamSoni/repos',
   'events_url': 'https: //api.github.com/users/PrathamSoni/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/PrathamSoni/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-04-12T22: 25: 35Z',
  'updated_at': '2024-06-23T06: 15: 38Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nUse similarity to also give similar nodes for a given node so each question has a set of hard negatives against it\r\n\r\n**Why is the feature important for you?**\r\nImprove dataset.\r\n\r\n**Additional context**\r\nN/A\r\n\r\n\n\n<sub>[R-236
                  ](https: //linear.app/exploding-gradients/issue/R-236/testset-hard-negatives)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/868/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/868/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/866',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/866/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/866/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/866/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/866',
  'id': 2239956642,
  'node_id': 'I_kwDOJgX1Gs6Fgwai',
  'number': 866,
  'title': 'Ragas Synthetic Test Data Generation error using AzureOpenaiEmbeddings',
  'user': {'login': 'sona-16',
   'id': 120117215,
   'node_id': 'U_kgDOByjX3w',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/120117215?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/sona-16',
   'html_url': 'https: //github.com/sona-16',
   'followers_url': 'https: //api.github.com/users/sona-16/followers',
   'following_url': 'https: //api.github.com/users/sona-16/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/sona-16/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/sona-16/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/sona-16/subscriptions',
   'organizations_url': 'https: //api.github.com/users/sona-16/orgs',
   'repos_url': 'https: //api.github.com/users/sona-16/repos',
   'events_url': 'https: //api.github.com/users/sona-16/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/sona-16/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 6,
  'created_at': '2024-04-12T11: 44: 16Z',
  'updated_at': '2024-05-30T07: 00: 35Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I was trying to do "test generation" using RAGAS framework with the help of the "https://docs.ragas.io/en/stable/concepts/testset_generation.html", I\'m facing error. \r\n\r\nPlease have a look on the below error. \r\n\r\nragas.exceptions.ExceptionInRunner: The runner thread which was running the jobs raised an exeception. Read the traceback above to debug it. You can also pass `raise_exceptions=False` incase you want to show only a warning message instead.\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-3\' coro=<as_completed.<locals>.sema_coro() running at C:\\Users\\sonaganesh.g\\Desktop\\RAGAS syhthetic data generation\\syn\\Lib\\sit\r\ne-packages\\ragas\\executor.py: 38> wait_for=<Future pending cb=[Task.task_wakeup()
                  ]> cb=[as_completed.<locals>._on_completion() at C:\\Users\\sonaganesh.g\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py: 618
                  ]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-5\' coro=<as_completed.<locals>.sema_coro() running at C:\\Users\\sonaganesh.g\\Desktop\\RAGAS syhthetic data generation\\syn\\Lib\\sit\r\ne-packages\\ragas\\executor.py: 38> wait_for=<_GatheringFuture pending cb=[Task.task_wakeup()
                  ]> cb=[as_completed.<locals>._on_completion() at C:\\Users\\sonaganesh.g\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py: 618
                  ]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'Task-2\' coro=<as_completed.<locals>.sema_coro() running at C:\\Users\\sonaganesh.g\\Desktop\\RAGAS syhthetic data generation\\syn\\Lib\\site-packages\\ragas\\executor.py: 38> wait_for=<Future pending cb=[Task.task_wakeup()
                  ]> cb=[as_completed.<locals>._on_completion() at C:\\Users\\sonaganesh.g\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py: 618
                  ]>\r\n\r\nAnd my code is: \r\n\r\nloader = PyPDFLoader("<some documnet> .pdf")\r\ndocuments = loader.load()\r\n\r\n#used same LLM for both generator_lmm and critic_llm\r\ngenerator_llm = llm()\r\ncritic_llm = llm() \r\nembeddings =embeddings() # used AzureOpenaiEmbeddings\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\ndistributions = {\r\n    simple: 0.5,\r\n    multi_context: 0.4,\r\n    reasoning: 0.1\r\n
                  }\r\n\r\n\r\ntestset = generator.generate_with_langchain_docs(documents,
                  10, distributions)\r\ntestset.to_pandas()\r\n\r\nversions:\r\nopenai - 1.17.0\r\nragas - 0.1.4/ 0.1.6',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/866/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/866/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/865',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/865/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/865/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/865/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/865',
  'id': 2238938838,
  'node_id': 'I_kwDOJgX1Gs6Fc37W',
  'number': 865,
  'title': "[R-237] ValueError: Unknown format code 'f' for object of type 'str'",
  'user': {'login': 'satadda',
   'id': 159094501,
   'node_id': 'U_kgDOCXuW5Q',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/159094501?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/satadda',
   'html_url': 'https: //github.com/satadda',
   'followers_url': 'https: //api.github.com/users/satadda/followers',
   'following_url': 'https: //api.github.com/users/satadda/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/satadda/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/satadda/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/satadda/subscriptions',
   'organizations_url': 'https: //api.github.com/users/satadda/orgs',
   'repos_url': 'https: //api.github.com/users/satadda/repos',
   'events_url': 'https: //api.github.com/users/satadda/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/satadda/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-12T02: 46: 37Z',
  'updated_at': '2024-06-10T07: 27: 43Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[X
                  ] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nValueError: Unknown format code \'f\' for object of type \'str\'\r\n\r\nRagas version: 0.1.7\r\nPython version: 3.10\r\n\r\n**Code to Reproduce**\r\n\r\n```\r\n\r\n    metrics = [\r\n            answer_relevancy,\r\n            answer_correctness,\r\n            answer_similarity,\r\n            context_recall,\r\n            context_precision,\r\n            context_relevancy, \r\n        ]\r\n\r\n       for question in test_questions:\r\n            response = rag_chain.invoke({"question" : question})\r\n            answers.append(response["answer"].content)\r\n            contexts.append([context.page_content for context in response[\'docs\']])\r\n\r\n        # create hf dataset\r\n        response_dataset = Dataset.from_dict({\r\n            "question" : test_questions,\r\n            "answer" : answers,\r\n            "contexts" : contexts,\r\n            "ground_truth" : test_groundtruths\r\n        })\r\n\r\n        print("sample response: ")\r\n        print(response_dataset[0])\r\n\r\n        results = evaluate(response_dataset, metrics, \r\n                           llm=llm, embeddings = openai_embed,\r\n                           raise_exceptions=False,\r\n                           )\r\n        print(results)\r\n\r\n```\r\n\r\n\r\n**Error trace**\r\n```\r\n  File "/home/asrst/.cache/pypoetry/virtualenvs/llm-NDDKoWLm-py3.10/lib/python3.10/site-packages/ragas/evaluation.py", line 292, in __repr__\r\n    score_strs = [f"\'{k}\': {v:0.4f}" for k, v in scores.items()]\r\n  File "/home/asrst/.cache/pypoetry/virtualenvs/llm-NDDKoWLm-py3.10/lib/python3.10/site-packages/ragas/evaluation.py", line 292, in <listcomp>\r\n    score_strs = [f"\'{k}\': {v:0.4f}" for k, v in scores.items()]\r\nValueError: Unknown format code \'f\' for object of type \'str\'\r\n\r\n```\r\n**Expected behavior**\r\n\r\noutput metrics (python dictonary)\r\n\r\n**Additional context**\r\nthis usually can happen when `v` is a string instead of float. But in what cases ragas returns a string value for `v` in scores.items() ? Ideally it should be numeric for any metric.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n\n\n<sub>[R-237](https://linear.app/exploding-gradients/issue/R-237/valueerror-unknown-format-code-f-for-object-of-type-str)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/865/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/865/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/864',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/864/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/864/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/864/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/864',
  'id': 2238910176,
  'node_id': 'I_kwDOJgX1Gs6Fcw7g',
  'number': 864,
  'title': '[R-238
                  ] Answer relevance metrics does not require embedding match if answer is non-commital',
  'user': {'login': 'rajib76',
   'id': 16340036,
   'node_id': 'MDQ6VXNlcjE2MzQwMDM2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/16340036?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/rajib76',
   'html_url': 'https: //github.com/rajib76',
   'followers_url': 'https: //api.github.com/users/rajib76/followers',
   'following_url': 'https: //api.github.com/users/rajib76/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/rajib76/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/rajib76/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/rajib76/subscriptions',
   'organizations_url': 'https: //api.github.com/users/rajib76/orgs',
   'repos_url': 'https: //api.github.com/users/rajib76/repos',
   'events_url': 'https: //api.github.com/users/rajib76/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/rajib76/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 4,
  'created_at': '2024-04-12T02: 17: 03Z',
  'updated_at': '2024-06-10T07: 28: 01Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nThe answer relevance metrics multiplies the cosine similarity with noncommittal. So, if we check the answer is noncommittal, we do not need to call the embedding model\r\n\r\n**Why is the feature important for you?**\r\nIt will improve the performance of the metrics\r\n\r\n**Additional context**\r\nNone\r\n\r\n<!-- PS: Thanks for your valuable feedback. Really! Its feedback from valuable community members like you that help us make Ragas event better for the whole community. So thanks again for taking the time to improve our community 🙂 -->\r\n\n\n<sub>[R-238
                  ](https: //linear.app/exploding-gradients/issue/R-238/answer-relevance-metrics-does-not-require-embedding-match-if-answer-is)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/864/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/864/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/860',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/860/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/860/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/860/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/860',
  'id': 2237264570,
  'node_id': 'I_kwDOJgX1Gs6FWfK6',
  'number': 860,
  'title': '[R-239
                  ] Why the later parts testset will never be accessed?',
  'user': {'login': 'princepride',
   'id': 29850264,
   'node_id': 'MDQ6VXNlcjI5ODUwMjY0',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/29850264?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/princepride',
   'html_url': 'https: //github.com/princepride',
   'followers_url': 'https: //api.github.com/users/princepride/followers',
   'following_url': 'https: //api.github.com/users/princepride/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/princepride/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/princepride/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/princepride/subscriptions',
   'organizations_url': 'https: //api.github.com/users/princepride/orgs',
   'repos_url': 'https: //api.github.com/users/princepride/repos',
   'events_url': 'https: //api.github.com/users/princepride/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/princepride/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-04-11T09: 11: 02Z',
  'updated_at': '2024-06-10T07: 28: 15Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'The code in testset/generator.py make me confused:\r\n```py\r\ncurrent_nodes = [\r\n            CurrentNodes(root_node=n, nodes=[n
                        ])\r\n            for n in self.docstore.get_random_nodes(k=test_size)\r\n
                  ]\r\n        total_evolutions = 0\r\n        for evolution, probability in distributions.items():\r\n            for i in range(round(probability * test_size)):\r\n                exec.submit(\r\n                    evolution.evolve,\r\n                    current_nodes[i
                  ],\r\n                    name=f"{evolution.__class__.__name__}-{i}",\r\n                )\r\n                total_evolutions += 1\r\n```\r\n**Your Question**\r\nAssuming that in the code, the current_nodes index range generated according to each distribution probability traversal will be concentrated in the front part of the current_nodes list, and the later parts will never be accessed?\r\n\r\n**Code Examples**\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\ngenerator_llm = ChatOpenAI(model="gpt-3.5-turbo-16k")\r\ncritic_llm = ChatOpenAI(model="gpt-4")\r\nembeddings = OpenAIEmbeddings()\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.3, multi_context: 0.2
                  })\r\n\r\nUsing the sample code from Ragas documents, the simple testset will use the No. 1-5 random selected documents, the reasoning testset will use the No. 1-3 random selected documents, the multi_context testset will use the No. 1-2 random selected documents. The No. 6-10 documents will never be used.\r\n\n\n<sub>[R-239
                  ](https: //linear.app/exploding-gradients/issue/R-239/why-the-later-parts-testset-will-never-be-accessed)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/860/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/860/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/859',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/859/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/859/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/859/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/859',
  'id': 2237039962,
  'node_id': 'I_kwDOJgX1Gs6FVoVa',
  'number': 859,
  'title': '[R-240
                  ] (docs): Document how to evaluating with a locally hosted LLM to help choose the ones that work best',
  'user': {'login': 'Exploding-squid',
   'id': 166690774,
   'node_id': 'U_kgDOCe9_1g',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/166690774?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Exploding-squid',
   'html_url': 'https: //github.com/Exploding-squid',
   'followers_url': 'https: //api.github.com/users/Exploding-squid/followers',
   'following_url': 'https: //api.github.com/users/Exploding-squid/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Exploding-squid/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Exploding-squid/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Exploding-squid/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Exploding-squid/orgs',
   'repos_url': 'https: //api.github.com/users/Exploding-squid/repos',
   'events_url': 'https: //api.github.com/users/Exploding-squid/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Exploding-squid/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 9,
  'created_at': '2024-04-11T06: 58: 24Z',
  'updated_at': '2024-08-05T18: 56: 42Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[X
                  ] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\n\n**Describe the bug**\nI have a locally hosted LLM which I am intending to use as a judge LLM. When using a simple test dataset, it appears that the LLM scores for Faithfulness are not correctly evaluated.\n\nI am using a self-hosted version of Zephyr-7B downloaded from Hugging Face, in addition to all-MiniLM-V2 as my Sentence Transformers model\n\nRagas version: 1.16\nPython version: 3.8\n\n**Code to Reproduce**\n\n\nfrom langchain_core.embeddings import Embeddings\n\nfrom ragas.llms.base import LangchainLLMWrapper\n\nfrom ragas.embeddings.base import LangchainEmbeddingsWrapper\n\nimport numpy as np\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\nfrom ragas.llms import BaseRagasLLM\n\nfrom langchain_community.llms import HuggingFacePipeline\n\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\n\nfrom datasets import load_dataset, Dataset\n\nfrom transformers import GenerationConfig\n\n\xa0\n\npipe = pipeline(task="text-generation", model="path/to/LLM",\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 torch_dtype=torch.bfloat16, device_map="auto", max_new_tokens=2000)\n\nhf = HuggingFacePipeline(pipeline=pipe)\n\n\nllm = LangchainLLMWrapper(hf)\n\n\nmodel_name = "/path/to/sentencetransformers/model"\n\nmodel_kwargs = {\'device\': \'cpu\'}\n\nencode_kwargs = {\'normalize_embeddings\': False}\n\nhf_e = HuggingFaceEmbeddings(\n\n\xa0\xa0\xa0 model_name=model_name,\n\n\xa0\xa0\xa0 model_kwargs=model_kwargs,\n\n\xa0\xa0\xa0 encode_kwargs=encode_kwargs\n\n)\n\nembedder = LangchainEmbeddingsWrapper(hf_e)\n\nprint("llm loaded")\n\nfrom ragas import evaluate\n\n\xa0\n\ntest_data = {\n\n\xa0\xa0\xa0 \'question\': [\'What is the capital of France?\', \'Who wrote "Romeo and Juliet"?\'],\n\n\xa0\xa0\xa0 \'contexts\': [[\'Bananas are an excellent source of potassium\', \'France is known for its cuisine.\', \'Data is more valulable than oil\'],\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 [\'William Shakespeare wrote "Romeo and Juliet".\', \'The play is a tragedy.\']],\n\n\xa0\xa0\xa0 \'answer\': [\'Paris\', \'William Shakespeare\'],\n\n\xa0\xa0\xa0 \'ground_truth\': [\'Paris\', \'William Shakespeare\']\n\n}\n\n\xa0\n\ndataset_eval=Dataset.from_dict(test_data)\n\n\xa0\n\nfrom ragas.metrics import (\n\n\xa0\xa0\xa0 answer_relevancy,\n\n\xa0\xa0\xa0 answer_similarity,\n\n\xa0\xa0\xa0 answer_correctness,\n\n\xa0\xa0\xa0 faithfulness,\n\n\xa0\xa0\xa0 context_recall,\n\n\xa0\xa0\xa0 context_precision,\n\n\xa0\xa0\xa0 context_relevancy,\n\n)\n\nstart_time = time.time()\n\n\xa0\n\nresults = evaluate(dataset_eval,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 metrics=[answer_similarity,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 answer_relevancy,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 answer_correctness,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 faithfulness,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 context_recall,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 context_precision,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 context_relevancy,\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ],\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 llm=llm, embeddings=embedder)\n\n\xa0\n\nprint(results)\n\n\xa0\n\nfinish_time = time.time()\n\n\xa0\n\nprint(f"time elapsed (minutes) = {(finish_time-start_time)/60}")\n\n\n\n**Error trace**\n\nLoading checkpoint shards: 100%|██████████| 8/8 [00:59<00:00,  7.40s/it]\r\nllm loaded\r\nEvaluating:   0%|          | 0/14 [00:00<?, ?it/s]/home/venv/lib64/python3.8/site-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\r\n  warnings.warn(\r\n/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nEvaluating:   7%|▋         | 1/14 [00:00<00:10,  1.24it/s]/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nEvaluating:  21%|██▏       | 3/14 [01:57<07:56, 43.34s/it]/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\n/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nEvaluating:  29%|██▊       | 4/14 [20:32<1:09:01, 414.16s/it]/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nEvaluating:  36%|███▌      | 5/14 [20:33<41:36, 277.40s/it]  /home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nEvaluating:  43%|████▎     | 6/14 [20:34<25:10, 188.85s/it]/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nEvaluating:  50%|█████     | 7/14 [20:34<15:06, 129.52s/it]/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\n/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nFailed to parse output. Returning None.\r\nEvaluating:  57%|█████▋    | 8/14 [23:57<15:14, 152.39s/it]Failed to parse output. Returning None.\r\n/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nEvaluating:  64%|██████▍   | 9/14 [33:41<23:43, 284.74s/it]Failed to parse output. Returning None.\r\nEvaluating:  71%|███████▏  | 10/14 [33:50<13:22, 200.63s/it]Failed to parse output. Returning None.\r\nEvaluating:  79%|███████▊  | 11/14 [33:51<07:00, 140.07s/it]Failed to parse output. Returning None.\r\n/home/venv/lib64/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\r\n  warnings.warn(\r\nFailed to parse output. Returning None.\r\nEvaluating: 100%|██████████| 14/14 [38:50<00:00, 166.48s/it]\n\n\r\n/home/venv/lib64/python3.8/site-packages/ragas/evaluation.py:276: RuntimeWarning: Mean of empty slice\r\n  value = np.nanmean(self.scores[cn])\r\n{\'answer_similarity\': 1.0000, \'answer_relevancy\': 0.5079, \'answer_correctness\': 0.6500, \'faithfulness\': nan, \'context_recall\': 0.0000, \'context_precision\': 0.0000, \'context_relevancy\': 1.0000}\r\ntime elapsed (minutes) = 38.91461242834727\r\n\n\n\n**Expected behavior**\n\nFaithfulness should return a number.\n\nI am also unsure if Context Recall and Context Precision are correctly evaluated here\n\n\n**Additional context**\nAdd any other context about the problem here.\n\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\n\n\n<sub>[R-240](https://linear.app/exploding-gradients/issue/R-240/docs-document-how-to-evaluating-with-a-locally-hosted-llm-to-help)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/859/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/859/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/857',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/857/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/857/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/857/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/857',
  'id': 2235484753,
  'node_id': 'PR_kwDOJgX1Gs5sPX6e',
  'number': 857,
  'title': 'Update prompt.py for french adaptation',
  'user': {'login': 'adrienB134',
   'id': 102990337,
   'node_id': 'U_kgDOBiOCAQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/102990337?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/adrienB134',
   'html_url': 'https: //github.com/adrienB134',
   'followers_url': 'https: //api.github.com/users/adrienB134/followers',
   'following_url': 'https: //api.github.com/users/adrienB134/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/adrienB134/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/adrienB134/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/adrienB134/subscriptions',
   'organizations_url': 'https: //api.github.com/users/adrienB134/orgs',
   'repos_url': 'https: //api.github.com/users/adrienB134/repos',
   'events_url': 'https: //api.github.com/users/adrienB134/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/adrienB134/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-10T12: 30: 36Z',
  'updated_at': '2024-04-16T23: 39: 06Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/857',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/857',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/857.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/857.patch',
   'merged_at': None
                  },
  'body': 'I was running into the same issue as here [#774
                  ](https: //github.com/explodinggradients/ragas/issues/774), so  I used his solution and added a set of french examples to the translation prompt.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/857/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/857/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/855',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/855/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/855/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/855/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/855',
  'id': 2233318613,
  'node_id': 'I_kwDOJgX1Gs6FHbzV',
  'number': 855,
  'title': '[R-246
                  ] Could it be a mistake in the prompts?',
  'user': {'login': 'cemsoyleyici',
   'id': 102302902,
   'node_id': 'U_kgDOBhkEtg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/102302902?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/cemsoyleyici',
   'html_url': 'https: //github.com/cemsoyleyici',
   'followers_url': 'https: //api.github.com/users/cemsoyleyici/followers',
   'following_url': 'https: //api.github.com/users/cemsoyleyici/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/cemsoyleyici/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/cemsoyleyici/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/cemsoyleyici/subscriptions',
   'organizations_url': 'https: //api.github.com/users/cemsoyleyici/orgs',
   'repos_url': 'https: //api.github.com/users/cemsoyleyici/repos',
   'events_url': 'https: //api.github.com/users/cemsoyleyici/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/cemsoyleyici/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                        ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
                  },
  'comments': 1,
  'created_at': '2024-04-09T12: 21: 58Z',
  'updated_at': '2024-09-02T07: 06: 47Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Hello,\r\n\r\nI assume that there is a minor mistake in find_relevant_context_prompt under the testset/prompt.py. \r\n\r\nrelevant contexts seem not right to me. Is it possible to be?\r\nThe first one is "relevant_contexts": [
                        1,
                        2,
                        3
                  ],\r\nThe second one is "relevant_contexts": [
                        1,
                        3
                  ],\r\n\r\nAlso, filter_question_prompt might need to be checked.\r\n\r\nThank you for your time.\r\n```py\r\nfind_relevant_context_prompt = Prompt(\r\n    name="find_relevant_context",\r\n    instruction="Given a question and set of contexts, find the most relevant contexts to answer the question.",\r\n    examples=[\r\n        {\r\n            "question": "What is the capital of France?",\r\n            "contexts": [\r\n                "1. France is a country in Western Europe. It has several cities, including Paris, Lyon, and Marseille. Paris is not only known for its cultural landmarks like the Eiffel Tower and the Louvre Museum but also as the administrative center.",\r\n                "2. The capital of France is Paris. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.",\r\n                "3. Paris is the capital of France. It is also the most populous city in France, with a population of over 2 million people. Paris is known for its cultural landmarks like the Eiffel Tower and the Louvre Museum.",\r\n
                              ],\r\n            **"output": {\r\n                "relevant_contexts": [
                                          1,
                                          2
                                    ],**\r\n
                              },\r\n
                        },\r\n        {\r\n            "question": "How does caffeine affect the body and what are its common sources?",\r\n            "contexts": [\r\n                "1. Caffeine is a central nervous system stimulant. It can temporarily ward off drowsiness and restore alertness. It primarily affects the brain, where it alters the function of neurotransmitters.",\r\n                "2. Regular physical activity is essential for maintaining good health. It can help control weight, combat health conditions, boost energy, and promote better sleep.",\r\n                "3. Common sources of caffeine include coffee, tea, cola, and energy drinks. These beverages are consumed worldwide and are known for providing a quick boost of energy.",\r\n
                              ],\r\n            **"output": {
                                    "relevant_contexts": [
                                          1,
                                          2
                                    ]
                              },**\r\n
                        },\r\n
                  ],\r\n    input_keys=[
                        "question",
                        "contexts"
                  ],\r\n    output_key="output",\r\n    output_type="json",\r\n    language="english",\r\n)\r\n\r\n```\n\n<sub>[R-246
                  ](https: //linear.app/exploding-gradients/issue/R-246/could-it-be-a-mistake-in-the-prompts)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/855/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/855/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/851',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/851/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/851/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/851/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/851',
  'id': 2231375463,
  'node_id': 'I_kwDOJgX1Gs6FABZn',
  'number': 851,
  'title': '[R-242
                  ] trouble in importing pydantic_output_parser from langchain',
  'user': {'login': 'kluskaj',
   'id': 11367352,
   'node_id': 'MDQ6VXNlcjExMzY3MzUy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/11367352?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/kluskaj',
   'html_url': 'https: //github.com/kluskaj',
   'followers_url': 'https: //api.github.com/users/kluskaj/followers',
   'following_url': 'https: //api.github.com/users/kluskaj/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/kluskaj/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/kluskaj/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/kluskaj/subscriptions',
   'organizations_url': 'https: //api.github.com/users/kluskaj/orgs',
   'repos_url': 'https: //api.github.com/users/kluskaj/repos',
   'events_url': 'https: //api.github.com/users/kluskaj/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/kluskaj/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20',
   'html_url': 'https: //github.com/explodinggradients/ragas/milestone/20',
   'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/milestones/20/labels',
   'id': 11527005,
   'node_id': 'MI_kwDOJgX1Gs4Ar-Nd',
   'number': 20,
   'title': 'v.19',
   'description': 'undefined\n\n> From [SyncLinear.com
                        ](https: //synclinear.com)',
   'creator': {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        },
   'open_issues': 11,
   'closed_issues': 0,
   'state': 'open',
   'created_at': '2024-09-02T07: 06: 42Z',
   'updated_at': '2024-09-02T07: 06: 53Z',
   'due_on': '2024-09-09T07: 00: 00Z',
   'closed_at': None
                  },
  'comments': 9,
  'created_at': '2024-04-08T14: 29: 29Z',
  'updated_at': '2024-09-02T07: 06: 42Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\nOnce ragas is installed I want to import it and I got an error on the import of pydantic output parser from langchain.\r\nRagas version: 0.1.6\r\nPython version: 3.10\r\nLangChain version: 0.1.14\r\n\r\n**Code to Reproduce**\r\n`import ragas`\r\n\r\n**Error trace**\r\n`---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nCell In[
                        6
                  ], line 1\r\n----> 1 import ragas\r\n\r\nFile /anaconda/envs/azureml_py310_langchain/lib/python3.10/site-packages/ragas/__init__.py: 1\r\n----> 1 from ragas.adaptation import adapt\r\n      2 from ragas.evaluation import evaluate\r\n      3 from ragas.run_config import RunConfig\r\n\r\nFile /anaconda/envs/azureml_py310_langchain/lib/python3.10/site-packages/ragas/adaptation.py: 7\r\n      5 from ragas.llms import llm_factory\r\n      6 from ragas.llms.base import BaseRagasLLM, LangchainLLMWrapper\r\n----> 7 from ragas.metrics.base import MetricWithLLM\r\n     10 def adapt(\r\n     11     metrics: t.List[MetricWithLLM
                  ],\r\n     12     language: str,\r\n     13     llm: t.Optional[BaseRagasLLM
                  ] = None,\r\n     14     cache_dir: t.Optional[str
                  ] = None,\r\n     15 ) -> None:\r\n     16     """\r\n     17     Adapt the metric to a different language.\r\n     18     """\r\n\r\nFile /anaconda/envs/azureml_py310_langchain/lib/python3.10/site-packages/ragas/metrics/__init__.py: 1\r\n----> 1 from ragas.metrics._answer_correctness import AnswerCorrectness, answer_correctness\r\n      2 from ragas.metrics._answer_relevance import AnswerRelevancy, answer_relevancy\r\n      3 from ragas.metrics._answer_similarity import AnswerSimilarity, answer_similarity\r\n\r\nFile /anaconda/envs/azureml_py310_langchain/lib/python3.10/site-packages/ragas/metrics/_answer_correctness.py: 10\r\n      7 import numpy as np\r\n      8 from langchain_core.pydantic_v1 import BaseModel\r\n---> 10 from ragas.llms.output_parser import RagasoutputParser, get_json_format_instructions\r\n     11 from ragas.llms.prompt import Prompt\r\n     12 from ragas.metrics._answer_similarity import AnswerSimilarity\r\n\r\nFile /anaconda/envs/azureml_py310_langchain/lib/python3.10/site-packages/ragas/llms/output_parser.py: 6\r\n      3 import typing as t\r\n      5 from langchain_core.exceptions import OutputParserException\r\n----> 6 from langchain_core.output_parsers import PydanticOutputParser\r\n      7 from langchain_core.pydantic_v1 import BaseModel\r\n      9 from ragas.llms import BaseRagasLLM\r\n\r\nImportError: cannot import name \'PydanticOutputParser\' from \'langchain_core.output_parsers\' (/anaconda/envs/azureml_py310_langchain/lib/python3.10/site-packages/langchain_core/output_parsers/__init__.py)`\r\n\r\n**Expected behavior**\r\nI expect the import to be without any errors. A quick fix would be to change the import in the file: ragas/tree/main/src/ragas/llms/output_parser.py\r\nfrom \r\n`from langchain_core.output_parsers import PydanticOutputParser`\r\nto\r\n`from langchain.output_parsers import PydanticOutputParser`\r\n\n\n<sub>[R-242
                  ](https: //linear.app/exploding-gradients/issue/R-242/trouble-in-importing-pydantic-output-parser-from-langchain)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/851/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/851/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/850',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/850/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/850/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/850/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/850',
  'id': 2230575469,
  'node_id': 'I_kwDOJgX1Gs6E8-Ft',
  'number': 850,
  'title': '[R-243
                  ] docs: Add documentation on the best approach to define custom metrics.',
  'user': {'login': 'ouphi',
   'id': 17216799,
   'node_id': 'MDQ6VXNlcjE3MjE2Nzk5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/17216799?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ouphi',
   'html_url': 'https: //github.com/ouphi',
   'followers_url': 'https: //api.github.com/users/ouphi/followers',
   'following_url': 'https: //api.github.com/users/ouphi/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ouphi/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ouphi/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ouphi/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ouphi/orgs',
   'repos_url': 'https: //api.github.com/users/ouphi/repos',
   'events_url': 'https: //api.github.com/users/ouphi/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ouphi/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028618,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZyg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/documentation',
    'name': 'documentation',
    'color': '0075ca',
    'default': True,
    'description': 'Improvements or additions to documentation'
                        },
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-04-08T08: 25: 19Z',
  'updated_at': '2024-08-08T04: 07: 57Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[X
                  ] I checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t find an answer to my question.\r\n\r\nI was exploring the possibility to create custom metrics.\r\nIt seems that it is possible, by subclassing either [Metric](https://github.com/explodinggradients/ragas/blob/e9418237d0dd06f640b0f6bbae7a5a3f9c1029ea/src/ragas/metrics/base.py#L52), [MetricWithLLM](https://github.com/explodinggradients/ragas/blob/e9418237d0dd06f640b0f6bbae7a5a3f9c1029ea/src/ragas/metrics/base.py#L127) or [MetricWithEmbeddings](https://github.com/explodinggradients/ragas/blob/e9418237d0dd06f640b0f6bbae7a5a3f9c1029ea/src/ragas/metrics/base.py#L144).\r\n\r\nFor example I created a dummy example computing the answer length:\r\nNote that I don\'t need this specific metric, I used it to have a simple example.\r\n\r\n```python\r\nimport typing as t\r\nfrom datasets import Dataset\r\nfrom ragas import evaluate\r\nfrom ragas.metrics.base import Metric, EvaluationMode\r\nfrom langchain_core.callbacks import Callbacks\r\nfrom ragas.run_config import RunConfig\r\n\r\nclass AnswerLength(Metric):\r\n    """Simple example of a custom metric. Returning the answer length."""\r\n    name: str = "answer_length"\r\n    evaluation_mode: EvaluationMode = EvaluationMode.qa\r\n    \r\n    async def _ascore(\r\n        self: t.Self, row: t.Dict, callbacks: Callbacks, is_async: bool\r\n    ) -> float:\r\n        return len(row["answer"])\r\n    def init(self, run_config: RunConfig):\r\n        """do nothing"""\r\n\r\nanswer_length = AnswerLength()\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n}\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\nscore = evaluate(dataset, metrics=[answer_length])\r\nscore.to_pandas()\r\n```\r\n\r\nMy questions are:\r\n\r\n- Do you recommend creating custom metrics with ragas? Or is it preferable to exclusively rely on the [pre-existing metrics offered by Ragas](https://docs.ragas.io/en/latest/concepts/metrics/index.html)?\r\n- If yes, is the approach described above correct?\r\n\r\nI am not sure if the possibility of creating custom metrics is an intended feature or not. I want to make sure that my custom metric implementations do not break when ragas evolves. I am interested in knowing the vision about supporting and documenting the possibility of having custom metrics in the future.\n\n<sub>[R-243](https://linear.app/exploding-gradients/issue/R-243/docs-add-documentation-on-the-best-approach-to-define-custom-metrics)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/850/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/850/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/841',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/841/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/841/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/841/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/841',
  'id': 2222659164,
  'node_id': 'PR_kwDOJgX1Gs5rjYUv',
  'number': 841,
  'title': 'define retry arg for AsyncRetrying',
  'user': {'login': 'anthonyivn2',
   'id': 21217602,
   'node_id': 'MDQ6VXNlcjIxMjE3NjAy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/21217602?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/anthonyivn2',
   'html_url': 'https: //github.com/anthonyivn2',
   'followers_url': 'https: //api.github.com/users/anthonyivn2/followers',
   'following_url': 'https: //api.github.com/users/anthonyivn2/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/anthonyivn2/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/anthonyivn2/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/anthonyivn2/subscriptions',
   'organizations_url': 'https: //api.github.com/users/anthonyivn2/orgs',
   'repos_url': 'https: //api.github.com/users/anthonyivn2/repos',
   'events_url': 'https: //api.github.com/users/anthonyivn2/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/anthonyivn2/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-03T11: 22: 15Z',
  'updated_at': '2024-04-08T16: 50: 34Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/841',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/841',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/841.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/841.patch',
   'merged_at': None
                  },
  'body': 'Related to issue #839 that I made',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/841/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/841/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/835',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/835/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/835/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/835/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/835',
  'id': 2220921915,
  'node_id': 'I_kwDOJgX1Gs6EYJQ7',
  'number': 835,
  'title': "How to fix AttributeError: 'str' object has no attribute 'generator_llm' with Ragas in python script?",
  'user': {'login': 'NicolasFerland',
   'id': 26882156,
   'node_id': 'MDQ6VXNlcjI2ODgyMTU2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/26882156?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/NicolasFerland',
   'html_url': 'https: //github.com/NicolasFerland',
   'followers_url': 'https: //api.github.com/users/NicolasFerland/followers',
   'following_url': 'https: //api.github.com/users/NicolasFerland/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/NicolasFerland/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/NicolasFerland/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/NicolasFerland/subscriptions',
   'organizations_url': 'https: //api.github.com/users/NicolasFerland/orgs',
   'repos_url': 'https: //api.github.com/users/NicolasFerland/repos',
   'events_url': 'https: //api.github.com/users/NicolasFerland/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/NicolasFerland/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-02T16: 17: 41Z',
  'updated_at': '2024-06-10T07: 30: 41Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[x
                  ] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nI have a code using the package ragas that works in a notebook but doesn\'t work in a script. I am trying to have it as a script. The error is inside the package, so I have no idea how to fix it. The version of the package is the same in the script and notebook \'0.1.4\'\r\n\r\nRagas version: 0.1.4\r\nPython version: 3.11.6\r\n\r\n**Code to Reproduce**\r\n`\r\nimport importlib.resources\r\nimport os\r\n\r\nimport pandas as pd\r\nimport yaml\r\nfrom dotenv import load_dotenv\r\nfrom google.cloud import storage\r\nfrom google.cloud.storage import Blob\r\nfrom langchain.docstore.document import Document\r\nfrom langchain_community.document_loaders import PDFPlumberLoader\r\nfrom langchain_experimental.text_splitter import SemanticChunker\r\nfrom langchain_openai.embeddings import OpenAIEmbeddings\r\nfrom ragas.testset.evolutions import multi_context, reasoning, simple\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom tqdm.notebook import tqdm\r\n\r\nload_dotenv()\r\n\r\n\r\ndef get_pdf_files(collection_name, filegroup_name):\r\n    """Get the pdf files from the collection and filegroup from the ds-librairie-genai-provisioning"""\r\n\r\n    collections_path = importlib.resources.files("genai_provisioning").joinpath(\r\n        "collections"\r\n    )\r\n    collection_path = collections_path.joinpath(collection_name)\r\n\r\n    filegroups_path = collection_path.joinpath("filegroups")\r\n    files_directory = filegroups_path.joinpath(filegroup_name).joinpath("files")\r\n\r\n    pdf_files = list(files_directory.glob("*.pdf"))\r\n\r\n    return pdf_files\r\n\r\n\r\ndef combine_all_page(docs):\r\n    """Combine all pages from one PDF into one Document object"""\r\n    try:\r\n        page_content = "/n".join([doc.page_content for doc in docs])\r\n        page_metadata = docs[0].metadata\r\n        if "page" in page_metadata:\r\n            page_metadata.pop("page")\r\n        return [Document(page_content=page_content, metadata=page_metadata)]\r\n    except Exception as e:\r\n        print(e)\r\n\r\n\r\ndef generate_testset(configs_file):\r\n    """Generate RAGAS synthetic test set"""\r\n    with open(configs_file) as f:\r\n        configs = yaml.safe_load(f)\r\n\r\n    collection_name = configs["collection_name"]\r\n    filegroup_name = configs["filegroup_name"]\r\n    version = configs["version"]\r\n\r\n    files = get_pdf_files(collection_name, filegroup_name)\r\n    print(f"Number of files: {len(files)}")\r\n\r\n    docs = []\r\n    for file in tqdm(files):\r\n        doc_ = PDFPlumberLoader(\r\n            str(file),\r\n            text_kwargs={\r\n                "x_tolerance": configs["x_tolerance"],\r\n                "y_tolerance": configs["y_tolerance"],\r\n            },\r\n        ).load()\r\n        doc_ = combine_all_page(doc_)\r\n        docs.extend(doc_)\r\n    print(f"Number of documents: {len(docs)}")\r\n\r\n    for doc_ in docs:\r\n        doc_.metadata["filename"] = doc_.metadata["source"]\r\n\r\n    splitted_testset_docs = docs\r\n\r\n    # RAGAS to generate a synthetic testset\r\n    generator = TestsetGenerator.with_openai()\r\n\r\n    testset = generator.generate_with_langchain_docs(\r\n        splitted_testset_docs,\r\n        test_size=configs["test_size"],\r\n        with_debugging_logs=True,\r\n        distributions=configs["distributions"],\r\n    )\r\n`\r\n\r\n**Error trace**\r\n`\r\n---------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\nCell In[2], line 3\r\n      1 from generate_testset import generate_testset\r\n----> 3 generate_testset("generate-testset.yml")\r\n\r\nFile ~/github_repos/ds-research-genai/common/src/rag_pipeline_evaluator/generate_testset.py:86, in generate_testset(configs_file)\r\n     83 print("len(splitted_testset_docs)", len(splitted_testset_docs))\r\n     84 print("splitted_testset_docs[0]", splitted_testset_docs[0])\r\n---> 86 testset = generator.generate_with_langchain_docs(\r\n     87     splitted_testset_docs,\r\n     88     test_size=configs["test_size"],\r\n     89     with_debugging_logs=True,\r\n     90     distributions=configs["distributions"],\r\n     91 )\r\n     93 # Remove nan and short ground truth\r\n     94 testset_improved = testset\r\n\r\nFile ~/github_repos/ds-research-genai/common/src/rag_pipeline_evaluator/venv/lib/python3.11/site-packages/ragas/testset/generator.py:179, in TestsetGenerator.generate_with_langchain_docs(self, documents, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\r\n    174 # chunk documents and add to docstore\r\n    175 self.docstore.add_documents(\r\n    176     [Document.from_langchain_document(doc) for doc in documents]\r\n    177 )\r\n--> 179 return self.generate(\r\n    180     test_size=test_size,\r\n    181     distributions=distributions,\r\n    182     with_debugging_logs=with_debugging_logs,\r\n    183     is_async=is_async,\r\n    184     raise_exceptions=raise_exceptions,\r\n    185     run_config=run_config,\r\n    186 )\r\n\r\nFile ~/github_repos/ds-research-genai/common/src/rag_pipeline_evaluator/venv/lib/python3.11/site-packages/ragas/testset/generator.py:227, in TestsetGenerator.generate(self, test_size, distributions, with_debugging_logs, is_async, raise_exceptions, run_config)\r\n    225 # init filters and evolutions\r\n    226 for evolution in distributions:\r\n--> 227     self.init_evolution(evolution)\r\n    228     evolution.init(is_async=is_async, run_config=run_config)\r\n    230 if with_debugging_logs:\r\n\r\nFile ~/github_repos/ds-research-genai/common/src/rag_pipeline_evaluator/venv/lib/python3.11/site-packages/ragas/testset/generator.py:189, in TestsetGenerator.init_evolution(self, evolution)\r\n    188 def init_evolution(self, evolution: Evolution) -> None:\r\n--> 189     if evolution.generator_llm is None:\r\n    190         evolution.generator_llm = self.generator_llm\r\n    191         if evolution.docstore is None:\r\n\r\nAttributeError: \'str\' object has no attribute \'generator_llm\'\r\n`\r\n\r\n**Expected behavior**\r\nNo error. Generate a test set.\r\n\r\n\r\n**Additional context**\r\nIt does the generating till 100%, then fails.\r\n\r\nIn a notebook, the exact same code with the exact same arguments work.\r\n\r\nevolution is inside the package and I do not touch it directly. I have no idea why it would be a string rather than the correct object.\r\n\r\nThe error happens both if I call the scrip inside a notebook after importing it or in a terminal. But the same code in a notebook is ok.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/835/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/835/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/834',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/834/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/834/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/834/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/834',
  'id': 2219741969,
  'node_id': 'PR_kwDOJgX1Gs5rZWRD',
  'number': 834,
  'title': 'contribution: infinity-integration',
  'user': {'login': 'michaelfeil',
   'id': 63565275,
   'node_id': 'MDQ6VXNlcjYzNTY1Mjc1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/63565275?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/michaelfeil',
   'html_url': 'https: //github.com/michaelfeil',
   'followers_url': 'https: //api.github.com/users/michaelfeil/followers',
   'following_url': 'https: //api.github.com/users/michaelfeil/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/michaelfeil/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/michaelfeil/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/michaelfeil/subscriptions',
   'organizations_url': 'https: //api.github.com/users/michaelfeil/orgs',
   'repos_url': 'https: //api.github.com/users/michaelfeil/repos',
   'events_url': 'https: //api.github.com/users/michaelfeil/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/michaelfeil/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-04-02T07: 16: 07Z',
  'updated_at': '2024-06-01T00: 38: 15Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/834',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/834',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/834.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/834.patch',
   'merged_at': None
                  },
  'body': '#596 this PR adds support for various embeddings\r\n\r\nAlso fixes: \r\n- `make format` had no purpose in the CI - it would not verify that code is formatted (help in code-review) - added `make format-check`\r\n- SentenceTransformer - import at runtime.\r\n- adds pytest-asyncio: `pytest.mark.asyncio` there was a previous test - these tests are skipped when it is not installed.\r\n- typing and other minor\r\n\r\nFeel free to commit directly to the branch.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/834/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/834/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/819',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/819/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/819/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/819/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/819',
  'id': 2213922079,
  'node_id': 'PR_kwDOJgX1Gs5rF2Xa',
  'number': 819,
  'title': '[AUG
                  ] Add solar model',
  'user': {'login': 'Tokkiu',
   'id': 13414571,
   'node_id': 'MDQ6VXNlcjEzNDE0NTcx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/13414571?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Tokkiu',
   'html_url': 'https: //github.com/Tokkiu',
   'followers_url': 'https: //api.github.com/users/Tokkiu/followers',
   'following_url': 'https: //api.github.com/users/Tokkiu/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Tokkiu/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Tokkiu/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Tokkiu/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Tokkiu/orgs',
   'repos_url': 'https: //api.github.com/users/Tokkiu/repos',
   'events_url': 'https: //api.github.com/users/Tokkiu/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Tokkiu/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-03-28T18: 58: 33Z',
  'updated_at': '2024-03-28T23: 02: 02Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/819',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/819',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/819.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/819.patch',
   'merged_at': None
                  },
  'body': None,
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/819/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/819/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/809',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/809/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/809/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/809/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/809',
  'id': 2209880653,
  'node_id': 'I_kwDOJgX1Gs6DuBpN',
  'number': 809,
  'title': 'Repetitive Data in Generated Synthetic Dataset',
  'user': {'login': 'thamasha24',
   'id': 110017491,
   'node_id': 'U_kgDOBo670w',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/110017491?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/thamasha24',
   'html_url': 'https: //github.com/thamasha24',
   'followers_url': 'https: //api.github.com/users/thamasha24/followers',
   'following_url': 'https: //api.github.com/users/thamasha24/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/thamasha24/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/thamasha24/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/thamasha24/subscriptions',
   'organizations_url': 'https: //api.github.com/users/thamasha24/orgs',
   'repos_url': 'https: //api.github.com/users/thamasha24/repos',
   'events_url': 'https: //api.github.com/users/thamasha24/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/thamasha24/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-03-27T05: 16: 10Z',
  'updated_at': '2024-06-04T18: 09: 10Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'When creating a synthetic dataset from documents, many of the questions and answers end up being the same. (Out of 20 questions and answers, around 15 are identical.)\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/809/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/809/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/804',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/804/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/804/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/804/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/804',
  'id': 2207374564,
  'node_id': 'I_kwDOJgX1Gs6Dkdzk',
  'number': 804,
  'title': "AssertionError: Adapted output keys set(output.keys())=set() do not match with the original output keys: output_keys[i]={'statements'}",
  'user': {'login': 'Ailce8862',
   'id': 42427256,
   'node_id': 'MDQ6VXNlcjQyNDI3MjU2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/42427256?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Ailce8862',
   'html_url': 'https: //github.com/Ailce8862',
   'followers_url': 'https: //api.github.com/users/Ailce8862/followers',
   'following_url': 'https: //api.github.com/users/Ailce8862/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Ailce8862/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Ailce8862/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Ailce8862/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Ailce8862/orgs',
   'repos_url': 'https: //api.github.com/users/Ailce8862/repos',
   'events_url': 'https: //api.github.com/users/Ailce8862/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Ailce8862/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2024-03-26T06: 34: 52Z',
  'updated_at': '2024-08-02T07: 26: 42Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nAssertionError: Adapted output keys set(output.keys())=set() do not match with the original output keys: output_keys[i]={\'statements\'}\r\n\r\n\r\nRagas version:0.1.5\r\nPython version:3.10.13 \r\n\r\n**Code to Reproduce**\r\nfrom ragas import adapt\r\n    from ragas.metrics import (\r\n        faithfulness,\r\n        answer_relevancy,\r\n        context_recall,\r\n    )\r\n    from langchain_community.embeddings import QianfanEmbeddingsEndpoint\r\n    from langchain_community.chat_models import QianfanChatEndpoint\r\n\r\n    embed_llm = QianfanEmbeddingsEndpoint(\r\n        qianfan_ak=\'XXX\',\r\n        qianfan_sk=\'XXX\'\r\n    )\r\n    chat_llm = QianfanChatEndpoint(streaming=True)\r\n\r\n    adapt(metrics=[faithfulness, answer_relevancy,context_recall], language="Chinese", llm=chat_llm)\r\n    print(faithfulness.long_form_answer_prompt.to_string())\r\n\r\n**Error trace**\r\nTraceback (most recent call last):\r\n  File "/Users/liangpan/工作/新点/coding/RAG_langchain/step3/RAGAS_eval_separation.py", line 133, in <module>\r\n    adapt(metrics=[faithfulness, answer_relevancy,context_recall], language="Chinese", llm=chat_llm)\r\n  File "/Users/liangpan/miniforge3/envs/langchain/lib/python3.10/site-packages/ragas/adaptation.py", line 36, in adapt\r\n    metric.adapt(language, cache_dir=cache_dir)\r\n  File "/Users/liangpan/miniforge3/envs/langchain/lib/python3.10/site-packages/ragas/metrics/_faithfulness.py", line 203, in adapt\r\n    self.long_form_answer_prompt = self.long_form_answer_prompt.adapt(\r\n  File "/Users/liangpan/miniforge3/envs/langchain/lib/python3.10/site-packages/ragas/llms/prompt.py", line 231, in adapt\r\n    set(output.keys()) == output_keys[i]\r\nAssertionError: Adapted output keys set(output.keys())=set() do not match with the original output keys: output_keys[i]={\'statements\'}\r\n\r\nProcess finished with exit code 1\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/804/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/804/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/784',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/784/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/784/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/784/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/784',
  'id': 2194354057,
  'node_id': 'I_kwDOJgX1Gs6Cyy-J',
  'number': 784,
  'title': 'erorr on windows',
  'user': {'login': 'frischzenger',
   'id': 3762972,
   'node_id': 'MDQ6VXNlcjM3NjI5NzI=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/3762972?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/frischzenger',
   'html_url': 'https: //github.com/frischzenger',
   'followers_url': 'https: //api.github.com/users/frischzenger/followers',
   'following_url': 'https: //api.github.com/users/frischzenger/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/frischzenger/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/frischzenger/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/frischzenger/subscriptions',
   'organizations_url': 'https: //api.github.com/users/frischzenger/orgs',
   'repos_url': 'https: //api.github.com/users/frischzenger/repos',
   'events_url': 'https: //api.github.com/users/frischzenger/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/frischzenger/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 4,
  'created_at': '2024-03-19T08: 40: 10Z',
  'updated_at': '2024-05-27T02: 35: 55Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\ni ran following code of ragas on windows 10\r\n\r\n\r\nRagas version: 0.1.4\r\nPython version: 3.9\r\n\r\n**Code to Reproduce**\r\n``\r\nfrom datasets import Dataset \r\nimport os\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import faithfulness, answer_correctness\r\n\r\nos.environ["OPENAI_API_KEY"] = "your-openai-key"\r\n\r\ndata_samples = {\r\n    \'question\': [\'When was the first super bowl?\', \'Who won the most super bowls?\'],\r\n    \'answer\': [\'The first superbowl was held on Jan 15, 1967\', \'The most super bowls have been won by The New England Patriots\'],\r\n    \'contexts\' : [[\'The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,\'], \r\n    [\'The Green Bay Packers...Green Bay, Wisconsin.\',\'The Packers compete...Football Conference\']],\r\n    \'ground_truth\': [\'The first superbowl was held on January 15, 1967\', \'The New England Patriots have won the Super Bowl a record six times\']\r\n}\r\n\r\ndataset = Dataset.from_dict(data_samples)\r\n\r\nscore = evaluate(dataset,metrics=[faithfulness,answer_correctness])\r\nscore.to_pandas()\r\n``\r\n\r\n**Error trace**\r\nRunTime error: event loop is closed.\r\n\r\n\r\n\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/784/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/784/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/774',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/774/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/774/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/774/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/774',
  'id': 2192005926,
  'node_id': 'I_kwDOJgX1Gs6Cp1sm',
  'number': 774,
  'title': 'Automatic language adaption TestSet generation error: "Adapted output keys do not match with the original output keys"',
  'user': {'login': 'baswenneker',
   'id': 173496,
   'node_id': 'MDQ6VXNlcjE3MzQ5Ng==',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/173496?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/baswenneker',
   'html_url': 'https: //github.com/baswenneker',
   'followers_url': 'https: //api.github.com/users/baswenneker/followers',
   'following_url': 'https: //api.github.com/users/baswenneker/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/baswenneker/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/baswenneker/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/baswenneker/subscriptions',
   'organizations_url': 'https: //api.github.com/users/baswenneker/orgs',
   'repos_url': 'https: //api.github.com/users/baswenneker/repos',
   'events_url': 'https: //api.github.com/users/baswenneker/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/baswenneker/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 9,
  'created_at': '2024-03-18T11: 57: 19Z',
  'updated_at': '2024-08-02T07: 26: 01Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\nCan\'t get the automatic language adaption going for testset generation. I retried this about 10 times.\r\n\r\nRagas version: 0.1.4\r\nPython version: 3.11\r\n\r\n**Code to Reproduce**\r\nShare code to reproduce the issue\r\n```\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context,conditional\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\n# generator with openai models\r\ngenerator_llm = azure_llm()\r\ncritic_llm = azure_llm()\r\nembeddings = azure_embeddings()\r\n\r\ngenerator = TestsetGenerator.from_langchain(\r\n    generator_llm,\r\n    critic_llm,\r\n    embeddings\r\n)\r\n\r\n# adapt to language\r\nlanguage = "Dutch"\r\ncache_dir = ".cache"\r\n\r\ngenerator.adapt(language, evolutions=[simple
                  ], cache_dir=cache_dir)\r\ngenerator.save(evolutions=[simple, reasoning, multi_context, conditional
                  ], cache_dir=cache_dir)\r\n```\r\n\r\nThis is the output until it errors out:\r\n```\r\n{\'keyphrases\': [\'Zwart gat\', \'Regio van ruimtetijd\', \'Sterke zwaartekracht\', \'Licht en elektromagnetische golven\', \'Theorie van algemene relativiteit\'
                        ]
                  }\r\n{\'keyphrases\': [\'Chinese Muur\', \'Oude vestingwerken\', \'Noord-China\'
                        ]
                  }\r\n{\'answer\': \'Menselijke activiteiten dragen voornamelijk bij aan klimaatverandering door de uitstoot van broeikasgassen bij het verbranden van fossiele brandstoffen. Deze uitstoot verhoogt de concentratie van broeikasgassen in de atmosfeer, wat meer warmte vasthoudt en leidt tot opwarming van de aarde en veranderde weerspatronen.\', \'verdict\': \'1\'
                  }\r\n{\'answer\': \'Kunstmatige intelligentie is ontworpen om menselijke cognitieve functies na te bootsen, met belangrijke capaciteiten zoals leren, redeneren, waarnemen en reageren op de omgeving op een manier die vergelijkbaar is met mensen. Deze capaciteiten maken AI cruciaal in verschillende velden, inclusief gezondheidszorg en autonoom rijden.\', \'verdict\': \'1\'
                  }\r\n{\'answer\': \'Het antwoord op de gegeven vraag is niet aanwezig in de context\', \'verdict\': \'-1\'
                  }\r\n{\'relevant_contexts\': [
                              1,
                              2
                        ]
                  }\r\n[
                        [
                              1,
                              2
                        ],
                        {\'relevant_contexts\': [
                                    1,
                                    2
                              ]
                        }
                  ]\r\n{\'score\': 6.0
                  }\r\n[
                        {\'statements\': [\'अल्बर्ट आइंस्टीन का जन्म जर्मनी में हुआ था।\', \'अल्बर्ट आइंस्टीन अपने सापेक्षता के सिद्धांत के लिए सबसे अधिक प्रसिद्ध थे।\'
                              ]
                        },
                        {\'feedback\': "De vraag is te vaag en breed, het vraagt om een \'ontdekking over de ruimte\' zonder een specifiek aspect, tijdskader of context van interesse te specificeren. Dit kan verwijzen naar een breed scala aan onderwerpen, van de ontdekking van nieuwe hemellichamen tot vooruitgang in de technologie van ruimtereizen. Om de duidelijkheid en beantwoordbaarheid te verbeteren, zou de vraag het type ontdekking (bijv. astronomisch, technologisch), het tijdskader (bijv. recent, historisch) of de context (bijv. binnen een specifieke onderzoeksstudie of ruimtemissie) kunnen specificeren.", \'verdict\': \'0\'
                        }
                  ]\r\n```\r\n\r\n**Error trace**\r\n```\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\nCell In[
                        4
                  ],
                  [line 20
                  ](vscode-notebook-cell:?execution_count=4&line=20)\r\n     [
                        17
                  ](vscode-notebook-cell:?execution_count=4&line=17) language = "Dutch"\r\n     [
                        18
                  ](vscode-notebook-cell:?execution_count=4&line=18) cache_dir = ".cache"\r\n---> [
                        20
                  ](vscode-notebook-cell:?execution_count=4&line=20) generator.adapt(language, evolutions=[simple
                  ], cache_dir=cache_dir)\r\n     [
                        21
                  ](vscode-notebook-cell:?execution_count=4&line=21) generator.save(evolutions=[simple, reasoning, multi_context, conditional
                  ], cache_dir=cache_dir)\r\n\r\nFile [~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/generator.py: 311
                  ](https: //file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/generator.py:311), in TestsetGenerator.adapt(self, language, evolutions, cache_dir)\r\n    [309](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/generator.py:309) self.init_evolution(evolution)\r\n    [310](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/generator.py:310) evolution.init()\r\n--> [311](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/generator.py:311) evolution.adapt(language, cache_dir=cache_dir)\r\n\r\nFile [~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:324](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:324), in SimpleEvolution.adapt(self, language, cache_dir)\r\n    [323](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:323) def adapt(self, language: str, cache_dir: t.Optional[str] = None) -> None:\r\n--> [324](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:324)     super().adapt(language, cache_dir)\r\n    [325](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:325)     self.seed_question_prompt = self.seed_question_prompt.adapt(\r\n    [326](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:326)         language, self.generator_llm, cache_dir\r\n    [327](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:327)     )\r\n\r\nFile [~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:261](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:261), in Evolution.adapt(self, language, cache_dir)\r\n    [255](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:255) self.rewrite_invalid_question_prompt = (\r\n    [256](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:256)     self.rewrite_invalid_question_prompt.adapt(\r\n    [257](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:257)         language, self.generator_llm, cache_dir\r\n    [258](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:258)     )\r\n    [259](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:259) )\r\n    [260](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:260) self.node_filter.adapt(language, cache_dir)\r\n--> [261](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/evolutions.py:261) self.question_filter.adapt(language, cache_dir)\r\n\r\nFile [~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:97](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:97), in QuestionFilter.adapt(self, language, cache_dir)\r\n     [93](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:93) def adapt(self, language: str, cache_dir: t.Optional[str] = None) -> None:\r\n     [94](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:94)     """\r\n     [95](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:95)     Adapt the filter to a different language.\r\n     [96](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:96)     """\r\n---> [97](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:97)     self.filter_question_prompt = self.filter_question_prompt.adapt(\r\n     [98](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:98)         language, self.llm, cache_dir\r\n     [99](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/testset/filters.py:99)     )\r\n\r\nFile [~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:236](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:236), in Prompt.adapt(self, language, llm, cache_dir)\r\n    [230](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:230)             assert (\r\n    [231](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:231)                 set(output.keys()) == output_keys[i]\r\n    [232](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:232)             ), f"Adapted output keys {set(output.keys())=} do not match with the original output keys: {output_keys[i]=}"\r\n    [233](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:233)         elif isinstance(output, list) and all(\r\n    [234](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:234)             isinstance(item, dict) for item in output\r\n    [235](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:235)         ):\r\n--> [236](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:236)             assert all(\r\n    [237](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:237)                 set(item.keys()) in output_keys[i] for item in output\r\n    [238](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:238)             ), "Adapted output keys do not match with the original output keys"\r\n    [240](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:240)     self.examples[i] = example_dict\r\n    [242](https://file+.vscode-resource.vscode-cdn.net/Users/bas/Development/HeadingFWD/evaluation-playground/~/Development/HeadingFWD/evaluation-playground/.venv/lib/python3.11/site-packages/ragas/llms/prompt.py:242) self.language = language\r\n```\r\n\r\n**Expected behavior**\r\nNo error!\r\n\r\n\r\n**Additional context**\r\nUsing langchain with azure openai endpoint.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/774/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/774/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/771',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/771/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/771/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/771/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/771',
  'id': 2191711473,
  'node_id': 'PR_kwDOJgX1Gs5p6jnS',
  'number': 771,
  'title': 'auto fix some json decoder errors',
  'user': {'login': 'ZeyuTeng96',
   'id': 96521059,
   'node_id': 'U_kgDOBcDLYw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/96521059?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/ZeyuTeng96',
   'html_url': 'https: //github.com/ZeyuTeng96',
   'followers_url': 'https: //api.github.com/users/ZeyuTeng96/followers',
   'following_url': 'https: //api.github.com/users/ZeyuTeng96/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/ZeyuTeng96/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/ZeyuTeng96/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/ZeyuTeng96/subscriptions',
   'organizations_url': 'https: //api.github.com/users/ZeyuTeng96/orgs',
   'repos_url': 'https: //api.github.com/users/ZeyuTeng96/repos',
   'events_url': 'https: //api.github.com/users/ZeyuTeng96/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/ZeyuTeng96/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-03-18T09: 45: 10Z',
  'updated_at': '2024-03-18T09: 46: 24Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/771',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/771',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/771.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/771.patch',
   'merged_at': None
                  },
  'body': "Hi there, \r\n\r\nWhen I used the 'context_recall' metric, I constantly got json decoder error of 'Invalid \\escape'. And the llm is fail to generate a propriate json. So, I just think can we auto fix some types of decoder error without calling llm. Therefore, I provide two fail cases and fix it by simply replacing some chars. It can also extend more decoder errors in the future. \r\n\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/771/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/771/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/764',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/764/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/764/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/764/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/764',
  'id': 2190120762,
  'node_id': 'I_kwDOJgX1Gs6Cipc6',
  'number': 764,
  'title': 'generate_with_langchain_docs is broken',
  'user': {'login': 'rolandgvc',
   'id': 26813782,
   'node_id': 'MDQ6VXNlcjI2ODEzNzgy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/26813782?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/rolandgvc',
   'html_url': 'https: //github.com/rolandgvc',
   'followers_url': 'https: //api.github.com/users/rolandgvc/followers',
   'following_url': 'https: //api.github.com/users/rolandgvc/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/rolandgvc/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/rolandgvc/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/rolandgvc/subscriptions',
   'organizations_url': 'https: //api.github.com/users/rolandgvc/orgs',
   'repos_url': 'https: //api.github.com/users/rolandgvc/repos',
   'events_url': 'https: //api.github.com/users/rolandgvc/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/rolandgvc/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 23,
  'created_at': '2024-03-16T16: 20: 14Z',
  'updated_at': '2024-08-19T02: 30: 09Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[x
                  ] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nRunning `generate_with_langchain_docs` gets stuck, showing:\r\n```\r\nFilename and doc_id are the same for all nodes.\r\nGenerating:   0%|                                                                                       | 0/1 [00:00<?, ?it/s]\r\n```\r\n\r\nRagas version:  0.1.4\r\nPython version: 3.9\r\n\r\n**Code to Reproduce**\r\n```\r\nimport os\r\nimport re\r\nfrom typing import List, Dict, Any\r\nimport pandas as pd\r\nfrom datasets import load_dataset\r\nfrom langchain.docstore.document import Document\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\r\n\r\n\r\nclass SyntheticDatasetGenerator:\r\n    def __init__(self, min_content_length: int = 1000) -> None:\r\n        self.min_content_length = min_content_length\r\n\r\n    def run(self, data: pd.DataFrame) -> pd.DataFrame:\r\n        filtered_emails = self._filter_and_process_emails(data)\r\n\r\n        documents = [\r\n            Document(\r\n                page_content=email["body"],\r\n                metadata={\r\n                    "date": email["date"],\r\n                    "from": email["from"],\r\n                },\r\n            )\r\n            for email in filtered_emails\r\n        ]\r\n\r\n        return self._generate_synthetic_dataset(documents)\r\n\r\n    def _extract_email_details(self, email_text: str) -> Dict[str, str]:\r\n        # Regular expression patterns for each field\r\n        patterns = {\r\n            "date": r"Date: (.+)",\r\n            "from": r"From: (.+)",\r\n            "to": r"To: (.+)",\r\n        }\r\n\r\n        result = {}\r\n        for field, pattern in patterns.items():\r\n            match = re.search(pattern, email_text)\r\n            if match:\r\n                result[field] = match.group(1).strip()\r\n\r\n        # Everything after "Subject:" is considered as the body\r\n        body_pattern = r"Subject:.*(?:\\n|\\r\\n?)(.*(?:\\n|\\r\\n?).*)"\r\n        body_match = re.search(body_pattern, email_text, re.DOTALL)\r\n        if body_match:\r\n            result["body"] = body_match.group(1).strip()\r\n        else:\r\n            print(email_text)\r\n\r\n        return result\r\n\r\n    def _filter_and_process_emails(self, data: pd.DataFrame) -> List[Dict[str, str]]:\r\n        filtered_emails = []\r\n        for _, email in data.iterrows():\r\n            if len(email.text) > self.min_content_length:\r\n                details = self._extract_email_details(email.text)\r\n                filtered_emails.append(details)\r\n\r\n        return filtered_emails\r\n\r\n    def _generate_synthetic_dataset(self, documents: List[Document]) -> pd.DataFrame:\r\n        generator_llm = ChatOpenAI(model_name="gpt-3.5-turbo")\r\n        critic_llm = ChatOpenAI(model_name="gpt-3.5-turbo")\r\n        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")\r\n        generator = TestsetGenerator.from_langchain(\r\n            generator_llm, critic_llm, embeddings, chunk_size=4096\r\n        )\r\n\r\n        testset = generator.generate_with_langchain_docs(\r\n            documents,\r\n            test_size=1,\r\n            distributions={simple: 0.5, reasoning: 0.1, multi_context: 0.4},\r\n            raise_exceptions=True,\r\n        )\r\n\r\n        return testset.to_pandas()\r\n\r\n\r\nif __name__ == "__main__":\r\n    from dotenv import load_dotenv\r\n\r\n    load_dotenv()\r\n\r\n    os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")\r\n\r\n    data = (\r\n        load_dataset("snoop2head/enron_aeslc_emails")["train"]\r\n        .select(range(100))\r\n        .to_pandas()\r\n    )\r\n\r\n    df = SyntheticDatasetGenerator().run(data)\r\n```\r\n\r\n**Error trace**\r\n```\r\nFilename and doc_id are the same for all nodes.\r\nGenerating:   0%|                                                                                       | 0/1 [00:00<?, ?it/s]\r\n```\r\n\r\n**Expected behavior**\r\nA synthetic dataset should be created.\r\n\r\n\r\n**Additional context**\r\nI\'m trying to generate a synthetic dataset of questions based on enron emails.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/764/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/764/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/761',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/761/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/761/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/761/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/761',
  'id': 2188743553,
  'node_id': 'I_kwDOJgX1Gs6CdZOB',
  'number': 761,
  'title': 'More robust JSON prompting and parsing',
  'user': {'login': 'mrtj',
   'id': 3469711,
   'node_id': 'MDQ6VXNlcjM0Njk3MTE=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/3469711?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/mrtj',
   'html_url': 'https: //github.com/mrtj',
   'followers_url': 'https: //api.github.com/users/mrtj/followers',
   'following_url': 'https: //api.github.com/users/mrtj/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/mrtj/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/mrtj/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/mrtj/subscriptions',
   'organizations_url': 'https: //api.github.com/users/mrtj/orgs',
   'repos_url': 'https: //api.github.com/users/mrtj/repos',
   'events_url': 'https: //api.github.com/users/mrtj/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/mrtj/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                        },
                        {'id': 6963995062,
    'node_id': 'LA_kwDOJgX1Gs8AAAABnxYhtg',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/stale',
    'name': 'stale',
    'color': 'dadada',
    'default': False,
    'description': 'Issue has not had recent activity or appears to be solved. Stale issues will be automatically closed'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'mrtj',
   'id': 3469711,
   'node_id': 'MDQ6VXNlcjM0Njk3MTE=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/3469711?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/mrtj',
   'html_url': 'https: //github.com/mrtj',
   'followers_url': 'https: //api.github.com/users/mrtj/followers',
   'following_url': 'https: //api.github.com/users/mrtj/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/mrtj/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/mrtj/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/mrtj/subscriptions',
   'organizations_url': 'https: //api.github.com/users/mrtj/orgs',
   'repos_url': 'https: //api.github.com/users/mrtj/repos',
   'events_url': 'https: //api.github.com/users/mrtj/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/mrtj/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'mrtj',
    'id': 3469711,
    'node_id': 'MDQ6VXNlcjM0Njk3MTE=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/3469711?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/mrtj',
    'html_url': 'https: //github.com/mrtj',
    'followers_url': 'https: //api.github.com/users/mrtj/followers',
    'following_url': 'https: //api.github.com/users/mrtj/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/mrtj/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/mrtj/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/mrtj/subscriptions',
    'organizations_url': 'https: //api.github.com/users/mrtj/orgs',
    'repos_url': 'https: //api.github.com/users/mrtj/repos',
    'events_url': 'https: //api.github.com/users/mrtj/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/mrtj/received_events',
    'type': 'User',
    'site_admin': False
                        },
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        },
                        {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 6,
  'created_at': '2024-03-15T14: 55: 58Z',
  'updated_at': '2024-06-03T16: 02: 23Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\n\r\nThis feature request is about integrating LangChain\'s `PydanticOutputParser` and pydantic models into ragas prompting.\r\n\r\n**Why is the feature important for you?**\r\n\r\nThe current prompting of the validation metrics uses a somewhat vague definition of the answer format, specifying only examples about the expected format. The LLM then should deduct the expected format and generate an answer that corresponds to the schema that is only implicitly specified in the single metrics implementation. Especially when using different LLMs compared to the default GPT-3.5, this leads to potential parsing errors and the metrics can not be calculated correctly.\r\n\r\nFor example:\r\n\r\n- Claude and other models tends to return the binary verdict as a JSON number opposed to the expected string: [#752
                  ](#752) (this issue is about testset generation, but I saw very similar issues also during context precision/recall calculation) and also [#715
                  ](#715)\r\n- Sometimes the "verdict" envelop is omitted from the response: [#733
                  ](#733)\r\n- Sometimes the response is embedded in a superfluous envelope: [#668
                  ](#668)\r\n- It seems different models have issues with the "Attributed" keys: [#619
                  ](#619)\r\n- ...and numerous other bugs might be related to the weak JSON parsing.\r\n\r\n**Additional context**\r\n\r\nLangChain has a [robust implementation
                  ](https: //python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic) of instructing the models to return a JSON response conforming to a specific schema. The output format can be specified with pydantic data classes, the expected JSON schema is injected into the prompt, and the response is automatically parsed by pydantic. Additionally, a [retry mechanism](https://python.langchain.com/docs/modules/model_io/output_parsers/types/retry) can be included for even more robust JSON parsing.\r\n\r\nConsidering that Ragas is already using LangChain, implementing this feature would not create addition dependencies to the project.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/761/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/761/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/759',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/759/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/759/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/759/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/759',
  'id': 2187897350,
  'node_id': 'PR_kwDOJgX1Gs5ptpV-',
  'number': 759,
  'title': 'fix: Recursive Key Retrieval to Handle Unspecified JSON Schema Types and Fix for Int Value Returns about context_precision and context_recall',
  'user': {'login': 'i-w-a',
   'id': 65731397,
   'node_id': 'MDQ6VXNlcjY1NzMxMzk3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/65731397?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/i-w-a',
   'html_url': 'https: //github.com/i-w-a',
   'followers_url': 'https: //api.github.com/users/i-w-a/followers',
   'following_url': 'https: //api.github.com/users/i-w-a/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/i-w-a/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/i-w-a/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/i-w-a/subscriptions',
   'organizations_url': 'https: //api.github.com/users/i-w-a/orgs',
   'repos_url': 'https: //api.github.com/users/i-w-a/repos',
   'events_url': 'https: //api.github.com/users/i-w-a/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/i-w-a/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-03-15T07: 34: 53Z',
  'updated_at': '2024-03-19T07: 01: 24Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/759',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/759',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/759.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/759.patch',
   'merged_at': None
                  },
  'body': "### Summary\r\nWhile utilizing the OpenAI API's GPT-4 turbo, I encountered an issue where JSON responses were returning with schema types that were not predefined. Additionally, despite specifying values as strings, some keys were returning integers. This pull request introduces a solution for both of these issues.\r\n\r\n### Changes\r\n- Implemented a recursive key retrieval function that can handle JSON objects of any structure, ensuring robust parsing regardless of the schema.\r\n- Added a type-checking mechanism that converts integers back to strings if the original schema specified string types for key values.\r\n\r\n### Rationale\r\nThe flexibility of the JSON response format from the GPT-4 turbo endpoint requires a more dynamic approach to parsing. The recursive method ensures that our application can seamlessly handle any JSON structure without the need for predefined schemas. Furthermore, the integrity of the data types is crucial for downstream processes, hence the necessity for a type-correction mechanism.\r\n\r\n### Impact\r\nThis update will enhance the reliability of our system when interfacing with the OpenAI API and provide a more consistent data handling experience, especially in cases where the API's response structure is unpredictable.\r\n\r\nPlease review the changes and provide your feedback.\r\n\r\nThank you!\r\n\r\ni-w-a",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/759/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/759/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/752',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/752/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/752/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/752/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/752',
  'id': 2184063221,
  'node_id': 'I_kwDOJgX1Gs6CLij1',
  'number': 752,
  'title': 'Getting exception when trying to generate test data with Bedrock and Anthropic claude2 combination',
  'user': {'login': 'sabypc',
   'id': 163312200,
   'node_id': 'U_kgDOCbvySA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/163312200?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/sabypc',
   'html_url': 'https: //github.com/sabypc',
   'followers_url': 'https: //api.github.com/users/sabypc/followers',
   'following_url': 'https: //api.github.com/users/sabypc/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/sabypc/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/sabypc/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/sabypc/subscriptions',
   'organizations_url': 'https: //api.github.com/users/sabypc/orgs',
   'repos_url': 'https: //api.github.com/users/sabypc/repos',
   'events_url': 'https: //api.github.com/users/sabypc/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/sabypc/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-03-13T13: 46: 56Z',
  'updated_at': '2024-08-02T04: 13: 46Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '[Yes
                  ] I have checked the [documentation
                  ](https: //docs.ragas.io/) and related resources and couldn\'t resolve my bug.\r\n\r\n**Describe the bug**\r\nA clear and concise description of what the bug is.\r\n\r\nRagas version: Latest as of today.\r\nPython version: Python3\r\n\r\n**Code to Reproduce**\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\n\r\n# generator with anthropic models\r\n\r\n```py\r\ntest_generator = TestsetGenerator(\r\n    generator_llm=ragas_bedrock_model,\r\n    critic_llm=ragas_bedrock_model,\r\n    embeddings=ragas_bedrock_embeddings,\r\n    docstore=ragas_docstore,\r\n)\r\n\r\ntestset = test_generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},with_debugging_logs=True,is_async=True, raise_exceptions=True)\r\n```\r\n\r\n**Error trace**\r\n```\r\nException in thread Thread-10:\r\nTraceback (most recent call last):\r\n  File "/opt/conda/lib/python3.10/threading.py", line 1016, in _bootstrap_inner\r\n    self.run()\r\n  File "/root/SabyWorkspace/ragas/src/ragas/executor.py", line 96, in run\r\n    results = self.loop.run_until_complete(self._aresults())\r\n  File "/opt/conda/lib/python3.10/asyncio/base_events.py", line 646, in run_until_complete\r\n    return future.result()\r\n  File "/root/SabyWorkspace/ragas/src/ragas/executor.py", line 84, in _aresults\r\n    raise e\r\n  File "/root/SabyWorkspace/ragas/src/ragas/executor.py", line 79, in _aresults\r\n    r = await future\r\n  File "/opt/conda/lib/python3.10/asyncio/tasks.py", line 571, in _wait_for_one\r\n    return f.result()  # May raise f.exception().\r\n  File "/root/SabyWorkspace/ragas/src/ragas/executor.py", line 38, in sema_coro\r\n    return await coro\r\n  File "/root/SabyWorkspace/ragas/src/ragas/executor.py", line 112, in wrapped_callable_async\r\n    return counter, await callable(*args, **kwargs)\r\n  File "/root/SabyWorkspace/ragas/src/ragas/testset/evolutions.py", line 141, in evolve\r\n    ) = await self._aevolve(current_tries, current_nodes)\r\n  File "/root/SabyWorkspace/ragas/src/ragas/testset/evolutions.py", line 291, in _aevolve\r\n    return await self.aretry_evolve(\r\n  File "/root/SabyWorkspace/ragas/src/ragas/testset/evolutions.py", line 119, in aretry_evolve\r\n    return await self._aevolve(current_tries, current_nodes)\r\n  File "/root/SabyWorkspace/ragas/src/ragas/testset/evolutions.py", line 287, in _aevolve\r\n    merged_node = self.merge_nodes(current_nodes)\r\n  File "/root/SabyWorkspace/ragas/src/ragas/testset/evolutions.py", line 73, in merge_nodes\r\n    new_node = Node(\r\n  File "/opt/conda/lib/python3.10/site-packages/langchain_core/documents/base.py", line 22, in __init__\r\n    super().__init__(page_content=page_content, **kwargs)\r\n  File "/opt/conda/lib/python3.10/site-packages/langchain_core/load/serializable.py", line 120, in __init__\r\n    super().__init__(**kwargs)\r\n  File "pydantic/main.py", line 341, in pydantic.main.BaseModel.__init__\r\npydantic.error_wrappers.ValidationError: 2 validation errors for Node\r\nkeyphrases -> 0\r\n  str type expected (type=type_error.str)\r\nkeyphrases -> 1\r\n  str type expected (type=type_error.str)\r\n**Expected behavior**\r\nWe would expect to get some test data ( questions, answers,with_groundth etc)\r\n```\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/752/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/752/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/749',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/749/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/749/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/749/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/749',
  'id': 2183063449,
  'node_id': 'I_kwDOJgX1Gs6CHueZ',
  'number': 749,
  'title': 'How to use it in js langchain environment?',
  'user': {'login': 'jung-han',
   'id': 35371660,
   'node_id': 'MDQ6VXNlcjM1MzcxNjYw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/35371660?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jung-han',
   'html_url': 'https: //github.com/jung-han',
   'followers_url': 'https: //api.github.com/users/jung-han/followers',
   'following_url': 'https: //api.github.com/users/jung-han/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jung-han/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jung-han/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jung-han/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jung-han/orgs',
   'repos_url': 'https: //api.github.com/users/jung-han/repos',
   'events_url': 'https: //api.github.com/users/jung-han/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jung-han/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-03-13T03: 54: 13Z',
  'updated_at': '2024-05-31T06: 11: 31Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "[x] I checked the [documentation](https://docs.ragas.io/) and related resources and couldn't find an answer to my question.\r\n\r\n**Your Question**\r\nHello, ragas Team!\r\nI am very impressed to see that they are making really good tools.\r\nI am creating a service using RAG, and while looking for a good evaluation tool, I ended up here.\r\n\r\nI am not an AI developer, so I am not familiar with Python and am creating an AI service based on JavaScript.\r\n(Seeing that most AI-related tools are provided in python, I am wondering if I should change the language. 🥲)\r\n\r\nFrom what I've found, I can't think of a way to test the model in a Langchain environment using JavaScript. \r\nCan you suggest a way to use Ragas? \r\n\r\nI'll wait for your reply. thanks!",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/749/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/749/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/729',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/729/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/729/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/729/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/729',
  'id': 2177325625,
  'node_id': 'PR_kwDOJgX1Gs5pJmms',
  'number': 729,
  'title': "Update generator.py with 'with_azureopenai'",
  'user': {'login': 'drumalv',
   'id': 43895121,
   'node_id': 'MDQ6VXNlcjQzODk1MTIx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/43895121?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/drumalv',
   'html_url': 'https: //github.com/drumalv',
   'followers_url': 'https: //api.github.com/users/drumalv/followers',
   'following_url': 'https: //api.github.com/users/drumalv/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/drumalv/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/drumalv/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/drumalv/subscriptions',
   'organizations_url': 'https: //api.github.com/users/drumalv/orgs',
   'repos_url': 'https: //api.github.com/users/drumalv/repos',
   'events_url': 'https: //api.github.com/users/drumalv/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/drumalv/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-03-09T17: 35: 31Z',
  'updated_at': '2024-03-12T07: 37: 35Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/729',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/729',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/729.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/729.patch',
   'merged_at': None
                  },
  'body': 'Add compatibility with AzureOpenAI to create testsets. I have test the function in a real case by my own.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/729/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/729/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/714',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/714/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/714/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/714/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/714',
  'id': 2171355511,
  'node_id': 'PR_kwDOJgX1Gs5o1N9f',
  'number': 714,
  'title': 'Function _calculate_average_precision() modified to cover when LLM provides a bad JSON format',
  'user': {'login': 'rodralez',
   'id': 5432060,
   'node_id': 'MDQ6VXNlcjU0MzIwNjA=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5432060?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/rodralez',
   'html_url': 'https: //github.com/rodralez',
   'followers_url': 'https: //api.github.com/users/rodralez/followers',
   'following_url': 'https: //api.github.com/users/rodralez/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/rodralez/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/rodralez/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/rodralez/subscriptions',
   'organizations_url': 'https: //api.github.com/users/rodralez/orgs',
   'repos_url': 'https: //api.github.com/users/rodralez/repos',
   'events_url': 'https: //api.github.com/users/rodralez/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/rodralez/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2024-03-06T12: 08: 20Z',
  'updated_at': '2024-03-06T16: 50: 39Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/714',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/714',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/714.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/714.patch',
   'merged_at': None
                  },
  'body': 'The modified version of the `_calculate_average_precision` function introduces several improvements and changes compared to the original version. Here\'s a detailed comparison highlighting these changes:\r\n\r\n1. **Debugging Support with Processed Responses**: \r\n   - **Original**: Directly processes the `json_responses` list within the list comprehensions, with no provision for debugging or inspecting the processed inputs.\r\n   - **Modified**: Introduces `processed_json_responses`, a separate list to store processed responses. This change aids in debugging by keeping a record of processed inputs, making it easier to understand how each input was handled.\r\n\r\n2. **Enhanced Error Handling with Print Statements**:\r\n   - **Original**: No explicit error messages or logging for specific cases like non-dict items or missing verdict keys within the input dictionaries.\r\n   - **Modified**: Adds print statements to log warnings when non-dict items are encountered or when a verdict is missing from a response. These enhancements improve the function\'s usability by providing immediate feedback on what might be wrong with the input data.\r\n\r\n3. **Flexibility with Nested Verification Key**:\r\n   - **Original**: Assumes a flat structure for the input dictionaries, directly looking for a `verdict` key at the top level.\r\n   - **Modified**: Adds flexibility to handle a potentially nested structure by checking for a `verification` key, which, if present and is a dictionary, is used to extract the verdict information. This adjustment allows the function to work with a broader range of input formats. This modification was done to deal with Azure OpenAI responses.\r\n\r\n4. **Robustness in Handling Invalid Verdict Values**:\r\n   - **Original**: Only considers responses with a `verdict` value explicitly equal to "1" as valid, implicitly treating all other cases as invalid (resulting in a `np.nan`).\r\n   - **Modified**: Explicitly checks if the `verdict` string is either "0" or "1", ensuring that only these values are considered valid and improving the handling of invalid data by appending `np.nan` for verdicts that do not match these criteria.\r\n\r\n5. **Use of `np.nansum` for Numerator and Denominator Calculation**:\r\n   - **Original**: Uses Python\'s built-in `sum` function which could lead to incorrect results if `np.nan` values are present in the `verdict_list`.\r\n   - **Modified**: Replaces `sum` with `np.nansum` for calculating both the numerator and the denominator. This choice correctly handles `np.nan` values by ignoring them in the sum, thus ensuring that the calculation of the average precision score is not affected by missing data.\r\n\r\n6. **Improved Numerator Calculation Logic**:\r\n   - **Original**: Uses a comprehension inside a `sum` call without directly addressing potential issues with NaN values in the computation.\r\n   - **Modified**: The use of `np.nansum` in the numerator calculation makes the approach more robust, correctly handling `np.nan` values during the computation process.\r\n\r\nThese improvements enhance the function\'s flexibility, error handling, and robustness, particularly in dealing with varying input formats and missing or invalid data.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/714/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/714/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/690',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/690/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/690/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/690/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/690',
  'id': 2165134877,
  'node_id': 'I_kwDOJgX1Gs6BDVYd',
  'number': 690,
  'title': 'max retries exceeded for SimpleEvolution ',
  'user': {'login': 'AshuKhandave',
   'id': 121536451,
   'node_id': 'U_kgDOBz5_ww',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/121536451?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/AshuKhandave',
   'html_url': 'https: //github.com/AshuKhandave',
   'followers_url': 'https: //api.github.com/users/AshuKhandave/followers',
   'following_url': 'https: //api.github.com/users/AshuKhandave/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/AshuKhandave/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/AshuKhandave/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/AshuKhandave/subscriptions',
   'organizations_url': 'https: //api.github.com/users/AshuKhandave/orgs',
   'repos_url': 'https: //api.github.com/users/AshuKhandave/repos',
   'events_url': 'https: //api.github.com/users/AshuKhandave/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/AshuKhandave/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 5,
  'created_at': '2024-03-03T04: 21: 36Z',
  'updated_at': '2024-05-10T01: 29: 28Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': "from ragas.testset import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\n\r\ntest_generator = TestsetGenerator(\r\n    generator_llm=bedrock_model,\r\n    critic_llm=bedrock_model,\r\n    embeddings=bedrock_embeddings,\r\n    docstore=docstore,\r\n)\r\n\r\ndistributions = {simple: 0.5, reasoning: 0.4, multi_context: 0.1}\r\n\r\ntestset = test_generator.generate_with_langchain_docs(\r\n    documents=documents, test_size=15, distributions=distributions\r\n)\r\n\r\nafter running this code the embeddings are created but there seems to be issue with generating the test data.\r\n![image](https://github.com/explodinggradients/ragas/assets/121536451/4c53b116-ebb2-429e-894f-17b2599f77a3)\r\n\r\nI'm trying to create the test dataset using llama2 from amazon bedrock. ",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/690/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/690/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/664',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/664/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/664/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/664/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/664',
  'id': 2156418250,
  'node_id': 'I_kwDOJgX1Gs6AiFTK',
  'number': 664,
  'title': 'Task was destroyed but it is pending!',
  'user': {'login': 'pxiongw',
   'id': 14227058,
   'node_id': 'MDQ6VXNlcjE0MjI3MDU4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/14227058?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/pxiongw',
   'html_url': 'https: //github.com/pxiongw',
   'followers_url': 'https: //api.github.com/users/pxiongw/followers',
   'following_url': 'https: //api.github.com/users/pxiongw/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/pxiongw/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/pxiongw/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/pxiongw/subscriptions',
   'organizations_url': 'https: //api.github.com/users/pxiongw/orgs',
   'repos_url': 'https: //api.github.com/users/pxiongw/repos',
   'events_url': 'https: //api.github.com/users/pxiongw/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/pxiongw/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 13,
  'created_at': '2024-02-27T12: 05: 49Z',
  'updated_at': '2024-06-26T14: 15: 35Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\nI use ragas to evaluate my project,the dataset comes from the project, when I use 100 number of data,it is normal and could get the evaluate result.Then when I use more than 300 number of data,it raise exception as follow. I suspect there is something wrong with asyncio in ragas framework.\r\n\r\nException ignored in: <coroutine object Executor.wrap_callable_with_index.<locals>.wrapped_callable_async at 0x7fc4761f9310>\r\nTraceback (most recent call last):\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/ragas/executor.py", line 91, in wrapped_callable_async\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/ragas/metrics/base.py", line 91, in ascore\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/ragas/metrics/base.py", line 87, in ascore\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/ragas/metrics/_context_precision.py", line 129, in _ascore\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/ragas/llms/base.py", line 92, in generate\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/tenacity/_asyncio.py", line 88, in async_wrapped\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/tenacity/_asyncio.py", line 47, in __call__\r\n  File "/home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/tenacity/__init__.py", line 334, in iter\r\nKeyError: \'idle_for\'\r\n........\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'context_recall-316\' coro=<Executor.wrap_callable_with_index.<locals>.wrapped_callable_async() done, defined at /home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/ragas/executor.py: 90> wait_for=<Future cancelled> cb=[as_completed.<locals>._on_completion() at /home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/asyncio/tasks.py: 558
                  ]>\r\nTask was destroyed but it is pending!\r\ntask: <Task pending name=\'context_precision-316\' coro=<Executor.wrap_callable_with_index.<locals>.wrapped_callable_async() done, defined at /home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/site-packages/ragas/executor.py: 90> wait_for=<Future cancelled> cb=[as_completed.<locals>._on_completion() at /home/gitlab-runner/anaconda3/envs/qa/lib/python3.10/asyncio/tasks.py: 558
                  ]>\r\n\r\n\r\nRagas version: 0.1.2\r\nPython version: 3.10.9\r\n\r\n**Code to Reproduce**\r\nimport nest_asyncio\r\nnest_asyncio.apply()\r\n\r\ndef run_evaluate(dataset,llm):\r\n    result = evaluate(\r\n        dataset=dataset,\r\n        metrics=metrics,\r\n        llm=llm,\r\n        embeddings=build_embeddings(model_name),\r\n        is_async=True,\r\n        raise_exceptions=True,\r\n    )\r\n\r\n**Error trace**\r\n\r\n**Expected behavior**\r\nA clear and concise description of what you expected to happen.\r\n\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/664/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/664/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/662',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/662/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/662/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/662/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/662',
  'id': 2155612144,
  'node_id': 'I_kwDOJgX1Gs6AfAfw',
  'number': 662,
  'title': 'Testset Generation: Is going into continuous loop ',
  'user': {'login': 'Vtej98',
   'id': 99729941,
   'node_id': 'U_kgDOBfHCFQ',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/99729941?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Vtej98',
   'html_url': 'https: //github.com/Vtej98',
   'followers_url': 'https: //api.github.com/users/Vtej98/followers',
   'following_url': 'https: //api.github.com/users/Vtej98/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Vtej98/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Vtej98/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Vtej98/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Vtej98/orgs',
   'repos_url': 'https: //api.github.com/users/Vtej98/repos',
   'events_url': 'https: //api.github.com/users/Vtej98/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Vtej98/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 19,
  'created_at': '2024-02-27T04: 12: 25Z',
  'updated_at': '2024-08-24T11: 11: 18Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Question**\r\nI am not sure, what\'s happening. I see that the testset data isn\'t generating and just going into a continuous loop, exhausting the tokens of openAI \r\n\r\n**My Code**\r\nfrom ragas.testset.generator import TestsetGenerator\r\nfrom ragas.testset.evolutions import simple, reasoning, multi_context\r\nfrom langchain.document_loaders import DirectoryLoader\r\nimport os\r\n\r\n\r\nOPENAI_API_KEY = "sk-xxxxxx"\r\nos.environ[
                        "OPENAI_API_KEY"
                  ] = OPENAI_API_KEY\r\n\r\ndef load_docs(directory):\r\n    loader = DirectoryLoader(directory)\r\n    documents = loader.load()\r\n    return documents\r\n\r\ndocuments = load_docs("./source")\r\nfor document in documents:\r\n    document.metadata[\'file_name\'
                  ] = document.metadata[\'source\'
                  ]\r\n\r\n\r\ngenerator = TestsetGenerator.with_openai()\r\n\r\n\r\ntestset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25
                  })\r\ntestset.to_pandas()\r\ntestset.to_pandas().to_excel(\'output_data.xlsx\', index=False)\r\n\r\n**Additional context**\r\nI did explore the code, and found that it has retry mechanisms, of 15 retries and a wait time of 90 seconds. But I still waited for a long time no response of completion. \r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/662/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/662/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/659',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/659/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/659/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/659/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/659',
  'id': 2152966472,
  'node_id': 'PR_kwDOJgX1Gs5n2d4B',
  'number': 659,
  'title': 'Add a mock for test_json_load',
  'user': {'login': 'pberger514',
   'id': 9138881,
   'node_id': 'MDQ6VXNlcjkxMzg4ODE=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/9138881?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/pberger514',
   'html_url': 'https: //github.com/pberger514',
   'followers_url': 'https: //api.github.com/users/pberger514/followers',
   'following_url': 'https: //api.github.com/users/pberger514/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/pberger514/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/pberger514/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/pberger514/subscriptions',
   'organizations_url': 'https: //api.github.com/users/pberger514/orgs',
   'repos_url': 'https: //api.github.com/users/pberger514/repos',
   'events_url': 'https: //api.github.com/users/pberger514/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/pberger514/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 0,
  'created_at': '2024-02-25T22: 17: 55Z',
  'updated_at': '2024-04-13T19: 21: 08Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'draft': True,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/659',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/659',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/659.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/659.patch',
   'merged_at': None
                  },
  'body': "Here's a draft of https://github.com/explodinggradients/ragas/issues/606 for OpenAI. Happy to discuss on how to improve/expand this.",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/659/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/659/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/657',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/657/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/657/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/657/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/657',
  'id': 2152371608,
  'node_id': 'PR_kwDOJgX1Gs5n0qqc',
  'number': 657,
  'title': 'Removed the temperature parameter',
  'user': {'login': 'Kirushikesh',
   'id': 49152921,
   'node_id': 'MDQ6VXNlcjQ5MTUyOTIx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/49152921?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Kirushikesh',
   'html_url': 'https: //github.com/Kirushikesh',
   'followers_url': 'https: //api.github.com/users/Kirushikesh/followers',
   'following_url': 'https: //api.github.com/users/Kirushikesh/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Kirushikesh/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Kirushikesh/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Kirushikesh/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Kirushikesh/orgs',
   'repos_url': 'https: //api.github.com/users/Kirushikesh/repos',
   'events_url': 'https: //api.github.com/users/Kirushikesh/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Kirushikesh/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 12,
  'created_at': '2024-02-24T15: 49: 27Z',
  'updated_at': '2024-06-11T14: 29: 54Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/657',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/657',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/657.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/657.patch',
   'merged_at': None
                  },
  'body': '## **User description**\naddressing the issue #656 \r\n\r\nThis PR removes all the occurrence of temperature keyword in LangChain LLM.\n\n\n___\n\n## **Description**\n- Removed the `temperature` parameter from the `BaseRagasLLM` class methods to align with issue #656.\n- Deleted the `get_temperature` method as it is no longer needed.\n- Updated tests to reflect the removal of the `temperature` parameter from method signatures.\n\n\n___\n\n## **Changes walkthrough**\n<table><thead><tr><th></th><th align="left">Relevant files</th></tr></thead><tbody><tr><td><strong>Enhancement</strong></td><td><table>\n<tr>\n  <td>\n    <details>\n      <summary><strong>base.py</strong><dd><code>Remove temperature parameter from BaseRagasLLM</code>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>\n<hr>\n\nsrc/ragas/llms/base.py\n<li>Removed the <code>get_temperature</code> method.<br> <li> Removed the <code>temperature</code> parameter from various methods.<br> <li> Simplified the <code>generate</code> and <code>agenerate_text</code> methods by removing <br>temperature handling logic.<br>\n\n\n</details>\n    \n\n  </td>\n  <td><a href="https://github.com/explodinggradients/ragas/pull/657/files#diff-f73302c30c4d4472a2acbbb5ee482dea0c869dd519ae2060f92136f36c2a6be0">+0/-17</a>&nbsp; &nbsp; </td>\n</tr>                    \n</table></td></tr><tr><td><strong>Tests</strong></td><td><table>\n<tr>\n  <td>\n    <details>\n      <summary><strong>conftest.py</strong><dd><code>Update test mocks to reflect temperature parameter removal</code>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>\n<hr>\n\ntests/conftest.py\n<li>Updated mock <code>generate_text</code> and <code>agenerate_text</code> methods to remove the <br><code>temperature</code> parameter.<br>\n\n\n</details>\n    \n\n  </td>\n  <td><a href="https://github.com/explodinggradients/ragas/pull/657/files#diff-e52e4ddd58b7ef887ab03c04116e676f6280b824ab7469d5d3080e5cba4f2128">+3/-3</a>&nbsp; &nbsp; &nbsp; </td>\n</tr>                    \n\n<tr>\n  <td>\n    <details>\n      <summary><strong>test_llm.py</strong><dd><code>Update unit tests for temperature parameter removal</code>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </dd></summary>\n<hr>\n\ntests/unit/llms/test_llm.py\n<li>Updated mock <code>generate_text</code> and <code>agenerate_text</code> methods to remove the <br><code>temperature</code> parameter.<br>\n\n\n</details>\n    \n\n  </td>\n  <td><a href="https://github.com/explodinggradients/ragas/pull/657/files#diff-e069ae28490bf61d2825d8febd4bec876bf8e33dcaf505d35e463453cf20fb61">+3/-3</a>&nbsp; &nbsp; &nbsp; </td>\n</tr>                    \n</table></td></tr></tr></tbody></table><details>\n<summary><strong>💡 Usage Guide</strong></summary>\n\n### Checking Your Pull Request\nEvery time you make a pull request, our system automatically looks through it. We check for security issues, mistakes in how you\'re setting up your infrastructure, and common code problems. We do this to make sure your changes are solid and won\'t cause any trouble later.\n\n### Talking to CodeAnt AI\nGot a question or need a hand with something in your pull request? You can easily get in touch with CodeAnt AI right here. Just type the following in a comment on your pull request, and replace "Your question here" with whatever you want to ask:\n<pre>\n<code>/codeantai ask: Your question here</code>\n</pre>\nThis lets you have a chat with CodeAnt AI about your pull request, making it easier to understand and improve your code.\n\n</details>\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/657/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/657/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/656',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/656/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/656/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/656/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/656',
  'id': 2152370758,
  'node_id': 'I_kwDOJgX1Gs6ASpJG',
  'number': 656,
  'title': "[R-273] 'temperature' parameter in LangchainLLMWrapper.generate_text causing issues",
  'user': {'login': 'Kirushikesh',
   'id': 49152921,
   'node_id': 'MDQ6VXNlcjQ5MTUyOTIx',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/49152921?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Kirushikesh',
   'html_url': 'https: //github.com/Kirushikesh',
   'followers_url': 'https: //api.github.com/users/Kirushikesh/followers',
   'following_url': 'https: //api.github.com/users/Kirushikesh/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Kirushikesh/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Kirushikesh/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Kirushikesh/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Kirushikesh/orgs',
   'repos_url': 'https: //api.github.com/users/Kirushikesh/repos',
   'events_url': 'https: //api.github.com/users/Kirushikesh/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Kirushikesh/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        },
                        {'id': 6872372831,
    'node_id': 'LA_kwDOJgX1Gs8AAAABmaAWXw',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/linear',
    'name': 'linear',
    'color': '4941DA',
    'default': False,
    'description': 'Created by Linear-GitHub Sync'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 7,
  'created_at': '2024-02-24T15: 46: 58Z',
  'updated_at': '2024-06-13T04: 52: 16Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the bug**\r\n\r\nLangchainLLMWrapper has .generate_text() function which further calls .generate_prompt() of the underlying LLM. The LangchainLLMWrapper passes \'temperature\' parameter in .generate_prompt() function which causes the following issues,\r\n\r\n1. temperature parameter is not affecting the response when using HuggingFace LLM\r\n2. Some Langchain Extensions like [IBM Generative AI
                  ](https: //github.com/IBM/ibm-generative-ai/tree/main) doesn\'t support temperature parameter to be passed in .generate_prompt() function.\r\n\r\nSince when initialising an LangChain LLM we can pass the temperature as a parameter, it is not needed to be supplied additionally in LangchainLLMWrapper. \r\n\r\nFor ex in HuggingFacePipeline, you can specify the temperature when initialization using:\r\n`pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, temperature=1)`\r\n\r\nOr when using IBM LLM you can specify the temperature by:\r\n```\r\nllm = LangChainInterface(\r\n        model_id=\'google/flan-t5-xl\',\r\n        client=Client(credentials=Credentials.from_env()),\r\n        parameters=TextGenerationParameters(\r\n                  decoding_method=DecodingMethod.SAMPLE,\r\n                  max_new_tokens=1000,\r\n                  min_new_tokens=1,\r\n                  temperature=0.2,\r\n                  top_k=20,\r\n                  top_p=1,\r\n                  random_seed=42,\r\n                  repetition_penalty = 1.1\r\n              )\r\n)\r\n```\r\n\r\nRagas version: 0.1.1\r\nPython version: 3.10.6\r\n\r\n**Code to Reproduce**\r\nThe following code explains why \'temperature\' parameter not affecting the response in HuggingFaceLLM\r\n```\r\nfrom langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\r\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\r\n\r\nfrom ragas.llms.base import BaseRagasLLM, LangchainLLMWrapper\r\nfrom ragas.run_config import RunConfig\r\nfrom ragas.llms.prompt import PromptValue\r\n\r\nmodel_id = "gpt2"\r\ntokenizer = AutoTokenizer.from_pretrained(model_id)\r\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\r\npipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=100)\r\nhf_llm = HuggingFacePipeline(pipeline=pipe)\r\n\r\npv = PromptValue(prompt_str=\'hi, how are you\')\r\nrun_config = RunConfig()\r\nragas_hf_llm = LangchainLLMWrapper(hf_llm, run_config=run_config)\r\nragas_hf_llm.generate_text(\r\n    prompt=pv,\r\n    stop=None,\r\n    temperature=0\r\n)\r\n\r\n# Output\r\nLLMResult(generations=[[Generation(text=\' feeling today?!\\n\\nThe sun was shining, and there was only a small light, but no more than a single drop from the sky. The clouds were white with white fringing, which they looked like a cloud filled with smoke. It covered the place with the smoke, and the man standing before them had a sword, as a symbol of protection. He was only slightly more than a hundred lightyears away from the Sun and the Moon.\\n\\n"Fuu...what?"\\n\\n\')]], llm_output=None, run=[RunInfo(run_id=UUID(\'cbd105d1-ab2c-4069-a6f3-20fc9159443e\'))])\r\n```\r\nIn the above code I initialised the HuggingFacePipeline with gpt-2 model and wrapped it around ragas LangchainLLMWrapper and i was passing \'temperature=0\' when calling .generate_text(), ideally this should generate error because 0 temperature is not accepted in [HuggingFace](https://huggingface.co/Open-Orca/oo-phi-1_5/discussions/2#6540fe460a4e554c1bfe9626).\r\n\r\nYou can also check by passing temperature as 99 in .generate_text() and its not raising any exception too for this high value of temperature. Thus its evident that temperature in .generate_text is not affecting the HuggingFace LLM. Also user can sent the temperature in pipeline() function so need to have an additional temperature in .generate_text() function.\r\n\r\nThe following code explains why passing \'temperature\' raises an error in IBM LLM:\r\n```\r\nfrom genai import Client, Credentials\r\nfrom genai.extensions.llama_index import IBMGenAILlamaIndex\r\n\r\nfrom genai.extensions.langchain import LangChainInterface\r\nfrom genai.extensions.langchain.chat_llm import LangChainChatInterface\r\nfrom genai.extensions.langchain import LangChainEmbeddingsInterface\r\nfrom genai.schema import (\r\n    DecodingMethod,\r\n    TextGenerationParameters,\r\n    TextEmbeddingParameters\r\n)\r\n\r\nllm = LangChainInterface(\r\n        model_id=\'google/flan-t5-xl\',\r\n        client=Client(credentials=Credentials.from_env()),\r\n        parameters=TextGenerationParameters(\r\n                  decoding_method=DecodingMethod.SAMPLE,\r\n                  max_new_tokens=1000,\r\n                  min_new_tokens=1,\r\n                  temperature=0.2,\r\n                  top_k=20,\r\n                  top_p=1,\r\n                  random_seed=42,\r\n                  repetition_penalty = 1.1\r\n              )\r\n)\r\n\r\nfrom ragas.llms.base import BaseRagasLLM, LangchainLLMWrapper\r\nfrom ragas.run_config import RunConfig\r\nfrom ragas.llms.prompt import PromptValue\r\n\r\npv = PromptValue(prompt_str=\'hi, how are you\')\r\nrun_config = RunConfig()\r\nragas_ibm_llm = LangchainLLMWrapper(llm, run_config=run_config)\r\nragas_ibm_llm.generate_text(\r\n    prompt=pv,\r\n    stop=None,\r\n    temperature=99\r\n)\r\n\r\n# Error Trace\r\n\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\nInput In [16], in <cell line: 1>()\r\n----> 1 ragas_ibm_llm.generate_text(\r\n      2     prompt=pv,\r\n      3     stop=None,\r\n      4     temperature=99\r\n      5 )\r\n\r\nFile /dccstor/kirushikesh/.conda/guardrails/lib/python3.10/site-packages/ragas/llms/base.py:147, in LangchainLLMWrapper.generate_text(self, prompt, n, temperature, stop, callbacks)\r\n    139     return self.langchain_llm.generate_prompt(\r\n    140         prompts=[prompt],\r\n    141         n=n,\r\n   (...)\r\n    144         callbacks=callbacks,\r\n    145     )\r\n    146 else:\r\n--> 147     result = self.langchain_llm.generate_prompt(\r\n    148         prompts=[prompt] * n,\r\n    149         temperature=temperature,\r\n    150         stop=stop,\r\n    151         callbacks=callbacks,\r\n    152     )\r\n    153     # make LLMResult.generation appear as if it was n_completions\r\n    154     # note that LLMResult.runs is still a list that represents each run\r\n    155     generations = [[g[0] for g in result.generations]]\r\n\r\nFile /dccstor/kirushikesh/.conda/guardrails/lib/python3.10/site-packages/langchain_core/language_models/llms.py:530, in BaseLLM.generate_prompt(self, prompts, stop, callbacks, **kwargs)\r\n    522 def generate_prompt(\r\n    523     self,\r\n    524     prompts: List[PromptValue],\r\n   (...)\r\n    527     **kwargs: Any,\r\n    528 ) -> LLMResult:\r\n    529     prompt_strings = [p.to_string() for p in prompts]\r\n--> 530     return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\r\n\r\nFile /dccstor/kirushikesh/.conda/guardrails/lib/python3.10/site-packages/langchain_core/language_models/llms.py:703, in BaseLLM.generate(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\r\n    687         raise ValueError(\r\n    688             "Asked to cache, but no cache found at `langchain.cache`."\r\n    689         )\r\n    690     run_managers = [\r\n    691         callback_manager.on_llm_start(\r\n    692             dumpd(self),\r\n   (...)\r\n    701         )\r\n    702     ]\r\n--> 703     output = self._generate_helper(\r\n    704         prompts, stop, run_managers, bool(new_arg_supported), **kwargs\r\n    705     )\r\n    706     return output\r\n    707 if len(missing_prompts) > 0:\r\n\r\nFile /dccstor/kirushikesh/.conda/guardrails/lib/python3.10/site-packages/langchain_core/language_models/llms.py:567, in BaseLLM._generate_helper(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\r\n    565     for run_manager in run_managers:\r\n    566         run_manager.on_llm_error(e, response=LLMResult(generations=[]))\r\n--> 567     raise e\r\n    568 flattened_outputs = output.flatten()\r\n    569 for manager, flattened_output in zip(run_managers, flattened_outputs):\r\n\r\nFile /dccstor/kirushikesh/.conda/guardrails/lib/python3.10/site-packages/langchain_core/language_models/llms.py:554, in BaseLLM._generate_helper(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\r\n    544 def _generate_helper(\r\n    545     self,\r\n    546     prompts: List[str],\r\n   (...)\r\n    550     **kwargs: Any,\r\n    551 ) -> LLMResult:\r\n    552     try:\r\n    553         output = (\r\n--> 554             self._generate(\r\n    555                 prompts,\r\n    556                 stop=stop,\r\n    557                 # TODO: support multiple run managers\r\n    558                 run_manager=run_managers[0] if run_managers else None,\r\n    559                 **kwargs,\r\n    560             )\r\n    561             if new_arg_supported\r\n    562             else self._generate(prompts, stop=stop)\r\n    563         )\r\n    564     except BaseException as e:\r\n    565         for run_manager in run_managers:\r\n\r\nFile /dccstor/kirushikesh/.conda/guardrails/lib/python3.10/site-packages/genai/extensions/langchain/llm.py:190, in LangChainInterface._generate(self, prompts, stop, run_manager, **kwargs)\r\n    187     return final_result\r\n    188 else:\r\n    189     responses = list(\r\n--> 190         self.client.text.generation.create(**self._prepare_request(inputs=prompts, stop=stop, **kwargs))\r\n    191     )\r\n    192     for response in responses:\r\n    193         for result in response.results:\r\n\r\nTypeError: GenerationService.create() got an unexpected keyword argument \'temperature\'\r\n```\r\nAs the error trace explains that using Langchain wrapped IBM LLM doesn\'t support \'temperature\' as an additional parameter in .generate_prompt() function. The error resolves when i didn\'t pass temperature parameter. The same error occurs when calling \'evaluate()\' function in ragas with the same IBM LLM.\r\n\r\n**Expected behavior**\r\nA clear solution to this problem was to remove the temperature parameter in LangchainLLMWrapper\r\n```\r\nclass LangchainLLMWrapper(BaseRagasLLM):\r\n    ...\r\n    def generate_text(\r\n        self,\r\n        prompt: PromptValue,\r\n        n: int = 1,\r\n        stop: t.Optional[t.List[str]] = None,\r\n        callbacks: t.Optional[Callbacks] = None,\r\n    ) -> LLMResult:\r\n        if is_multiple_completion_supported(self.langchain_llm):\r\n            return self.langchain_llm.generate_prompt(\r\n                prompts=[prompt],\r\n                n=n,\r\n                stop=stop,\r\n                callbacks=callbacks,\r\n            )\r\n        else:\r\n            result = self.langchain_llm.generate_prompt(\r\n                prompts=[prompt] * n,\r\n                stop=stop,\r\n                callbacks=callbacks,\r\n            )\r\n            # make LLMResult.generation appear as if it was n_completions\r\n            # note that LLMResult.runs is still a list that represents each run\r\n            generations = [[g[0] for g in result.generations]]\r\n            result.generations = generations\r\n            return result\r\n    ...\r\n\r\n```\r\n\r\n**Additional context**\r\nAdd any other context about the problem here.\r\n\r\n<!-- PS: bugs suck but is also part of the process. We sincerely apologies for breaking your flow because of it, but don\'t worry, we got your back ❤️. We will get this fixed as fast as we can and thanks for helping us out by reporting it 🙏. -->\r\n\n\n<sub>[R-273](https://linear.app/exploding-gradients/issue/R-273/temperature-parameter-in-langchainllmwrappergenerate-text-causing)</sub>',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/656/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/656/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/645',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/645/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/645/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/645/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/645',
  'id': 2146283859,
  'node_id': 'I_kwDOJgX1Gs5_7bFT',
  'number': 645,
  'title': 'Extremly high gpu memory consumption for evluation with custom LLM (over 60 GBs)',
  'user': {'login': 'Johncrtz',
   'id': 75075593,
   'node_id': 'MDQ6VXNlcjc1MDc1NTkz',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/75075593?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Johncrtz',
   'html_url': 'https: //github.com/Johncrtz',
   'followers_url': 'https: //api.github.com/users/Johncrtz/followers',
   'following_url': 'https: //api.github.com/users/Johncrtz/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Johncrtz/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Johncrtz/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Johncrtz/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Johncrtz/orgs',
   'repos_url': 'https: //api.github.com/users/Johncrtz/repos',
   'events_url': 'https: //api.github.com/users/Johncrtz/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Johncrtz/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028647,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ5w',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/question',
    'name': 'question',
    'color': 'd876e3',
    'default': True,
    'description': 'Further information is requested'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-02-21T09: 46: 48Z',
  'updated_at': '2024-05-29T10: 53: 32Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Hello, i created a testset and run it through my RAG pipeline to get documents and a answer for each question. I now have 50 pairs of [question, ground_truth, documents, answer
                  ] that i want get the context_recall from. \r\n\r\nCode for my custom LLM:\r\n\r\n```\r\nfrom torch import cuda, bfloat16 \r\nfrom torch import nn\r\nimport transformers\r\nfrom transformers import BitsAndBytesConfig\r\nfrom transformers import LlamaTokenizer\r\nimport os\r\nfrom langchain.llms import HuggingFacePipeline \r\n\r\nmodel_id = \'meta-llama/Llama-2-7b-chat-hf\' #\'HuggingFaceH4/zephyr-7b-alpha\' \r\nhf_auth = \'...\' \r\nos.environ[\'OPENAI_API_KEY\'
                  ] = "..."\r\n\r\nbnb_config = transformers.BitsAndBytesConfig( load_in_4bit=True, \r\n                                             bnb_4bit_quant_type=\'nf4\',\r\n                                             bnb_4bit_use_double_quant=True, \r\n                                             bnb_4bit_compute_dtype=bfloat16 ) # begin initializing HF items, need auth token for these \r\n\r\nmodel_config = transformers.AutoConfig.from_pretrained( model_id, token=hf_auth )\r\n\r\nmodel = transformers.AutoModelForCausalLM.from_pretrained(model_id, \r\n                                                          trust_remote_code=True,\r\n                                                          config=model_config,\r\n                                                          quantization_config=bnb_config,\r\n                                                          device_map="auto",\r\n                                                          token=hf_auth ) \r\n\r\ntokenizer = LlamaTokenizer.from_pretrained("meta-llama/Llama-2-7b-chat-hf",token=hf_auth)\r\n\r\ngenerate_text = transformers.pipeline( model=model, tokenizer=tokenizer,\r\n                                      return_full_text=True, # langchain expects the full text\r\n                                      task=\'text-generation\', # we pass model parameters here too \r\n                                      temperature=0.01, # \'randomness\' of outputs,
                  0.0 is the min and 1.0 the max\r\n                                      max_new_tokens=512,\r\n                                      repetition_penalty=1.1, # without this output begins repeating\r\n                                      use_cache=True,\r\n                                      #num_return_sequences=1,\r\n                                      #eos_token_id=tokenizer.eos_token_id, \r\n                                      #pad_token_id=tokenizer.eos_token_id, \r\n                                     )\r\n\r\nllm = HuggingFacePipeline(pipeline=generate_text)``\r\n```\r\n\r\nAfter i do the evaluation:\r\n\r\n```\r\nfrom ragas import evaluate\r\nfrom ragas.metrics import (\r\n    context_recall,\r\n)\r\n\r\nresult = evaluate(\r\n    dataset,\r\n    metrics=[
                        ,\r\n        context_recall,\r\n
                  ],\r\n    llm = llm\r\n)\r\n\r\nresult\r\n```\r\n\r\nIt runs for a while and then ends up with the following error:\r\n\r\n`torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 1 has a total capacity of 31.74 GiB of which 29.44 MiB is free. Including non-PyTorch memory, this process has 31.70 GiB memory in use. Of the allocated memory 27.44 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https: //pytorch.org/docs/stable/notes/cuda.html#environment-variables)`\r\n\r\nI tried to customize pytorch memory config to make it more efficient, this however did no change:\r\n```\r\nimport os\r\nos.environ["PYTORCH_CUDA_ALLOC_CONF"] = "backend:native"\r\nos.environ["PYTORCH_CUDA_ALLOC_CONF"] = "garbage_collection_threshold:0.8"\r\nos.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"\r\nos.environ["PYTORCH_CUDA_ALLOC_CONF"] = "roundup_power2_divisions:[256:1,512:2,1024:4,>:8]"\r\nos.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:64"\r\n```\r\nHere you can see my memory allocation:\r\n\r\n```\r\nDevice 0: Tesla V100-SXM2-32GB\r\n  Total memory: 31.74 GB\r\n  Allocated memory: 22.81 GB\r\n  Cached memory: 31.10 GB\r\nDevice 1: Tesla V100-SXM2-32GB\r\n  Total memory: 31.74 GB\r\n  Allocated memory: 27.59 GB\r\n  Cached memory: 31.11 GB\r\n```\r\n\r\nIs there any way to do the evaluation with a custom LLM and not consume ungodly amounts of memory? imo 50 questions are not too much and i jus expected it to work. Does somone know how to handle this?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/645/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/645/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/633',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/633/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/633/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/633/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/633',
  'id': 2142472247,
  'node_id': 'PR_kwDOJgX1Gs5nSz1M',
  'number': 633,
  'title': 'rework classification and recall prompts for mixtral, add json respon…',
  'user': {'login': 'stepoibm',
   'id': 91447325,
   'node_id': 'MDQ6VXNlcjkxNDQ3MzI1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/91447325?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/stepoibm',
   'html_url': 'https: //github.com/stepoibm',
   'followers_url': 'https: //api.github.com/users/stepoibm/followers',
   'following_url': 'https: //api.github.com/users/stepoibm/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/stepoibm/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/stepoibm/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/stepoibm/subscriptions',
   'organizations_url': 'https: //api.github.com/users/stepoibm/orgs',
   'repos_url': 'https: //api.github.com/users/stepoibm/repos',
   'events_url': 'https: //api.github.com/users/stepoibm/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/stepoibm/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 3,
  'created_at': '2024-02-19T14: 14: 56Z',
  'updated_at': '2024-02-27T22: 16: 22Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/633',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/633',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/633.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/633.patch',
   'merged_at': None
                  },
  'body': 'Issue #608 \r\n\r\n* chg CONTEXT_PRECISION prompt to be more specifc what is expected. Reduces the likelihood of the model generating `verification : {...
                  }` instead of the expected json directly\r\n* chg CONTEXT_RECALL_RA prompt. Reduces likelihood of the model generating int 0 or 1 instead of the expected text "0" or "1".\r\n* chg CONTEXT_RECALL_RA examples to always expect an array instead of switching based on one or multiple statements. Prevents "classification: {...}" vs "classifications: {...}" being generated. Also checks whether "classifications: {...}" was generated as a key and extracts the payload.\r\n* added json payload in log in case of error\r\n* chg expected "Attributed" to "attributed" as the model randomly switches between those',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/633/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/633/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/596',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/596/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/596/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/596/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/596',
  'id': 2131679225,
  'node_id': 'I_kwDOJgX1Gs5_Dtf5',
  'number': 596,
  'title': 'Support for Async Embeddings via michaelfeil/infinity',
  'user': {'login': 'michaelfeil',
   'id': 63565275,
   'node_id': 'MDQ6VXNlcjYzNTY1Mjc1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/63565275?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/michaelfeil',
   'html_url': 'https: //github.com/michaelfeil',
   'followers_url': 'https: //api.github.com/users/michaelfeil/followers',
   'following_url': 'https: //api.github.com/users/michaelfeil/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/michaelfeil/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/michaelfeil/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/michaelfeil/subscriptions',
   'organizations_url': 'https: //api.github.com/users/michaelfeil/orgs',
   'repos_url': 'https: //api.github.com/users/michaelfeil/repos',
   'events_url': 'https: //api.github.com/users/michaelfeil/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/michaelfeil/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028629,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZ1Q',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/enhancement',
    'name': 'enhancement',
    'color': 'a2eeef',
    'default': True,
    'description': 'New feature or request'
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 10,
  'created_at': '2024-02-13T08: 03: 12Z',
  'updated_at': '2024-07-03T04: 43: 04Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Describe the Feature**\r\nI would like to integrate https: //github.com/michaelfeil/infinity for embeddings inference. This would automatically batch up concurrent request, uses flash-attention2, compatible with cuda, rocm, apple mps and cpu. \r\nDepending on the usage, you might expect between a 2.5x-22x throughput improvment / speedup over using the default hf embeddings langchain code.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/596/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/596/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/580',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/580/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/580/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/580/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/580',
  'id': 2126475345,
  'node_id': 'I_kwDOJgX1Gs5-v3BR',
  'number': 580,
  'title': 'Why faithfullness is NaN most of the times even when context and answer both makes sense.',
  'user': {'login': 'repl-mira-agarwal',
   'id': 86981996,
   'node_id': 'MDQ6VXNlcjg2OTgxOTk2',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/86981996?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/repl-mira-agarwal',
   'html_url': 'https: //github.com/repl-mira-agarwal',
   'followers_url': 'https: //api.github.com/users/repl-mira-agarwal/followers',
   'following_url': 'https: //api.github.com/users/repl-mira-agarwal/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/repl-mira-agarwal/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/repl-mira-agarwal/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/repl-mira-agarwal/subscriptions',
   'organizations_url': 'https: //api.github.com/users/repl-mira-agarwal/orgs',
   'repos_url': 'https: //api.github.com/users/repl-mira-agarwal/repos',
   'events_url': 'https: //api.github.com/users/repl-mira-agarwal/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/repl-mira-agarwal/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'shahules786',
   'id': 25312635,
   'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/shahules786',
   'html_url': 'https: //github.com/shahules786',
   'followers_url': 'https: //api.github.com/users/shahules786/followers',
   'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
   'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
   'repos_url': 'https: //api.github.com/users/shahules786/repos',
   'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'shahules786',
    'id': 25312635,
    'node_id': 'MDQ6VXNlcjI1MzEyNjM1',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/25312635?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/shahules786',
    'html_url': 'https: //github.com/shahules786',
    'followers_url': 'https: //api.github.com/users/shahules786/followers',
    'following_url': 'https: //api.github.com/users/shahules786/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/shahules786/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/shahules786/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/shahules786/subscriptions',
    'organizations_url': 'https: //api.github.com/users/shahules786/orgs',
    'repos_url': 'https: //api.github.com/users/shahules786/repos',
    'events_url': 'https: //api.github.com/users/shahules786/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/shahules786/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 17,
  'created_at': '2024-02-09T05: 04: 14Z',
  'updated_at': '2024-05-16T14: 11: 14Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'I am using Bedrock for my RAG and faithfullness is NaN most of the times even when context and answer both makes sense. The same problem is also there for the amnesty dataset shared in ragas docs.\r\n\r\nRagas version: 0.1.0\r\n\r\n**Code to Reproduce**\r\nfrom datasets import load_dataset\r\nfrom ragas import evaluate\r\n\r\namnesty_qa = load_dataset("explodinggradients/amnesty_qa",
                  "english_v2")\r\nresult = evaluate(amnesty_qa[
                        "eval"
                  ],metrics=[context_precision, faithfulness, answer_relevancy
                  ])\r\nresult.to_pandas()\r\n\r\n**Error trace**\r\n![image
                  ](https: //github.com/explodinggradients/ragas/assets/86981996/995b4d7d-1c97-4c18-abe5-b528bc25475f)\r\n\r\nI see similar issue in my own dataset as well, but it\'s not clear why failthfulness is NaN. Could you please give some clarity what is the issue here.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/580/reactions',
   'total_count': 2,
   '+1': 2,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/580/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/571',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/571/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/571/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/571/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/571',
  'id': 2122403348,
  'node_id': 'I_kwDOJgX1Gs5-gU4U',
  'number': 571,
  'title': "ModuleNotFoundError: No module named 'ragas.langchain'",
  'user': {'login': 'xinyang-handalindah',
   'id': 155500350,
   'node_id': 'U_kgDOCUS_Pg',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/155500350?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/xinyang-handalindah',
   'html_url': 'https: //github.com/xinyang-handalindah',
   'followers_url': 'https: //api.github.com/users/xinyang-handalindah/followers',
   'following_url': 'https: //api.github.com/users/xinyang-handalindah/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/xinyang-handalindah/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/xinyang-handalindah/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/xinyang-handalindah/subscriptions',
   'organizations_url': 'https: //api.github.com/users/xinyang-handalindah/orgs',
   'repos_url': 'https: //api.github.com/users/xinyang-handalindah/repos',
   'events_url': 'https: //api.github.com/users/xinyang-handalindah/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/xinyang-handalindah/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': {'login': 'jjmachan',
   'id': 5261489,
   'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/jjmachan',
   'html_url': 'https: //github.com/jjmachan',
   'followers_url': 'https: //api.github.com/users/jjmachan/followers',
   'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
   'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
   'repos_url': 'https: //api.github.com/users/jjmachan/repos',
   'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 17,
  'created_at': '2024-02-07T07: 52: 51Z',
  'updated_at': '2024-08-16T13: 07: 07Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': '**Description of the bug**\r\nUsing Google Colab.  After running `!pip install ragas`, unable to import RagasEvaluatorChain from ragas.langchain.evalchain.\r\nIt was okay last week (v0.0.22).\r\n\r\nRagas version: 0.1.0\r\nPython version: 3.10.12\r\n\r\n**Code to Reproduce**\r\n```\r\nfrom ragas.langchain.evalchain import RagasEvaluatorChain\r\nfrom ragas.metrics import AnswerCorrectness\r\n\r\nfrom ragas.metrics import (\r\n    faithfulness,\r\n    context_precision,\r\n    context_recall\r\n)\r\n\r\n# Customise the weight of answer_correctness\r\nanswer_correctness = AnswerCorrectness(\r\n    weights = [
                        0.1,
                        0.9
                  ] # 10% factuality and 90% semantic similarity check.\r\n)\r\n\r\ndef ragas_eval(result):\r\n  """\r\n  Define a chain to evaluate the result in terms of:\r\n  - faithfulness\r\n  - answer correctness\r\n  - context precision\r\n  - context recall\r\n\r\n  Then, return the scores.\r\n\r\n  """\r\n  metrics = [faithfulness, answer_correctness,\r\n             context_precision, context_recall
                  ]\r\n  scores = {}\r\n\r\n  for m in metrics:\r\n    eval_result = RagasEvaluatorChain(metric=m)(result)\r\n    scores[f"{m.name}_score"
                  ] = round(eval_result[m.name+\'_score\'
                  ],
                  2)\r\n  return scores\r\n\r\n```\r\n**Error trace**\r\n```\r\n---------------------------------------------------------------------------\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n[<ipython-input-13-d21d7383e19b>
                  ](https: //localhost:8080/#) in <cell line: 1>()\r\n----> 1 from ragas.langchain import RagasEvaluatorChain\r\n      2 from ragas.metrics import AnswerCorrectness\r\n      3 \r\n      4 from ragas.metrics import (\r\n      5     faithfulness,\r\n\r\nModuleNotFoundError: No module named \'ragas.langchain\'\r\n\r\n```\r\n\r\n**Expected behavior**\r\nLast Week I was still able to import the "RagasEvaluatorChain" from ragas.langchain.evalchain, but encounter this error today.\r\n',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/571/reactions',
   'total_count': 4,
   '+1': 4,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/571/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/402',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/402/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/402/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/402/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/402',
  'id': 2052301183,
  'node_id': 'I_kwDOJgX1Gs56U6F_',
  'number': 402,
  'title': 'Evaluating results in languages other than English',
  'user': {'login': 'gitrid',
   'id': 21285019,
   'node_id': 'MDQ6VXNlcjIxMjg1MDE5',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/21285019?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/gitrid',
   'html_url': 'https: //github.com/gitrid',
   'followers_url': 'https: //api.github.com/users/gitrid/followers',
   'following_url': 'https: //api.github.com/users/gitrid/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/gitrid/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/gitrid/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/gitrid/subscriptions',
   'organizations_url': 'https: //api.github.com/users/gitrid/orgs',
   'repos_url': 'https: //api.github.com/users/gitrid/repos',
   'events_url': 'https: //api.github.com/users/gitrid/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/gitrid/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 22,
  'created_at': '2023-12-21T12: 06: 17Z',
  'updated_at': '2024-08-02T07: 27: 23Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Ragas version: 0.0.22\r\nPython version: Python 3.11.7\r\n\r\nCan ragas correctly evaluate results in other languages? It seems that fully correct answers receive quite low scores. E.g.\r\n\r\n```\r\nQuery: Ile kosztuje opłata miesięczna za prowadzenie Konta Santander dla osoby w wieku 35 lat?\r\nAnswer: Opłata miesięczna za prowadzenie Konta Santander dla osoby w wieku 35 lat wynosi 0 zł, pod warunkiem spełnienia warunku zwolnienia z opłaty, którym jest płatność kartą lub BLIKIEM na łączną kwotę co najmniej 300 zł miesięcznie. Jeśli warunek nie jest spełniony, opłata wynosi 6 zł miesięcznie.\r\nExpected: Opłata miesięczna wyniesie 0 zł, jeżeli osoba dokona płatności kartą lub BLIKIEM na łączną kwotę co najmniej 300 zł. Jeżeli nie, opłata wynosi 6 zł.\r\n\r\nResults:\r\n  ANSWER CORRECTNESS: 0.48\r\n  Faithfulness: 0.67\r\n  Answer Relevancy: 0.91\r\n  Context Precision: 0.00\r\n  Context Recall: 1.00\r\n  Context Relevancy: 0.05\r\n```\r\n\r\nTranslation:\r\n```\r\nQuery: How much is the monthly fee for a Santander Account for a person aged 35?\r\nAnswer: The monthly fee for a Santander Account for a person aged 35 is PLN 0, provided that the condition for exemption from the fee is met, which is payment with a card or BLIK for a total amount of at least PLN 300 per month. If the condition is not met, the fee is PLN 6 per month.\r\nExpected: The monthly fee will be PLN 0 if the person makes payments with a card or BLIK for a total amount of at least PLN 300. If not, the fee is PLN 6.\r\n```\r\n\r\nAs the answer is exactly correct, I would expect that answer correctness be close to 1. However it is only 0.48, whereas many other queries receive scoring of even 0.8 with a wrong answer.\r\nCan it be optimized? Is this an issue with non-English language?',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/402/reactions',
   'total_count': 4,
   '+1': 4,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/402/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/397',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/397/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/397/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/397/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/397',
  'id': 2050988573,
  'node_id': 'PR_kwDOJgX1Gs5ifq3-',
  'number': 397,
  'title': 'harmonized and removed typos in prompts in testset generation',
  'user': {'login': 'MoritzLaurer',
   'id': 41862082,
   'node_id': 'MDQ6VXNlcjQxODYyMDgy',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/41862082?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/MoritzLaurer',
   'html_url': 'https: //github.com/MoritzLaurer',
   'followers_url': 'https: //api.github.com/users/MoritzLaurer/followers',
   'following_url': 'https: //api.github.com/users/MoritzLaurer/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/MoritzLaurer/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/MoritzLaurer/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/MoritzLaurer/subscriptions',
   'organizations_url': 'https: //api.github.com/users/MoritzLaurer/orgs',
   'repos_url': 'https: //api.github.com/users/MoritzLaurer/repos',
   'events_url': 'https: //api.github.com/users/MoritzLaurer/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/MoritzLaurer/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2023-12-20T17: 31: 26Z',
  'updated_at': '2023-12-29T07: 22: 23Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/397',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/397',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/397.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/397.patch',
   'merged_at': None
                  },
  'body': 'this pull requests harmonises prompt formatting and makes minor improvements (e.g. removal of typos) in the prompt templates for testset generation',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/397/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/397/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/332',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/332/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/332/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/332/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/332',
  'id': 2009149464,
  'node_id': 'PR_kwDOJgX1Gs5gRzOU',
  'number': 332,
  'title': 'Support passing OPENAI base url w/ env variable',
  'user': {'login': 'baichuan-assistant',
   'id': 139942740,
   'node_id': 'U_kgDOCFdbVA',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/139942740?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/baichuan-assistant',
   'html_url': 'https: //github.com/baichuan-assistant',
   'followers_url': 'https: //api.github.com/users/baichuan-assistant/followers',
   'following_url': 'https: //api.github.com/users/baichuan-assistant/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/baichuan-assistant/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/baichuan-assistant/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/baichuan-assistant/subscriptions',
   'organizations_url': 'https: //api.github.com/users/baichuan-assistant/orgs',
   'repos_url': 'https: //api.github.com/users/baichuan-assistant/repos',
   'events_url': 'https: //api.github.com/users/baichuan-assistant/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/baichuan-assistant/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 1,
  'created_at': '2023-11-24T05: 58: 01Z',
  'updated_at': '2023-11-30T07: 04: 33Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/332',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/332',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/332.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/332.patch',
   'merged_at': None
                  },
  'body': None,
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/332/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/332/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/313',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/313/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/313/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/313/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/313',
  'id': 2002993220,
  'node_id': 'PR_kwDOJgX1Gs5f89dA',
  'number': 313,
  'title': 'added model kwargs support to AzureChAzureMLChatOnlineEndpoint',
  'user': {'login': 'Manikanta5112',
   'id': 116510423,
   'node_id': 'U_kgDOBvHO1w',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/116510423?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/Manikanta5112',
   'html_url': 'https: //github.com/Manikanta5112',
   'followers_url': 'https: //api.github.com/users/Manikanta5112/followers',
   'following_url': 'https: //api.github.com/users/Manikanta5112/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/Manikanta5112/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/Manikanta5112/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/Manikanta5112/subscriptions',
   'organizations_url': 'https: //api.github.com/users/Manikanta5112/orgs',
   'repos_url': 'https: //api.github.com/users/Manikanta5112/repos',
   'events_url': 'https: //api.github.com/users/Manikanta5112/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/Manikanta5112/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2023-11-20T20: 56: 42Z',
  'updated_at': '2023-12-14T06: 03: 49Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/313',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/313',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/313.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/313.patch',
   'merged_at': None
                  },
  'body': "open source chat models like llama2, has to instantiate through AzureMLChatOnlineEndpoint(azure_ml_endpoint)\r\n\r\ncurrently, we are directly checking temperature parameter for self.llm. whereas models instantiated through (azure_ml_endpoint) doesn't contain that parameter.\r\n\r\nwhereas it exist as dictionary under model_kwargs.\r\n\r\nso, added support for this.\r\n\r\n\r\n",
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/313/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/313/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/299',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/299/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/299/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/299/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/299',
  'id': 1999446315,
  'node_id': 'PR_kwDOJgX1Gs5fxJeZ',
  'number': 299,
  'title': 'feat: allow metric traces',
  'user': {'login': 'grauvictor',
   'id': 149517415,
   'node_id': 'U_kgDOCOl0Zw',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/149517415?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/grauvictor',
   'html_url': 'https: //github.com/grauvictor',
   'followers_url': 'https: //api.github.com/users/grauvictor/followers',
   'following_url': 'https: //api.github.com/users/grauvictor/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/grauvictor/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/grauvictor/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/grauvictor/subscriptions',
   'organizations_url': 'https: //api.github.com/users/grauvictor/orgs',
   'repos_url': 'https: //api.github.com/users/grauvictor/repos',
   'events_url': 'https: //api.github.com/users/grauvictor/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/grauvictor/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2023-11-17T15: 59: 24Z',
  'updated_at': '2023-11-21T11: 28: 28Z',
  'closed_at': None,
  'author_association': 'CONTRIBUTOR',
  'active_lock_reason': None,
  'draft': True,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/299',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/299',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/299.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/299.patch',
   'merged_at': None
                  },
  'body': 'fixes: #250\r\n\r\nAllow to retrieve metric logs calculation',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/299/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/299/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/298',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/298/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/298/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/298/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/298',
  'id': 1999439785,
  'node_id': 'PR_kwDOJgX1Gs5fxIGQ',
  'number': 298,
  'title': 'Working version for Bedrock Anthropic models',
  'user': {'login': 'austinmw',
   'id': 12224358,
   'node_id': 'MDQ6VXNlcjEyMjI0MzU4',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/12224358?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/austinmw',
   'html_url': 'https: //github.com/austinmw',
   'followers_url': 'https: //api.github.com/users/austinmw/followers',
   'following_url': 'https: //api.github.com/users/austinmw/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/austinmw/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/austinmw/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/austinmw/subscriptions',
   'organizations_url': 'https: //api.github.com/users/austinmw/orgs',
   'repos_url': 'https: //api.github.com/users/austinmw/repos',
   'events_url': 'https: //api.github.com/users/austinmw/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/austinmw/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2023-11-17T15: 56: 32Z',
  'updated_at': '2024-02-03T18: 49: 40Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/298',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/298',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/298.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/298.patch',
   'merged_at': None
                  },
  'body': 'Hi, I assume this PR will not actually get merged as-is, but I wanted to share the changes I made in order to get Anthropic models to produce reasonable evaluation outputs:\r\n\r\n- Added option for custom prompts\r\n- Defined and tested prompts for Claude models\r\n- Added logging\r\n\r\nI also copied and updated your `aws-bedrock.ipynb` to reflect the changes. Hope this may help! 😊',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/298/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/298/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/278',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/278/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/278/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/278/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/pull/278',
  'id': 1988955446,
  'node_id': 'PR_kwDOJgX1Gs5fNlJX',
  'number': 278,
  'title': 'feat: add custom prompt feature to testset generator',
  'user': {'login': 'gsittyz',
   'id': 27331655,
   'node_id': 'MDQ6VXNlcjI3MzMxNjU1',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/27331655?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/gsittyz',
   'html_url': 'https: //github.com/gsittyz',
   'followers_url': 'https: //api.github.com/users/gsittyz/followers',
   'following_url': 'https: //api.github.com/users/gsittyz/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/gsittyz/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/gsittyz/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/gsittyz/subscriptions',
   'organizations_url': 'https: //api.github.com/users/gsittyz/orgs',
   'repos_url': 'https: //api.github.com/users/gsittyz/repos',
   'events_url': 'https: //api.github.com/users/gsittyz/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/gsittyz/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [],
  'milestone': None,
  'comments': 2,
  'created_at': '2023-11-11T13: 45: 36Z',
  'updated_at': '2023-12-14T06: 11: 13Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'draft': False,
  'pull_request': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/pulls/278',
   'html_url': 'https: //github.com/explodinggradients/ragas/pull/278',
   'diff_url': 'https: //github.com/explodinggradients/ragas/pull/278.diff',
   'patch_url': 'https: //github.com/explodinggradients/ragas/pull/278.patch',
   'merged_at': None
                  },
  'body': '- Prompts are stored as instance variables\r\n- Add prompts argmument in the initialization method',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/278/reactions',
   'total_count': 0,
   '+1': 0,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/278/timeline',
  'performed_via_github_app': None,
  'state_reason': None
            },
            {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/247',
  'repository_url': 'https: //api.github.com/repos/explodinggradients/ragas',
  'labels_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/247/labels{/name}',
  'comments_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/247/comments',
  'events_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/247/events',
  'html_url': 'https: //github.com/explodinggradients/ragas/issues/247',
  'id': 1973290994,
  'node_id': 'I_kwDOJgX1Gs51ngfy',
  'number': 247,
  'title': 'maximum context length  ',
  'user': {'login': 'aydinmyilmaz',
   'id': 29075537,
   'node_id': 'MDQ6VXNlcjI5MDc1NTM3',
   'avatar_url': 'https: //avatars.githubusercontent.com/u/29075537?v=4',
   'gravatar_id': '',
   'url': 'https: //api.github.com/users/aydinmyilmaz',
   'html_url': 'https: //github.com/aydinmyilmaz',
   'followers_url': 'https: //api.github.com/users/aydinmyilmaz/followers',
   'following_url': 'https: //api.github.com/users/aydinmyilmaz/following{/other_user}',
   'gists_url': 'https: //api.github.com/users/aydinmyilmaz/gists{/gist_id}',
   'starred_url': 'https: //api.github.com/users/aydinmyilmaz/starred{/owner}{/repo}',
   'subscriptions_url': 'https: //api.github.com/users/aydinmyilmaz/subscriptions',
   'organizations_url': 'https: //api.github.com/users/aydinmyilmaz/orgs',
   'repos_url': 'https: //api.github.com/users/aydinmyilmaz/repos',
   'events_url': 'https: //api.github.com/users/aydinmyilmaz/events{/privacy}',
   'received_events_url': 'https: //api.github.com/users/aydinmyilmaz/received_events',
   'type': 'User',
   'site_admin': False
                  },
  'labels': [
                        {'id': 5480028613,
    'node_id': 'LA_kwDOJgX1Gs8AAAABRqKZxQ',
    'url': 'https: //api.github.com/repos/explodinggradients/ragas/labels/bug',
    'name': 'bug',
    'color': 'd73a4a',
    'default': True,
    'description': "Something isn't working"
                        }
                  ],
  'state': 'open',
  'locked': False,
  'assignee': None,
  'assignees': [
                        {'login': 'jjmachan',
    'id': 5261489,
    'node_id': 'MDQ6VXNlcjUyNjE0ODk=',
    'avatar_url': 'https: //avatars.githubusercontent.com/u/5261489?v=4',
    'gravatar_id': '',
    'url': 'https: //api.github.com/users/jjmachan',
    'html_url': 'https: //github.com/jjmachan',
    'followers_url': 'https: //api.github.com/users/jjmachan/followers',
    'following_url': 'https: //api.github.com/users/jjmachan/following{/other_user}',
    'gists_url': 'https: //api.github.com/users/jjmachan/gists{/gist_id}',
    'starred_url': 'https: //api.github.com/users/jjmachan/starred{/owner}{/repo}',
    'subscriptions_url': 'https: //api.github.com/users/jjmachan/subscriptions',
    'organizations_url': 'https: //api.github.com/users/jjmachan/orgs',
    'repos_url': 'https: //api.github.com/users/jjmachan/repos',
    'events_url': 'https: //api.github.com/users/jjmachan/events{/privacy}',
    'received_events_url': 'https: //api.github.com/users/jjmachan/received_events',
    'type': 'User',
    'site_admin': False
                        }
                  ],
  'milestone': None,
  'comments': 1,
  'created_at': '2023-11-02T00: 15: 46Z',
  'updated_at': '2024-06-10T07: 36: 15Z',
  'closed_at': None,
  'author_association': 'NONE',
  'active_lock_reason': None,
  'body': 'Hi There,\r\n\r\nIs it possible to add an option to limit the token or word counts with a parameter, or just skip a request with this error instead of breaking all evaluation process?\r\n\r\nevaluating with [answer_relevancy
                  ]\r\n\r\n---------------------------------------------------------------------------\r\nInvalidRequestError                       Traceback (most recent call last)\r\n[<ipython-input-13-cc8ae8de5cb3>
                  ](https: //localhost:8080/#) in <cell line: 63>()\r\n     62 \r\n     63 for col in columns_to_evaluate:\r\n---> 64     evaluate_column_and_save(df_9_response, col, evaluate)\r\n\r\n22 frames\r\n[/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py](https://localhost:8080/#) in _interpret_response_line(self, rbody, rcode, rheaders, stream)\r\n    773         stream_error = stream and "error" in resp.data\r\n    774         if stream_error or not 200 <= rcode < 300:\r\n--> 775             raise self.handle_error_response(\r\n    776                 rbody, rcode, resp.data, rheaders, stream_error=stream_error\r\n    777             )\r\n\r\nInvalidRequestError: This model\'s maximum context length is 4097 tokens. However, your messages resulted in 4218 tokens. Please reduce the length of the messages.',
  'reactions': {'url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/247/reactions',
   'total_count': 1,
   '+1': 1,
   '-1': 0,
   'laugh': 0,
   'hooray': 0,
   'confused': 0,
   'heart': 0,
   'rocket': 0,
   'eyes': 0
                  },
  'timeline_url': 'https: //api.github.com/repos/explodinggradients/ragas/issues/247/timeline',
  'performed_via_github_app': None,
  'state_reason': 'reopened'
            }
      ]